* 
* ==> Audit <==
* |---------|-----------------------------|----------|-------------|---------|-------------------------------|-------------------------------|
| Command |            Args             | Profile  |    User     | Version |          Start Time           |           End Time            |
|---------|-----------------------------|----------|-------------|---------|-------------------------------|-------------------------------|
| service | emp-service --url           | minikube | ashujauhari | v1.25.2 | Sat, 28 Jan 2023 19:26:59 IST | Sat, 28 Jan 2023 19:37:41 IST |
| service | emp-service --url           | minikube | ashujauhari | v1.25.2 | Sat, 28 Jan 2023 19:37:44 IST | Sat, 28 Jan 2023 19:37:51 IST |
| service | list                        | minikube | ashujauhari | v1.25.2 | Sat, 28 Jan 2023 23:11:12 IST | Sat, 28 Jan 2023 23:11:12 IST |
| service | eureka-webapp --url         | minikube | ashujauhari | v1.25.2 | Sat, 28 Jan 2023 23:11:23 IST | Sat, 28 Jan 2023 23:12:54 IST |
| service | list                        | minikube | ashujauhari | v1.25.2 | Sat, 28 Jan 2023 23:19:54 IST | Sat, 28 Jan 2023 23:19:55 IST |
| service | api --url                   | minikube | ashujauhari | v1.25.2 | Sat, 28 Jan 2023 23:23:04 IST | Sat, 28 Jan 2023 23:29:59 IST |
| stop    |                             | minikube | ashujauhari | v1.25.2 | Sat, 28 Jan 2023 23:50:47 IST | Sat, 28 Jan 2023 23:50:59 IST |
| start   | --driver=docker             | minikube | ashujauhari | v1.25.2 | Sun, 29 Jan 2023 21:47:53 IST | Sun, 29 Jan 2023 21:48:13 IST |
| ip      |                             | minikube | ashujauhari | v1.25.2 | Sun, 29 Jan 2023 21:49:14 IST | Sun, 29 Jan 2023 21:49:14 IST |
| service | list                        | minikube | ashujauhari | v1.25.2 | Sun, 29 Jan 2023 21:49:19 IST | Sun, 29 Jan 2023 21:49:19 IST |
| service | eureka-webapp --url         | minikube | ashujauhari | v1.25.2 | Sun, 29 Jan 2023 21:49:33 IST | Sun, 29 Jan 2023 21:51:13 IST |
| ip      |                             | minikube | ashujauhari | v1.25.2 | Sun, 29 Jan 2023 21:53:52 IST | Sun, 29 Jan 2023 21:53:52 IST |
| service | eureka-webapp               | minikube | ashujauhari | v1.25.2 | Sun, 29 Jan 2023 21:51:24 IST | Sun, 29 Jan 2023 22:01:17 IST |
| stop    |                             | minikube | ashujauhari | v1.25.2 | Mon, 30 Jan 2023 08:53:43 IST | Mon, 30 Jan 2023 08:53:55 IST |
| start   | --driver=docker             | minikube | ashujauhari | v1.25.2 | Mon, 30 Jan 2023 09:48:32 IST | Mon, 30 Jan 2023 09:48:49 IST |
| ip      |                             | minikube | ashujauhari | v1.25.2 | Mon, 30 Jan 2023 10:24:56 IST | Mon, 30 Jan 2023 10:24:56 IST |
| service | list                        | minikube | ashujauhari | v1.25.2 | Mon, 30 Jan 2023 10:29:08 IST | Mon, 30 Jan 2023 10:29:08 IST |
| service | eureka-webapp --url         | minikube | ashujauhari | v1.25.2 | Sun, 29 Jan 2023 22:00:06 IST | Mon, 30 Jan 2023 13:29:25 IST |
| start   |                             | minikube | ashujauhari | v1.29.0 | 02 Mar 23 17:29 IST           | 02 Mar 23 17:31 IST           |
| service | hello-minikube --url        | minikube | ashujauhari | v1.29.0 | 02 Mar 23 17:44 IST           |                               |
| stop    |                             | minikube | ashujauhari | v1.29.0 | 02 Mar 23 17:46 IST           | 02 Mar 23 17:47 IST           |
| start   | --driver=docker             | minikube | ashujauhari | v1.29.0 | 02 Mar 23 17:50 IST           | 02 Mar 23 17:50 IST           |
| service | hello-minikube1 --url       | minikube | ashujauhari | v1.29.0 | 02 Mar 23 17:56 IST           | 02 Mar 23 17:58 IST           |
| stop    |                             | minikube | ashujauhari | v1.29.0 | 02 Mar 23 18:03 IST           | 02 Mar 23 18:03 IST           |
| start   |                             | minikube | ashujauhari | v1.29.0 | 02 Mar 23 18:07 IST           | 02 Mar 23 18:07 IST           |
| stop    |                             | minikube | ashujauhari | v1.29.0 | 02 Mar 23 18:08 IST           | 02 Mar 23 18:09 IST           |
| start   | --driver=docker             | minikube | ashujauhari | v1.29.0 | 02 Mar 23 18:15 IST           | 02 Mar 23 18:16 IST           |
| service | hello-minikube --url        | minikube | ashujauhari | v1.29.0 | 02 Mar 23 18:19 IST           | 02 Mar 23 18:30 IST           |
| service | hello-minikube1             | minikube | ashujauhari | v1.29.0 | 02 Mar 23 18:30 IST           | 02 Mar 23 18:36 IST           |
| service | service/eureka-webapp --url | minikube | ashujauhari | v1.29.0 | 02 Mar 23 18:37 IST           |                               |
| service | eureka-webapp --url         | minikube | ashujauhari | v1.29.0 | 02 Mar 23 18:37 IST           | 02 Mar 23 18:39 IST           |
| service | eureka-webapp --url         | minikube | ashujauhari | v1.29.0 | 02 Mar 23 18:40 IST           | 02 Mar 23 18:40 IST           |
| service | hello-minikube1             | minikube | ashujauhari | v1.29.0 | 02 Mar 23 18:40 IST           | 02 Mar 23 18:42 IST           |
| service | hello-minikube              | minikube | ashujauhari | v1.29.0 | 02 Mar 23 18:45 IST           | 02 Mar 23 18:52 IST           |
| service | hello-minikube --url        | minikube | ashujauhari | v1.29.0 | 02 Mar 23 19:05 IST           | 02 Mar 23 19:05 IST           |
| stop    |                             | minikube | ashujauhari | v1.29.0 | 02 Mar 23 19:09 IST           | 02 Mar 23 19:09 IST           |
| start   | --driver=docker             | minikube | ashujauhari | v1.29.0 | 04 Mar 23 10:33 IST           | 04 Mar 23 10:35 IST           |
| service | hello-minikube --url        | minikube | ashujauhari | v1.29.0 | 04 Mar 23 10:36 IST           | 04 Mar 23 10:37 IST           |
| service | hello-minikube              | minikube | ashujauhari | v1.29.0 | 04 Mar 23 10:37 IST           | 04 Mar 23 10:43 IST           |
| service | eureka --url                | minikube | ashujauhari | v1.29.0 | 04 Mar 23 10:46 IST           | 04 Mar 23 10:46 IST           |
| service | eureka --url                | minikube | ashujauhari | v1.29.0 | 04 Mar 23 10:46 IST           | 04 Mar 23 10:47 IST           |
| service | eureka --url                | minikube | ashujauhari | v1.29.0 | 04 Mar 23 10:47 IST           | 04 Mar 23 10:55 IST           |
| service | emp                         | minikube | ashujauhari | v1.29.0 | 04 Mar 23 10:56 IST           | 04 Mar 23 10:58 IST           |
| service | hello-minikube              | minikube | ashujauhari | v1.29.0 | 04 Mar 23 10:58 IST           | 04 Mar 23 12:03 IST           |
| service | nginx-service --url         | minikube | ashujauhari | v1.29.0 | 05 Mar 23 00:41 IST           | 05 Mar 23 20:52 IST           |
| stop    |                             | minikube | ashujauhari | v1.29.0 | 06 Mar 23 09:34 IST           |                               |
| start   |                             | minikube | ashujauhari | v1.29.0 | 06 Mar 23 12:03 IST           | 06 Mar 23 12:04 IST           |
| ip      |                             | minikube | ashujauhari | v1.29.0 | 08 Mar 23 14:10 IST           | 08 Mar 23 14:10 IST           |
| ip      |                             | minikube | ashujauhari | v1.29.0 | 08 Mar 23 14:11 IST           | 08 Mar 23 14:11 IST           |
| ssh     | -v 7                        | minikube | ashujauhari | v1.29.0 | 08 Mar 23 14:12 IST           |                               |
| start   |                             | minikube | ashujauhari | v1.29.0 | 14 Oct 23 22:56 IST           |                               |
| start   |                             | minikube | ashujauhari | v1.29.0 | 14 Oct 23 22:57 IST           |                               |
| stop    |                             | minikube | ashujauhari | v1.29.0 | 14 Oct 23 23:00 IST           | 14 Oct 23 23:00 IST           |
| delete  |                             | minikube | ashujauhari | v1.29.0 | 14 Oct 23 23:00 IST           | 14 Oct 23 23:00 IST           |
| start   |                             | minikube | ashujauhari | v1.29.0 | 16 Oct 23 13:50 IST           | 16 Oct 23 13:52 IST           |
| service | myapp-service --url         | minikube | ashujauhari | v1.29.0 | 17 Oct 23 17:05 IST           |                               |
| start   |                             | minikube | ashujauhari | v1.29.0 | 17 Oct 23 17:06 IST           | 17 Oct 23 17:07 IST           |
| service | myapp-service --url         | minikube | ashujauhari | v1.29.0 | 17 Oct 23 17:07 IST           |                               |
| stop    |                             | minikube | ashujauhari | v1.29.0 | 17 Oct 23 17:07 IST           | 17 Oct 23 17:08 IST           |
| start   | --network=socket_vmnet      | minikube | ashujauhari | v1.29.0 | 17 Oct 23 17:08 IST           |                               |
|---------|-----------------------------|----------|-------------|---------|-------------------------------|-------------------------------|

* 
* ==> Last Start <==
* Log file created at: 2023/10/17 17:08:27
Running on machine: Ashus-MacBook-Air
Binary: Built with gc go1.19.5 for darwin/arm64
Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
I1017 17:08:27.473552   28215 out.go:296] Setting OutFile to fd 1 ...
I1017 17:08:27.473666   28215 out.go:348] isatty.IsTerminal(1) = true
I1017 17:08:27.473668   28215 out.go:309] Setting ErrFile to fd 2...
I1017 17:08:27.473670   28215 out.go:348] isatty.IsTerminal(2) = true
I1017 17:08:27.473729   28215 root.go:334] Updating PATH: /Users/ashujauhari/.minikube/bin
I1017 17:08:27.474470   28215 out.go:303] Setting JSON to false
I1017 17:08:27.498573   28215 start.go:125] hostinfo: {"hostname":"Ashus-MacBook-Air.local","uptime":2398639,"bootTime":1695144068,"procs":299,"os":"darwin","platform":"darwin","platformFamily":"Standalone Workstation","platformVersion":"11.7","kernelVersion":"20.6.0","kernelArch":"arm64","virtualizationSystem":"","virtualizationRole":"","hostId":"8d29fd61-d603-554a-8e4a-f18b56e5b6ef"}
W1017 17:08:27.498685   28215 start.go:133] gopshost.Virtualization returned error: not implemented yet
I1017 17:08:27.523861   28215 out.go:177] 😄  minikube v1.29.0 on Darwin 11.7 (arm64)
I1017 17:08:27.561071   28215 notify.go:220] Checking for updates...
I1017 17:08:27.561242   28215 config.go:180] Loaded profile config "minikube": Driver=qemu2, ContainerRuntime=docker, KubernetesVersion=v1.26.1
I1017 17:08:27.562124   28215 driver.go:365] Setting default libvirt URI to qemu:///system
I1017 17:08:27.582168   28215 out.go:177] ✨  Using the qemu2 driver based on existing profile
I1017 17:08:27.621527   28215 start.go:296] selected driver: qemu2
I1017 17:08:27.621788   28215 start.go:857] validating driver "qemu2" against &{Name:minikube KeepContext:false EmbedCerts:false MinikubeISO:https://storage.googleapis.com/minikube/iso/minikube-v1.29.0-arm64.iso KicBaseImage:gcr.io/k8s-minikube/kicbase:v0.0.37@sha256:8bf7a0e8a062bc5e2b71d28b35bfa9cc862d9220e234e86176b3785f685d8b15 Memory:4000 CPUs:2 DiskSize:20000 VMDriver: Driver:qemu2 HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[] ContainerVolumeMounts:[] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.59.1/24 HypervVirtualSwitch: HypervUseExternalSwitch:false HypervExternalAdapter: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false KVMNUMACount:1 APIServerPort:49338 DockerOpt:[] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:false DNSProxy:false HostDNSResolver:true HostOnlyNicType:virtio NatNicType:virtio SSHIPAddress: SSHUser:root SSHKey: SSHPort:22 KubernetesConfig:{KubernetesVersion:v1.26.1 ClusterName:minikube Namespace:default APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI: NodeIP: NodePort:8443 NodeName:} Nodes:[{Name: IP:10.0.2.15 Port:8443 KubernetesVersion:v1.26.1 ContainerRuntime:docker ControlPlane:true Worker:true}] Addons:map[default-storageclass:true storage-provisioner:true] CustomAddonImages:map[] CustomAddonRegistries:map[] VerifyComponents:map[apiserver:true system_pods:true] StartHostTimeout:6m0s ScheduledStop:<nil> ExposedPorts:[] ListenAddress: Network:user Subnet: MultiNodeRequested:false ExtraDisks:0 CertExpiration:26280h0m0s Mount:false MountString:/Users:/minikube-host Mount9PVersion:9p2000.L MountGID:docker MountIP: MountMSize:262144 MountOptions:[] MountPort:0 MountType:9p MountUID:docker BinaryMirror: DisableOptimizations:false DisableMetrics:false CustomQemuFirmwarePath: SocketVMnetClientPath: SocketVMnetPath: StaticIP:}
I1017 17:08:27.621945   28215 start.go:868] status for qemu2: {Installed:true Healthy:true Running:true NeedsImprovement:false Error:<nil> Reason: Fix: Doc: Version:}
I1017 17:08:27.627236   28215 cni.go:84] Creating CNI manager for ""
I1017 17:08:27.627282   28215 cni.go:157] "qemu2" driver + "docker" container runtime found on kubernetes v1.24+, recommending bridge
I1017 17:08:27.627308   28215 start_flags.go:319] config:
{Name:minikube KeepContext:false EmbedCerts:false MinikubeISO:https://storage.googleapis.com/minikube/iso/minikube-v1.29.0-arm64.iso KicBaseImage:gcr.io/k8s-minikube/kicbase:v0.0.37@sha256:8bf7a0e8a062bc5e2b71d28b35bfa9cc862d9220e234e86176b3785f685d8b15 Memory:4000 CPUs:2 DiskSize:20000 VMDriver: Driver:qemu2 HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[] ContainerVolumeMounts:[] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.59.1/24 HypervVirtualSwitch: HypervUseExternalSwitch:false HypervExternalAdapter: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false KVMNUMACount:1 APIServerPort:49338 DockerOpt:[] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:false DNSProxy:false HostDNSResolver:true HostOnlyNicType:virtio NatNicType:virtio SSHIPAddress: SSHUser:root SSHKey: SSHPort:22 KubernetesConfig:{KubernetesVersion:v1.26.1 ClusterName:minikube Namespace:default APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI: NodeIP: NodePort:8443 NodeName:} Nodes:[{Name: IP:10.0.2.15 Port:8443 KubernetesVersion:v1.26.1 ContainerRuntime:docker ControlPlane:true Worker:true}] Addons:map[default-storageclass:true storage-provisioner:true] CustomAddonImages:map[] CustomAddonRegistries:map[] VerifyComponents:map[apiserver:true system_pods:true] StartHostTimeout:6m0s ScheduledStop:<nil> ExposedPorts:[] ListenAddress: Network:socket_vmnet Subnet: MultiNodeRequested:false ExtraDisks:0 CertExpiration:26280h0m0s Mount:false MountString:/Users:/minikube-host Mount9PVersion:9p2000.L MountGID:docker MountIP: MountMSize:262144 MountOptions:[] MountPort:0 MountType:9p MountUID:docker BinaryMirror: DisableOptimizations:false DisableMetrics:false CustomQemuFirmwarePath: SocketVMnetClientPath: SocketVMnetPath: StaticIP:}
I1017 17:08:27.627694   28215 iso.go:125] acquiring lock: {Name:mkf3b3bf34991096ec34a474fef57af6c5b15d55 Clock:{} Delay:500ms Timeout:10m0s Cancel:<nil>}
I1017 17:08:27.647602   28215 out.go:177] 👍  Starting control plane node minikube in cluster minikube
I1017 17:08:27.685902   28215 preload.go:132] Checking if preload exists for k8s version v1.26.1 and runtime docker
I1017 17:08:27.685947   28215 preload.go:148] Found local preload: /Users/ashujauhari/.minikube/cache/preloaded-tarball/preloaded-images-k8s-v18-v1.26.1-docker-overlay2-arm64.tar.lz4
I1017 17:08:27.686631   28215 cache.go:57] Caching tarball of preloaded images
I1017 17:08:27.686824   28215 preload.go:174] Found /Users/ashujauhari/.minikube/cache/preloaded-tarball/preloaded-images-k8s-v18-v1.26.1-docker-overlay2-arm64.tar.lz4 in cache, skipping download
I1017 17:08:27.686841   28215 cache.go:60] Finished verifying existence of preloaded tar for  v1.26.1 on docker
I1017 17:08:27.687004   28215 profile.go:148] Saving config to /Users/ashujauhari/.minikube/profiles/minikube/config.json ...
I1017 17:08:27.687699   28215 cache.go:193] Successfully downloaded all kic artifacts
I1017 17:08:27.687768   28215 start.go:364] acquiring machines lock for minikube: {Name:mkc67b67417322117f82338a02a191ad4081cd81 Clock:{} Delay:500ms Timeout:13m0s Cancel:<nil>}
I1017 17:08:27.687839   28215 start.go:368] acquired machines lock for "minikube" in 57.709µs
I1017 17:08:27.687880   28215 start.go:96] Skipping create...Using existing machine configuration
I1017 17:08:27.687885   28215 fix.go:55] fixHost starting: 
I1017 17:08:27.688144   28215 fix.go:103] recreateIfNeeded on minikube: state=Stopped err=<nil>
W1017 17:08:27.688160   28215 fix.go:129] unexpected machine state, will restart: <nil>
I1017 17:08:27.726209   28215 out.go:177] 🔄  Restarting existing qemu2 VM for "minikube" ...
I1017 17:08:27.745517   28215 main.go:141] libmachine: executing: qemu-system-aarch64 -M virt -cpu host -drive file=/opt/homebrew/Cellar/qemu/8.0.2/share/qemu/edk2-aarch64-code.fd,readonly=on,format=raw,if=pflash -display none -accel hvf -m 4000 -smp 2 -boot d -cdrom /Users/ashujauhari/.minikube/machines/minikube/boot2docker.iso -qmp unix:/Users/ashujauhari/.minikube/machines/minikube/monitor,server,nowait -pidfile /Users/ashujauhari/.minikube/machines/minikube/qemu.pid -nic user,model=virtio,hostfwd=tcp::55250-:22,hostfwd=tcp::55251-:2376,hostname=minikube -daemonize /Users/ashujauhari/.minikube/machines/minikube/disk.qcow2
I1017 17:08:27.872136   28215 main.go:141] libmachine: STDOUT: 
I1017 17:08:27.872170   28215 main.go:141] libmachine: STDERR: 
I1017 17:08:27.872176   28215 main.go:141] libmachine: Waiting for VM to start (ssh -p 55250 docker@127.0.0.1)...
I1017 17:08:47.299041   28215 profile.go:148] Saving config to /Users/ashujauhari/.minikube/profiles/minikube/config.json ...
I1017 17:08:47.299317   28215 machine.go:88] provisioning docker machine ...
I1017 17:08:47.299875   28215 buildroot.go:166] provisioning hostname "minikube"
I1017 17:08:47.300132   28215 main.go:141] libmachine: Using SSH client type: native
I1017 17:08:47.301098   28215 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x100495d30] 0x1004987d0 <nil>  [] 0s} localhost 55250 <nil> <nil>}
I1017 17:08:47.301104   28215 main.go:141] libmachine: About to run SSH command:
sudo hostname minikube && echo "minikube" | sudo tee /etc/hostname
I1017 17:08:47.377090   28215 main.go:141] libmachine: SSH cmd err, output: <nil>: minikube

I1017 17:08:47.377174   28215 main.go:141] libmachine: Using SSH client type: native
I1017 17:08:47.377265   28215 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x100495d30] 0x1004987d0 <nil>  [] 0s} localhost 55250 <nil> <nil>}
I1017 17:08:47.377271   28215 main.go:141] libmachine: About to run SSH command:

		if ! grep -xq '.*\sminikube' /etc/hosts; then
			if grep -xq '127.0.1.1\s.*' /etc/hosts; then
				sudo sed -i 's/^127.0.1.1\s.*/127.0.1.1 minikube/g' /etc/hosts;
			else 
				echo '127.0.1.1 minikube' | sudo tee -a /etc/hosts; 
			fi
		fi
I1017 17:08:47.448212   28215 main.go:141] libmachine: SSH cmd err, output: <nil>: 
I1017 17:08:47.448226   28215 buildroot.go:172] set auth options {CertDir:/Users/ashujauhari/.minikube CaCertPath:/Users/ashujauhari/.minikube/certs/ca.pem CaPrivateKeyPath:/Users/ashujauhari/.minikube/certs/ca-key.pem CaCertRemotePath:/etc/docker/ca.pem ServerCertPath:/Users/ashujauhari/.minikube/machines/server.pem ServerKeyPath:/Users/ashujauhari/.minikube/machines/server-key.pem ClientKeyPath:/Users/ashujauhari/.minikube/certs/key.pem ServerCertRemotePath:/etc/docker/server.pem ServerKeyRemotePath:/etc/docker/server-key.pem ClientCertPath:/Users/ashujauhari/.minikube/certs/cert.pem ServerCertSANs:[] StorePath:/Users/ashujauhari/.minikube}
I1017 17:08:47.448234   28215 buildroot.go:174] setting up certificates
I1017 17:08:47.448387   28215 provision.go:83] configureAuth start
I1017 17:08:47.448392   28215 provision.go:138] copyHostCerts
I1017 17:08:47.448993   28215 exec_runner.go:144] found /Users/ashujauhari/.minikube/ca.pem, removing ...
I1017 17:08:47.449108   28215 exec_runner.go:207] rm: /Users/ashujauhari/.minikube/ca.pem
I1017 17:08:47.449655   28215 exec_runner.go:151] cp: /Users/ashujauhari/.minikube/certs/ca.pem --> /Users/ashujauhari/.minikube/ca.pem (1090 bytes)
I1017 17:08:47.449905   28215 exec_runner.go:144] found /Users/ashujauhari/.minikube/cert.pem, removing ...
I1017 17:08:47.449907   28215 exec_runner.go:207] rm: /Users/ashujauhari/.minikube/cert.pem
I1017 17:08:47.449971   28215 exec_runner.go:151] cp: /Users/ashujauhari/.minikube/certs/cert.pem --> /Users/ashujauhari/.minikube/cert.pem (1135 bytes)
I1017 17:08:47.450124   28215 exec_runner.go:144] found /Users/ashujauhari/.minikube/key.pem, removing ...
I1017 17:08:47.450126   28215 exec_runner.go:207] rm: /Users/ashujauhari/.minikube/key.pem
I1017 17:08:47.450162   28215 exec_runner.go:151] cp: /Users/ashujauhari/.minikube/certs/key.pem --> /Users/ashujauhari/.minikube/key.pem (1679 bytes)
I1017 17:08:47.450362   28215 provision.go:112] generating server cert: /Users/ashujauhari/.minikube/machines/server.pem ca-key=/Users/ashujauhari/.minikube/certs/ca.pem private-key=/Users/ashujauhari/.minikube/certs/ca-key.pem org=ashujauhari.minikube san=[127.0.0.1 localhost localhost 127.0.0.1 minikube minikube]
I1017 17:08:47.526767   28215 provision.go:172] copyRemoteCerts
I1017 17:08:47.527175   28215 ssh_runner.go:195] Run: sudo mkdir -p /etc/docker /etc/docker /etc/docker
I1017 17:08:47.527186   28215 sshutil.go:53] new ssh client: &{IP:localhost Port:55250 SSHKeyPath:/Users/ashujauhari/.minikube/machines/minikube/id_rsa Username:docker}
I1017 17:08:47.566084   28215 ssh_runner.go:362] scp /Users/ashujauhari/.minikube/machines/server.pem --> /etc/docker/server.pem (1220 bytes)
I1017 17:08:47.574652   28215 ssh_runner.go:362] scp /Users/ashujauhari/.minikube/machines/server-key.pem --> /etc/docker/server-key.pem (1675 bytes)
I1017 17:08:47.583218   28215 ssh_runner.go:362] scp /Users/ashujauhari/.minikube/certs/ca.pem --> /etc/docker/ca.pem (1090 bytes)
I1017 17:08:47.592378   28215 provision.go:86] duration metric: configureAuth took 143.980042ms
I1017 17:08:47.592391   28215 buildroot.go:189] setting minikube options for container-runtime
I1017 17:08:47.592514   28215 config.go:180] Loaded profile config "minikube": Driver=qemu2, ContainerRuntime=docker, KubernetesVersion=v1.26.1
I1017 17:08:47.592596   28215 main.go:141] libmachine: Using SSH client type: native
I1017 17:08:47.592678   28215 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x100495d30] 0x1004987d0 <nil>  [] 0s} localhost 55250 <nil> <nil>}
I1017 17:08:47.592682   28215 main.go:141] libmachine: About to run SSH command:
df --output=fstype / | tail -n 1
I1017 17:08:47.660722   28215 main.go:141] libmachine: SSH cmd err, output: <nil>: tmpfs

I1017 17:08:47.660731   28215 buildroot.go:70] root file system type: tmpfs
I1017 17:08:47.660847   28215 provision.go:309] Updating docker unit: /lib/systemd/system/docker.service ...
I1017 17:08:47.660947   28215 main.go:141] libmachine: Using SSH client type: native
I1017 17:08:47.661970   28215 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x100495d30] 0x1004987d0 <nil>  [] 0s} localhost 55250 <nil> <nil>}
I1017 17:08:47.662006   28215 main.go:141] libmachine: About to run SSH command:
sudo mkdir -p /lib/systemd/system && printf %!s(MISSING) "[Unit]
Description=Docker Application Container Engine
Documentation=https://docs.docker.com
After=network.target  minikube-automount.service docker.socket
Requires= minikube-automount.service docker.socket 
StartLimitBurst=3
StartLimitIntervalSec=60

[Service]
Type=notify
Restart=on-failure



# This file is a systemd drop-in unit that inherits from the base dockerd configuration.
# The base configuration already specifies an 'ExecStart=...' command. The first directive
# here is to clear out that command inherited from the base configuration. Without this,
# the command from the base configuration and the command specified here are treated as
# a sequence of commands, which is not the desired behavior, nor is it valid -- systemd
# will catch this invalid input and refuse to start the service with an error like:
#  Service has more than one ExecStart= setting, which is only allowed for Type=oneshot services.

# NOTE: default-ulimit=nofile is set to an arbitrary number for consistency with other
# container runtimes. If left unlimited, it may result in OOM issues with MySQL.
ExecStart=
ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2376 -H unix:///var/run/docker.sock --default-ulimit=nofile=1048576:1048576 --tlsverify --tlscacert /etc/docker/ca.pem --tlscert /etc/docker/server.pem --tlskey /etc/docker/server-key.pem --label provider=qemu2 --insecure-registry 10.96.0.0/12 
ExecReload=/bin/kill -s HUP \$MAINPID

# Having non-zero Limit*s causes performance problems due to accounting overhead
# in the kernel. We recommend using cgroups to do container-local accounting.
LimitNOFILE=infinity
LimitNPROC=infinity
LimitCORE=infinity

# Uncomment TasksMax if your systemd version supports it.
# Only systemd 226 and above support this version.
TasksMax=infinity
TimeoutStartSec=0

# set delegate yes so that systemd does not reset the cgroups of docker containers
Delegate=yes

# kill only the docker process, not all processes in the cgroup
KillMode=process

[Install]
WantedBy=multi-user.target
" | sudo tee /lib/systemd/system/docker.service.new
I1017 17:08:47.736152   28215 main.go:141] libmachine: SSH cmd err, output: <nil>: [Unit]
Description=Docker Application Container Engine
Documentation=https://docs.docker.com
After=network.target  minikube-automount.service docker.socket
Requires= minikube-automount.service docker.socket 
StartLimitBurst=3
StartLimitIntervalSec=60

[Service]
Type=notify
Restart=on-failure



# This file is a systemd drop-in unit that inherits from the base dockerd configuration.
# The base configuration already specifies an 'ExecStart=...' command. The first directive
# here is to clear out that command inherited from the base configuration. Without this,
# the command from the base configuration and the command specified here are treated as
# a sequence of commands, which is not the desired behavior, nor is it valid -- systemd
# will catch this invalid input and refuse to start the service with an error like:
#  Service has more than one ExecStart= setting, which is only allowed for Type=oneshot services.

# NOTE: default-ulimit=nofile is set to an arbitrary number for consistency with other
# container runtimes. If left unlimited, it may result in OOM issues with MySQL.
ExecStart=
ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2376 -H unix:///var/run/docker.sock --default-ulimit=nofile=1048576:1048576 --tlsverify --tlscacert /etc/docker/ca.pem --tlscert /etc/docker/server.pem --tlskey /etc/docker/server-key.pem --label provider=qemu2 --insecure-registry 10.96.0.0/12 
ExecReload=/bin/kill -s HUP $MAINPID

# Having non-zero Limit*s causes performance problems due to accounting overhead
# in the kernel. We recommend using cgroups to do container-local accounting.
LimitNOFILE=infinity
LimitNPROC=infinity
LimitCORE=infinity

# Uncomment TasksMax if your systemd version supports it.
# Only systemd 226 and above support this version.
TasksMax=infinity
TimeoutStartSec=0

# set delegate yes so that systemd does not reset the cgroups of docker containers
Delegate=yes

# kill only the docker process, not all processes in the cgroup
KillMode=process

[Install]
WantedBy=multi-user.target

I1017 17:08:47.736247   28215 main.go:141] libmachine: Using SSH client type: native
I1017 17:08:47.736370   28215 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x100495d30] 0x1004987d0 <nil>  [] 0s} localhost 55250 <nil> <nil>}
I1017 17:08:47.736378   28215 main.go:141] libmachine: About to run SSH command:
sudo diff -u /lib/systemd/system/docker.service /lib/systemd/system/docker.service.new || { sudo mv /lib/systemd/system/docker.service.new /lib/systemd/system/docker.service; sudo systemctl -f daemon-reload && sudo systemctl -f enable docker && sudo systemctl -f restart docker; }
I1017 17:08:48.357020   28215 main.go:141] libmachine: SSH cmd err, output: <nil>: diff: can't stat '/lib/systemd/system/docker.service': No such file or directory
Created symlink /etc/systemd/system/multi-user.target.wants/docker.service → /usr/lib/systemd/system/docker.service.

I1017 17:08:48.357092   28215 machine.go:91] provisioned docker machine in 1.057765791s
I1017 17:08:48.357106   28215 start.go:300] post-start starting for "minikube" (driver="qemu2")
I1017 17:08:48.357139   28215 start.go:328] creating required directories: [/etc/kubernetes/addons /etc/kubernetes/manifests /var/tmp/minikube /var/lib/minikube /var/lib/minikube/certs /var/lib/minikube/images /var/lib/minikube/binaries /tmp/gvisor /usr/share/ca-certificates /etc/ssl/certs]
I1017 17:08:48.357482   28215 ssh_runner.go:195] Run: sudo mkdir -p /etc/kubernetes/addons /etc/kubernetes/manifests /var/tmp/minikube /var/lib/minikube /var/lib/minikube/certs /var/lib/minikube/images /var/lib/minikube/binaries /tmp/gvisor /usr/share/ca-certificates /etc/ssl/certs
I1017 17:08:48.357491   28215 sshutil.go:53] new ssh client: &{IP:localhost Port:55250 SSHKeyPath:/Users/ashujauhari/.minikube/machines/minikube/id_rsa Username:docker}
I1017 17:08:48.398067   28215 ssh_runner.go:195] Run: cat /etc/os-release
I1017 17:08:48.399793   28215 info.go:137] Remote host: Buildroot 2021.02.12
I1017 17:08:48.400016   28215 filesync.go:126] Scanning /Users/ashujauhari/.minikube/addons for local assets ...
I1017 17:08:48.400325   28215 filesync.go:126] Scanning /Users/ashujauhari/.minikube/files for local assets ...
I1017 17:08:48.400390   28215 start.go:303] post-start completed in 43.278417ms
I1017 17:08:48.400394   28215 fix.go:57] fixHost completed within 20.712574083s
I1017 17:08:48.400479   28215 main.go:141] libmachine: Using SSH client type: native
I1017 17:08:48.400566   28215 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x100495d30] 0x1004987d0 <nil>  [] 0s} localhost 55250 <nil> <nil>}
I1017 17:08:48.400573   28215 main.go:141] libmachine: About to run SSH command:
date +%!s(MISSING).%!N(MISSING)
I1017 17:08:48.471598   28215 main.go:141] libmachine: SSH cmd err, output: <nil>: 1697542727.976369129

I1017 17:08:48.471605   28215 fix.go:207] guest clock: 1697542727.976369129
I1017 17:08:48.471610   28215 fix.go:220] Guest: 2023-10-17 17:08:47.976369129 +0530 IST Remote: 2023-10-17 17:08:48.400404 +0530 IST m=+20.958928376 (delta=-424.034871ms)
I1017 17:08:48.471625   28215 fix.go:191] guest clock delta is within tolerance: -424.034871ms
I1017 17:08:48.471628   28215 start.go:83] releasing machines lock for "minikube", held for 20.78384625s
I1017 17:08:48.471762   28215 ssh_runner.go:195] Run: cat /version.json
I1017 17:08:48.471770   28215 sshutil.go:53] new ssh client: &{IP:localhost Port:55250 SSHKeyPath:/Users/ashujauhari/.minikube/machines/minikube/id_rsa Username:docker}
I1017 17:08:48.473357   28215 ssh_runner.go:195] Run: curl -sS -m 2 https://registry.k8s.io/
I1017 17:08:48.473539   28215 sshutil.go:53] new ssh client: &{IP:localhost Port:55250 SSHKeyPath:/Users/ashujauhari/.minikube/machines/minikube/id_rsa Username:docker}
I1017 17:08:48.508637   28215 ssh_runner.go:195] Run: systemctl --version
I1017 17:08:48.781208   28215 ssh_runner.go:195] Run: sh -c "stat /etc/cni/net.d/*loopback.conf*"
W1017 17:08:48.784044   28215 cni.go:208] loopback cni configuration skipped: "/etc/cni/net.d/*loopback.conf*" not found
I1017 17:08:48.784313   28215 ssh_runner.go:195] Run: sudo mkdir -p /etc/systemd/system/cri-docker.service.d
I1017 17:08:48.787578   28215 ssh_runner.go:362] scp memory --> /etc/systemd/system/cri-docker.service.d/10-cni.conf (135 bytes)
I1017 17:08:48.793286   28215 ssh_runner.go:195] Run: sudo find /etc/cni/net.d -maxdepth 1 -type f ( ( -name *bridge* -or -name *podman* ) -and -not -name *.mk_disabled ) -printf "%!p(MISSING), " -exec sh -c "sudo mv {} {}.mk_disabled" ;
I1017 17:08:48.798278   28215 cni.go:261] disabled [/etc/cni/net.d/87-podman-bridge.conflist] bridge cni config(s)
I1017 17:08:48.798288   28215 preload.go:132] Checking if preload exists for k8s version v1.26.1 and runtime docker
I1017 17:08:48.798398   28215 ssh_runner.go:195] Run: docker images --format {{.Repository}}:{{.Tag}}
I1017 17:08:48.812966   28215 docker.go:630] Got preloaded images: -- stdout --
nginx:1.25
nginx:latest
postgres:latest
registry.k8s.io/kube-apiserver:v1.26.1
registry.k8s.io/kube-proxy:v1.26.1
registry.k8s.io/kube-controller-manager:v1.26.1
registry.k8s.io/kube-scheduler:v1.26.1
registry.k8s.io/etcd:3.5.6-0
registry.k8s.io/pause:3.9
registry.k8s.io/coredns/coredns:v1.9.3
registry.k8s.io/pause:3.6
ashujauhari/ij005-emp:latest
gcr.io/k8s-minikube/storage-provisioner:v5
ashujauhari/eureka:latest
nginx:1.7.1

-- /stdout --
I1017 17:08:48.813235   28215 docker.go:560] Images already preloaded, skipping extraction
I1017 17:08:48.813421   28215 start.go:483] detecting cgroup driver to use...
I1017 17:08:48.813640   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo mkdir -p /etc && printf %!s(MISSING) "runtime-endpoint: unix:///run/containerd/containerd.sock
image-endpoint: unix:///run/containerd/containerd.sock
" | sudo tee /etc/crictl.yaml"
I1017 17:08:48.819791   28215 ssh_runner.go:195] Run: sh -c "sudo sed -i -r 's|^( *)sandbox_image = .*$|\1sandbox_image = "registry.k8s.io/pause:3.9"|' /etc/containerd/config.toml"
I1017 17:08:48.823643   28215 ssh_runner.go:195] Run: sh -c "sudo sed -i -r 's|^( *)restrict_oom_score_adj = .*$|\1restrict_oom_score_adj = false|' /etc/containerd/config.toml"
I1017 17:08:48.827140   28215 containerd.go:145] configuring containerd to use "cgroupfs" as cgroup driver...
I1017 17:08:48.827220   28215 ssh_runner.go:195] Run: sh -c "sudo sed -i -r 's|^( *)SystemdCgroup = .*$|\1SystemdCgroup = false|g' /etc/containerd/config.toml"
I1017 17:08:48.831130   28215 ssh_runner.go:195] Run: sh -c "sudo sed -i 's|"io.containerd.runtime.v1.linux"|"io.containerd.runc.v2"|g' /etc/containerd/config.toml"
I1017 17:08:48.835252   28215 ssh_runner.go:195] Run: sh -c "sudo sed -i '/systemd_cgroup/d' /etc/containerd/config.toml"
I1017 17:08:48.839402   28215 ssh_runner.go:195] Run: sh -c "sudo sed -i 's|"io.containerd.runc.v1"|"io.containerd.runc.v2"|g' /etc/containerd/config.toml"
I1017 17:08:48.843299   28215 ssh_runner.go:195] Run: sh -c "sudo rm -rf /etc/cni/net.mk"
I1017 17:08:48.847273   28215 ssh_runner.go:195] Run: sh -c "sudo sed -i -r 's|^( *)conf_dir = .*$|\1conf_dir = "/etc/cni/net.d"|g' /etc/containerd/config.toml"
I1017 17:08:48.851141   28215 ssh_runner.go:195] Run: sudo sysctl net.bridge.bridge-nf-call-iptables
I1017 17:08:48.854832   28215 ssh_runner.go:195] Run: sudo sh -c "echo 1 > /proc/sys/net/ipv4/ip_forward"
I1017 17:08:48.858680   28215 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I1017 17:08:48.933364   28215 ssh_runner.go:195] Run: sudo systemctl restart containerd
I1017 17:08:48.940962   28215 start.go:483] detecting cgroup driver to use...
I1017 17:08:48.941087   28215 ssh_runner.go:195] Run: sudo systemctl cat docker.service
I1017 17:08:48.948654   28215 ssh_runner.go:195] Run: sudo systemctl is-active --quiet service containerd
I1017 17:08:48.955182   28215 ssh_runner.go:195] Run: sudo systemctl stop -f containerd
I1017 17:08:48.963940   28215 ssh_runner.go:195] Run: sudo systemctl is-active --quiet service containerd
I1017 17:08:48.970275   28215 ssh_runner.go:195] Run: sudo systemctl is-active --quiet service crio
I1017 17:08:48.976971   28215 ssh_runner.go:195] Run: sudo systemctl stop -f crio
I1017 17:08:49.022161   28215 ssh_runner.go:195] Run: sudo systemctl is-active --quiet service crio
I1017 17:08:49.028377   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo mkdir -p /etc && printf %!s(MISSING) "runtime-endpoint: unix:///var/run/cri-dockerd.sock
image-endpoint: unix:///var/run/cri-dockerd.sock
" | sudo tee /etc/crictl.yaml"
I1017 17:08:49.035084   28215 ssh_runner.go:195] Run: sudo systemctl unmask docker.service
I1017 17:08:49.111486   28215 ssh_runner.go:195] Run: sudo systemctl enable docker.socket
I1017 17:08:49.188749   28215 docker.go:529] configuring docker to use "cgroupfs" as cgroup driver...
I1017 17:08:49.188760   28215 ssh_runner.go:362] scp memory --> /etc/docker/daemon.json (144 bytes)
I1017 17:08:49.195850   28215 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I1017 17:08:49.275333   28215 ssh_runner.go:195] Run: sudo systemctl restart docker
I1017 17:08:50.538953   28215 ssh_runner.go:235] Completed: sudo systemctl restart docker: (1.263606875s)
I1017 17:08:50.539033   28215 ssh_runner.go:195] Run: sudo systemctl enable cri-docker.socket
I1017 17:08:50.608879   28215 ssh_runner.go:195] Run: sudo systemctl unmask cri-docker.socket
I1017 17:08:50.687586   28215 ssh_runner.go:195] Run: sudo systemctl enable cri-docker.socket
I1017 17:08:50.766641   28215 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I1017 17:08:50.847888   28215 ssh_runner.go:195] Run: sudo systemctl restart cri-docker.socket
I1017 17:08:50.857615   28215 start.go:530] Will wait 60s for socket path /var/run/cri-dockerd.sock
I1017 17:08:50.858590   28215 ssh_runner.go:195] Run: stat /var/run/cri-dockerd.sock
I1017 17:08:50.861693   28215 start.go:551] Will wait 60s for crictl version
I1017 17:08:50.861972   28215 ssh_runner.go:195] Run: which crictl
I1017 17:08:50.865533   28215 ssh_runner.go:195] Run: sudo /usr/bin/crictl version
I1017 17:08:50.909158   28215 start.go:567] Version:  0.1.0
RuntimeName:  docker
RuntimeVersion:  20.10.23
RuntimeApiVersion:  v1alpha2
I1017 17:08:50.909255   28215 ssh_runner.go:195] Run: docker version --format {{.Server.Version}}
I1017 17:08:50.928936   28215 ssh_runner.go:195] Run: docker version --format {{.Server.Version}}
I1017 17:08:50.967669   28215 out.go:204] 🐳  Preparing Kubernetes v1.26.1 on Docker 20.10.23 ...
I1017 17:08:50.968388   28215 ssh_runner.go:195] Run: grep 10.0.2.2	host.minikube.internal$ /etc/hosts
I1017 17:08:50.970262   28215 ssh_runner.go:195] Run: /bin/bash -c "{ grep -v $'\thost.minikube.internal$' "/etc/hosts"; echo "10.0.2.2	host.minikube.internal"; } > /tmp/h.$$; sudo cp /tmp/h.$$ "/etc/hosts""
I1017 17:08:50.975205   28215 preload.go:132] Checking if preload exists for k8s version v1.26.1 and runtime docker
I1017 17:08:50.975286   28215 ssh_runner.go:195] Run: docker images --format {{.Repository}}:{{.Tag}}
I1017 17:08:50.985122   28215 docker.go:630] Got preloaded images: -- stdout --
nginx:1.25
nginx:latest
postgres:latest
registry.k8s.io/kube-apiserver:v1.26.1
registry.k8s.io/kube-controller-manager:v1.26.1
registry.k8s.io/kube-proxy:v1.26.1
registry.k8s.io/kube-scheduler:v1.26.1
registry.k8s.io/etcd:3.5.6-0
registry.k8s.io/pause:3.9
registry.k8s.io/coredns/coredns:v1.9.3
registry.k8s.io/pause:3.6
ashujauhari/ij005-emp:latest
gcr.io/k8s-minikube/storage-provisioner:v5
ashujauhari/eureka:latest
nginx:1.7.1

-- /stdout --
I1017 17:08:50.985129   28215 docker.go:560] Images already preloaded, skipping extraction
I1017 17:08:50.985604   28215 ssh_runner.go:195] Run: docker images --format {{.Repository}}:{{.Tag}}
I1017 17:08:50.996490   28215 docker.go:630] Got preloaded images: -- stdout --
nginx:1.25
nginx:latest
postgres:latest
registry.k8s.io/kube-apiserver:v1.26.1
registry.k8s.io/kube-proxy:v1.26.1
registry.k8s.io/kube-controller-manager:v1.26.1
registry.k8s.io/kube-scheduler:v1.26.1
registry.k8s.io/etcd:3.5.6-0
registry.k8s.io/pause:3.9
registry.k8s.io/coredns/coredns:v1.9.3
registry.k8s.io/pause:3.6
ashujauhari/ij005-emp:latest
gcr.io/k8s-minikube/storage-provisioner:v5
ashujauhari/eureka:latest
nginx:1.7.1

-- /stdout --
I1017 17:08:50.996497   28215 cache_images.go:84] Images are preloaded, skipping loading
I1017 17:08:50.996823   28215 ssh_runner.go:195] Run: docker info --format {{.CgroupDriver}}
I1017 17:08:51.010905   28215 cni.go:84] Creating CNI manager for ""
I1017 17:08:51.010915   28215 cni.go:157] "qemu2" driver + "docker" container runtime found on kubernetes v1.24+, recommending bridge
I1017 17:08:51.011182   28215 kubeadm.go:87] Using pod CIDR: 10.244.0.0/16
I1017 17:08:51.011200   28215 kubeadm.go:172] kubeadm options: {CertDir:/var/lib/minikube/certs ServiceCIDR:10.96.0.0/12 PodSubnet:10.244.0.0/16 AdvertiseAddress:10.0.2.15 APIServerPort:8443 KubernetesVersion:v1.26.1 EtcdDataDir:/var/lib/minikube/etcd EtcdExtraArgs:map[] ClusterName:minikube NodeName:minikube DNSDomain:cluster.local CRISocket:/var/run/cri-dockerd.sock ImageRepository: ComponentOptions:[{Component:apiServer ExtraArgs:map[enable-admission-plugins:NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,MutatingAdmissionWebhook,ValidatingAdmissionWebhook,ResourceQuota] Pairs:map[certSANs:["127.0.0.1", "localhost", "10.0.2.15"]]} {Component:controllerManager ExtraArgs:map[allocate-node-cidrs:true leader-elect:false] Pairs:map[]} {Component:scheduler ExtraArgs:map[leader-elect:false] Pairs:map[]}] FeatureArgs:map[] NodeIP:10.0.2.15 CgroupDriver:cgroupfs ClientCAFile:/var/lib/minikube/certs/ca.crt StaticPodPath:/etc/kubernetes/manifests ControlPlaneAddress:control-plane.minikube.internal KubeProxyOptions:map[] ResolvConfSearchRegression:false KubeletConfigOpts:map[hairpinMode:hairpin-veth runtimeRequestTimeout:15m]}
I1017 17:08:51.011332   28215 kubeadm.go:177] kubeadm config:
apiVersion: kubeadm.k8s.io/v1beta3
kind: InitConfiguration
localAPIEndpoint:
  advertiseAddress: 10.0.2.15
  bindPort: 8443
bootstrapTokens:
  - groups:
      - system:bootstrappers:kubeadm:default-node-token
    ttl: 24h0m0s
    usages:
      - signing
      - authentication
nodeRegistration:
  criSocket: /var/run/cri-dockerd.sock
  name: "minikube"
  kubeletExtraArgs:
    node-ip: 10.0.2.15
  taints: []
---
apiVersion: kubeadm.k8s.io/v1beta3
kind: ClusterConfiguration
apiServer:
  certSANs: ["127.0.0.1", "localhost", "10.0.2.15"]
  extraArgs:
    enable-admission-plugins: "NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,MutatingAdmissionWebhook,ValidatingAdmissionWebhook,ResourceQuota"
controllerManager:
  extraArgs:
    allocate-node-cidrs: "true"
    leader-elect: "false"
scheduler:
  extraArgs:
    leader-elect: "false"
certificatesDir: /var/lib/minikube/certs
clusterName: mk
controlPlaneEndpoint: control-plane.minikube.internal:8443
etcd:
  local:
    dataDir: /var/lib/minikube/etcd
    extraArgs:
      proxy-refresh-interval: "70000"
kubernetesVersion: v1.26.1
networking:
  dnsDomain: cluster.local
  podSubnet: "10.244.0.0/16"
  serviceSubnet: 10.96.0.0/12
---
apiVersion: kubelet.config.k8s.io/v1beta1
kind: KubeletConfiguration
authentication:
  x509:
    clientCAFile: /var/lib/minikube/certs/ca.crt
cgroupDriver: cgroupfs
hairpinMode: hairpin-veth
runtimeRequestTimeout: 15m
clusterDomain: "cluster.local"
# disable disk resource management by default
imageGCHighThresholdPercent: 100
evictionHard:
  nodefs.available: "0%!"(MISSING)
  nodefs.inodesFree: "0%!"(MISSING)
  imagefs.available: "0%!"(MISSING)
failSwapOn: false
staticPodPath: /etc/kubernetes/manifests
---
apiVersion: kubeproxy.config.k8s.io/v1alpha1
kind: KubeProxyConfiguration
clusterCIDR: "10.244.0.0/16"
metricsBindAddress: 0.0.0.0:10249
conntrack:
  maxPerCore: 0
# Skip setting "net.netfilter.nf_conntrack_tcp_timeout_established"
  tcpEstablishedTimeout: 0s
# Skip setting "net.netfilter.nf_conntrack_tcp_timeout_close"
  tcpCloseWaitTimeout: 0s

I1017 17:08:51.011394   28215 kubeadm.go:968] kubelet [Unit]
Wants=docker.socket

[Service]
ExecStart=
ExecStart=/var/lib/minikube/binaries/v1.26.1/kubelet --bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --config=/var/lib/kubelet/config.yaml --container-runtime=remote --container-runtime-endpoint=/var/run/cri-dockerd.sock --hostname-override=minikube --image-service-endpoint=/var/run/cri-dockerd.sock --kubeconfig=/etc/kubernetes/kubelet.conf --node-ip=10.0.2.15

[Install]
 config:
{KubernetesVersion:v1.26.1 ClusterName:minikube Namespace:default APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI: NodeIP: NodePort:8443 NodeName:}
I1017 17:08:51.011565   28215 ssh_runner.go:195] Run: sudo ls /var/lib/minikube/binaries/v1.26.1
I1017 17:08:51.016742   28215 binaries.go:44] Found k8s binaries, skipping transfer
I1017 17:08:51.016846   28215 ssh_runner.go:195] Run: sudo mkdir -p /etc/systemd/system/kubelet.service.d /lib/systemd/system /var/tmp/minikube
I1017 17:08:51.020981   28215 ssh_runner.go:362] scp memory --> /etc/systemd/system/kubelet.service.d/10-kubeadm.conf (437 bytes)
I1017 17:08:51.028038   28215 ssh_runner.go:362] scp memory --> /lib/systemd/system/kubelet.service (352 bytes)
I1017 17:08:51.035924   28215 ssh_runner.go:362] scp memory --> /var/tmp/minikube/kubeadm.yaml.new (2075 bytes)
I1017 17:08:51.043687   28215 ssh_runner.go:195] Run: grep 10.0.2.15	control-plane.minikube.internal$ /etc/hosts
I1017 17:08:51.045368   28215 ssh_runner.go:195] Run: /bin/bash -c "{ grep -v $'\tcontrol-plane.minikube.internal$' "/etc/hosts"; echo "10.0.2.15	control-plane.minikube.internal"; } > /tmp/h.$$; sudo cp /tmp/h.$$ "/etc/hosts""
I1017 17:08:51.050443   28215 certs.go:56] Setting up /Users/ashujauhari/.minikube/profiles/minikube for IP: 10.0.2.15
I1017 17:08:51.050457   28215 certs.go:186] acquiring lock for shared ca certs: {Name:mk55416ec21892f30b1abaaf322c0d822baf0e41 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I1017 17:08:51.050747   28215 certs.go:195] skipping minikubeCA CA generation: /Users/ashujauhari/.minikube/ca.key
I1017 17:08:51.050907   28215 certs.go:195] skipping proxyClientCA CA generation: /Users/ashujauhari/.minikube/proxy-client-ca.key
I1017 17:08:51.051139   28215 certs.go:311] skipping minikube-user signed cert generation: /Users/ashujauhari/.minikube/profiles/minikube/client.key
I1017 17:08:51.051330   28215 certs.go:311] skipping minikube signed cert generation: /Users/ashujauhari/.minikube/profiles/minikube/apiserver.key.49504c3e
I1017 17:08:51.051523   28215 certs.go:311] skipping aggregator signed cert generation: /Users/ashujauhari/.minikube/profiles/minikube/proxy-client.key
I1017 17:08:51.051706   28215 certs.go:401] found cert: /Users/ashujauhari/.minikube/certs/Users/ashujauhari/.minikube/certs/ca-key.pem (1675 bytes)
I1017 17:08:51.051734   28215 certs.go:401] found cert: /Users/ashujauhari/.minikube/certs/Users/ashujauhari/.minikube/certs/ca.pem (1090 bytes)
I1017 17:08:51.051758   28215 certs.go:401] found cert: /Users/ashujauhari/.minikube/certs/Users/ashujauhari/.minikube/certs/cert.pem (1135 bytes)
I1017 17:08:51.051780   28215 certs.go:401] found cert: /Users/ashujauhari/.minikube/certs/Users/ashujauhari/.minikube/certs/key.pem (1679 bytes)
I1017 17:08:51.053586   28215 ssh_runner.go:362] scp /Users/ashujauhari/.minikube/profiles/minikube/apiserver.crt --> /var/lib/minikube/certs/apiserver.crt (1399 bytes)
I1017 17:08:51.063513   28215 ssh_runner.go:362] scp /Users/ashujauhari/.minikube/profiles/minikube/apiserver.key --> /var/lib/minikube/certs/apiserver.key (1679 bytes)
I1017 17:08:51.075038   28215 ssh_runner.go:362] scp /Users/ashujauhari/.minikube/profiles/minikube/proxy-client.crt --> /var/lib/minikube/certs/proxy-client.crt (1147 bytes)
I1017 17:08:51.084825   28215 ssh_runner.go:362] scp /Users/ashujauhari/.minikube/profiles/minikube/proxy-client.key --> /var/lib/minikube/certs/proxy-client.key (1675 bytes)
I1017 17:08:51.094510   28215 ssh_runner.go:362] scp /Users/ashujauhari/.minikube/ca.crt --> /var/lib/minikube/certs/ca.crt (1111 bytes)
I1017 17:08:51.105233   28215 ssh_runner.go:362] scp /Users/ashujauhari/.minikube/ca.key --> /var/lib/minikube/certs/ca.key (1675 bytes)
I1017 17:08:51.115366   28215 ssh_runner.go:362] scp /Users/ashujauhari/.minikube/proxy-client-ca.crt --> /var/lib/minikube/certs/proxy-client-ca.crt (1119 bytes)
I1017 17:08:51.125824   28215 ssh_runner.go:362] scp /Users/ashujauhari/.minikube/proxy-client-ca.key --> /var/lib/minikube/certs/proxy-client-ca.key (1675 bytes)
I1017 17:08:51.135352   28215 ssh_runner.go:362] scp /Users/ashujauhari/.minikube/ca.crt --> /usr/share/ca-certificates/minikubeCA.pem (1111 bytes)
I1017 17:08:51.144911   28215 ssh_runner.go:362] scp memory --> /var/lib/minikube/kubeconfig (738 bytes)
I1017 17:08:51.152805   28215 ssh_runner.go:195] Run: openssl version
I1017 17:08:51.155858   28215 ssh_runner.go:195] Run: sudo /bin/bash -c "test -s /usr/share/ca-certificates/minikubeCA.pem && ln -fs /usr/share/ca-certificates/minikubeCA.pem /etc/ssl/certs/minikubeCA.pem"
I1017 17:08:51.160266   28215 ssh_runner.go:195] Run: ls -la /usr/share/ca-certificates/minikubeCA.pem
I1017 17:08:51.162149   28215 certs.go:444] hashing: -rw-r--r-- 1 root root 1111 Jun  9  2022 /usr/share/ca-certificates/minikubeCA.pem
I1017 17:08:51.162188   28215 ssh_runner.go:195] Run: openssl x509 -hash -noout -in /usr/share/ca-certificates/minikubeCA.pem
I1017 17:08:51.164784   28215 ssh_runner.go:195] Run: sudo /bin/bash -c "test -L /etc/ssl/certs/b5213941.0 || ln -fs /etc/ssl/certs/minikubeCA.pem /etc/ssl/certs/b5213941.0"
I1017 17:08:51.168954   28215 kubeadm.go:401] StartCluster: {Name:minikube KeepContext:false EmbedCerts:false MinikubeISO:https://storage.googleapis.com/minikube/iso/minikube-v1.29.0-arm64.iso KicBaseImage:gcr.io/k8s-minikube/kicbase:v0.0.37@sha256:8bf7a0e8a062bc5e2b71d28b35bfa9cc862d9220e234e86176b3785f685d8b15 Memory:4000 CPUs:2 DiskSize:20000 VMDriver: Driver:qemu2 HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[] ContainerVolumeMounts:[] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.59.1/24 HypervVirtualSwitch: HypervUseExternalSwitch:false HypervExternalAdapter: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false KVMNUMACount:1 APIServerPort:49338 DockerOpt:[] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:false DNSProxy:false HostDNSResolver:true HostOnlyNicType:virtio NatNicType:virtio SSHIPAddress: SSHUser:root SSHKey: SSHPort:22 KubernetesConfig:{KubernetesVersion:v1.26.1 ClusterName:minikube Namespace:default APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI: NodeIP: NodePort:8443 NodeName:} Nodes:[{Name: IP:10.0.2.15 Port:8443 KubernetesVersion:v1.26.1 ContainerRuntime:docker ControlPlane:true Worker:true}] Addons:map[default-storageclass:true storage-provisioner:true] CustomAddonImages:map[] CustomAddonRegistries:map[] VerifyComponents:map[apiserver:true system_pods:true] StartHostTimeout:6m0s ScheduledStop:<nil> ExposedPorts:[] ListenAddress: Network:socket_vmnet Subnet: MultiNodeRequested:false ExtraDisks:0 CertExpiration:26280h0m0s Mount:false MountString:/Users:/minikube-host Mount9PVersion:9p2000.L MountGID:docker MountIP: MountMSize:262144 MountOptions:[] MountPort:0 MountType:9p MountUID:docker BinaryMirror: DisableOptimizations:false DisableMetrics:false CustomQemuFirmwarePath: SocketVMnetClientPath: SocketVMnetPath: StaticIP:}
I1017 17:08:51.169097   28215 ssh_runner.go:195] Run: docker ps --filter status=paused --filter=name=k8s_.*_(kube-system)_ --format={{.ID}}
I1017 17:08:51.180614   28215 ssh_runner.go:195] Run: sudo ls /var/lib/kubelet/kubeadm-flags.env /var/lib/kubelet/config.yaml /var/lib/minikube/etcd
I1017 17:08:51.185284   28215 host.go:66] Checking if "minikube" exists ...
I1017 17:08:51.186511   28215 main.go:141] libmachine: Using SSH client type: external
I1017 17:08:51.186532   28215 main.go:141] libmachine: Using SSH private key: /Users/ashujauhari/.minikube/machines/minikube/id_rsa (-rw-------)
I1017 17:08:51.186557   28215 main.go:141] libmachine: &{[-F /dev/null -o ConnectionAttempts=3 -o ConnectTimeout=10 -o ControlMaster=no -o ControlPath=none -o LogLevel=quiet -o PasswordAuthentication=no -o ServerAliveInterval=60 -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null docker@localhost -o IdentitiesOnly=yes -i /Users/ashujauhari/.minikube/machines/minikube/id_rsa -p 55250] /usr/bin/ssh <nil>}
I1017 17:08:51.186573   28215 main.go:141] libmachine: /usr/bin/ssh -F /dev/null -o ConnectionAttempts=3 -o ConnectTimeout=10 -o ControlMaster=no -o ControlPath=none -o LogLevel=quiet -o PasswordAuthentication=no -o ServerAliveInterval=60 -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null docker@localhost -o IdentitiesOnly=yes -i /Users/ashujauhari/.minikube/machines/minikube/id_rsa -p 55250 -f -NTL 49338:localhost:8443
I1017 17:08:51.280295   28215 kubeadm.go:416] found existing configuration files, will attempt cluster restart
I1017 17:08:51.280315   28215 kubeadm.go:633] restartCluster start
I1017 17:08:51.280443   28215 ssh_runner.go:195] Run: sudo test -d /data/minikube
I1017 17:08:51.285435   28215 kubeadm.go:127] /data/minikube skipping compat symlinks: sudo test -d /data/minikube: Process exited with status 1
stdout:

stderr:
I1017 17:08:51.287053   28215 kubeconfig.go:135] verify returned: extract IP: "minikube" does not appear in /Users/ashujauhari/.kube/config
I1017 17:08:51.287791   28215 kubeconfig.go:146] "minikube" context is missing from /Users/ashujauhari/.kube/config - will repair!
I1017 17:08:51.288828   28215 lock.go:35] WriteFile acquiring /Users/ashujauhari/.kube/config: {Name:mke38aee53c70a24ab9bd1ba88bb9a09437bd913 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I1017 17:08:51.295483   28215 ssh_runner.go:195] Run: sudo diff -u /var/tmp/minikube/kubeadm.yaml /var/tmp/minikube/kubeadm.yaml.new
I1017 17:08:51.300012   28215 api_server.go:165] Checking apiserver status ...
I1017 17:08:51.300108   28215 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W1017 17:08:51.304741   28215 api_server.go:169] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I1017 17:08:51.805389   28215 api_server.go:165] Checking apiserver status ...
I1017 17:08:51.805551   28215 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W1017 17:08:51.815501   28215 api_server.go:169] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I1017 17:08:52.307921   28215 api_server.go:165] Checking apiserver status ...
I1017 17:08:52.308079   28215 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W1017 17:08:52.318534   28215 api_server.go:169] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I1017 17:08:52.809748   28215 api_server.go:165] Checking apiserver status ...
I1017 17:08:52.810002   28215 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W1017 17:08:52.819522   28215 api_server.go:169] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I1017 17:08:53.307950   28215 api_server.go:165] Checking apiserver status ...
I1017 17:08:53.308102   28215 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W1017 17:08:53.315648   28215 api_server.go:169] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I1017 17:08:53.807792   28215 api_server.go:165] Checking apiserver status ...
I1017 17:08:53.808021   28215 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W1017 17:08:53.819590   28215 api_server.go:169] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I1017 17:08:54.306513   28215 api_server.go:165] Checking apiserver status ...
I1017 17:08:54.306705   28215 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W1017 17:08:54.318013   28215 api_server.go:169] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I1017 17:08:54.808000   28215 api_server.go:165] Checking apiserver status ...
I1017 17:08:54.808156   28215 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W1017 17:08:54.821043   28215 api_server.go:169] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I1017 17:08:55.309876   28215 api_server.go:165] Checking apiserver status ...
I1017 17:08:55.310044   28215 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W1017 17:08:55.320010   28215 api_server.go:169] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I1017 17:08:55.808028   28215 api_server.go:165] Checking apiserver status ...
I1017 17:08:55.808227   28215 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W1017 17:08:55.817749   28215 api_server.go:169] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I1017 17:08:56.308860   28215 api_server.go:165] Checking apiserver status ...
I1017 17:08:56.308948   28215 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W1017 17:08:56.313189   28215 api_server.go:169] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I1017 17:08:56.806396   28215 api_server.go:165] Checking apiserver status ...
I1017 17:08:56.806579   28215 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W1017 17:08:56.816541   28215 api_server.go:169] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I1017 17:08:57.305412   28215 api_server.go:165] Checking apiserver status ...
I1017 17:08:57.305614   28215 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W1017 17:08:57.316144   28215 api_server.go:169] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I1017 17:08:57.809848   28215 api_server.go:165] Checking apiserver status ...
I1017 17:08:57.810040   28215 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W1017 17:08:57.820199   28215 api_server.go:169] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I1017 17:08:58.307877   28215 api_server.go:165] Checking apiserver status ...
I1017 17:08:58.308143   28215 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W1017 17:08:58.319644   28215 api_server.go:169] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I1017 17:08:58.807497   28215 api_server.go:165] Checking apiserver status ...
I1017 17:08:58.807818   28215 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W1017 17:08:58.814115   28215 api_server.go:169] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I1017 17:08:59.309997   28215 api_server.go:165] Checking apiserver status ...
I1017 17:08:59.310665   28215 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W1017 17:08:59.317331   28215 api_server.go:169] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I1017 17:08:59.807808   28215 api_server.go:165] Checking apiserver status ...
I1017 17:08:59.807986   28215 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W1017 17:08:59.818433   28215 api_server.go:169] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I1017 17:09:00.305646   28215 api_server.go:165] Checking apiserver status ...
I1017 17:09:00.305829   28215 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W1017 17:09:00.317468   28215 api_server.go:169] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I1017 17:09:00.809223   28215 api_server.go:165] Checking apiserver status ...
I1017 17:09:00.809368   28215 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W1017 17:09:00.819807   28215 api_server.go:169] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I1017 17:09:01.306250   28215 api_server.go:165] Checking apiserver status ...
I1017 17:09:01.306427   28215 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W1017 17:09:01.313304   28215 api_server.go:169] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I1017 17:09:01.313311   28215 api_server.go:165] Checking apiserver status ...
I1017 17:09:01.313394   28215 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W1017 17:09:01.317192   28215 api_server.go:169] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I1017 17:09:01.317200   28215 kubeadm.go:608] needs reconfigure: apiserver error: timed out waiting for the condition
I1017 17:09:01.317202   28215 kubeadm.go:1120] stopping kube-system containers ...
I1017 17:09:01.317292   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_.*_(kube-system)_ --format={{.ID}}
I1017 17:09:01.327195   28215 docker.go:456] Stopping containers: [23cfc6ab0d6d 9d8ce9c34f4f 960681dbb24d 87638495abba b069ae6fcb01 793d0a98cfba 067e7d061ba4 d7899b5676a6 6a34f72dcdc3 1dd1bf4d5a41 4baec2e22148 08d1c1430a8f 62fc315153cd 70abb5e2d7cc e5543621a743 2cd7727dc0fc 2881f492acf4 970ddb070425 e3619bd375ba 8aee8ef988cf fdf4d51f5493 022276dadb0b 37bd131352a5 f5018e1258f1 21f096461b77 4f0badf4785a a31194574d67]
I1017 17:09:01.327343   28215 ssh_runner.go:195] Run: docker stop 23cfc6ab0d6d 9d8ce9c34f4f 960681dbb24d 87638495abba b069ae6fcb01 793d0a98cfba 067e7d061ba4 d7899b5676a6 6a34f72dcdc3 1dd1bf4d5a41 4baec2e22148 08d1c1430a8f 62fc315153cd 70abb5e2d7cc e5543621a743 2cd7727dc0fc 2881f492acf4 970ddb070425 e3619bd375ba 8aee8ef988cf fdf4d51f5493 022276dadb0b 37bd131352a5 f5018e1258f1 21f096461b77 4f0badf4785a a31194574d67
I1017 17:09:01.337803   28215 ssh_runner.go:195] Run: sudo systemctl stop kubelet
I1017 17:09:01.344929   28215 ssh_runner.go:195] Run: sudo ls -la /etc/kubernetes/admin.conf /etc/kubernetes/kubelet.conf /etc/kubernetes/controller-manager.conf /etc/kubernetes/scheduler.conf
I1017 17:09:01.348071   28215 kubeadm.go:152] config check failed, skipping stale config cleanup: sudo ls -la /etc/kubernetes/admin.conf /etc/kubernetes/kubelet.conf /etc/kubernetes/controller-manager.conf /etc/kubernetes/scheduler.conf: Process exited with status 2
stdout:

stderr:
ls: cannot access '/etc/kubernetes/admin.conf': No such file or directory
ls: cannot access '/etc/kubernetes/kubelet.conf': No such file or directory
ls: cannot access '/etc/kubernetes/controller-manager.conf': No such file or directory
ls: cannot access '/etc/kubernetes/scheduler.conf': No such file or directory
I1017 17:09:01.348151   28215 ssh_runner.go:195] Run: sudo cp /var/tmp/minikube/kubeadm.yaml.new /var/tmp/minikube/kubeadm.yaml
I1017 17:09:01.351407   28215 kubeadm.go:710] reconfiguring cluster from /var/tmp/minikube/kubeadm.yaml
I1017 17:09:01.351413   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.26.1:$PATH" kubeadm init phase certs all --config /var/tmp/minikube/kubeadm.yaml"
I1017 17:09:01.447836   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.26.1:$PATH" kubeadm init phase kubeconfig all --config /var/tmp/minikube/kubeadm.yaml"
I1017 17:09:01.982120   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.26.1:$PATH" kubeadm init phase kubelet-start --config /var/tmp/minikube/kubeadm.yaml"
I1017 17:09:02.101153   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.26.1:$PATH" kubeadm init phase control-plane all --config /var/tmp/minikube/kubeadm.yaml"
I1017 17:09:02.135024   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.26.1:$PATH" kubeadm init phase etcd local --config /var/tmp/minikube/kubeadm.yaml"
I1017 17:09:02.170903   28215 api_server.go:51] waiting for apiserver process to appear ...
I1017 17:09:02.171004   28215 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I1017 17:09:02.682069   28215 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I1017 17:09:03.182051   28215 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I1017 17:09:03.682029   28215 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I1017 17:09:04.182097   28215 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I1017 17:09:04.682127   28215 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I1017 17:09:04.692675   28215 api_server.go:71] duration metric: took 2.521778917s to wait for apiserver process to appear ...
I1017 17:09:04.692687   28215 api_server.go:87] waiting for apiserver healthz status ...
I1017 17:09:04.692693   28215 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I1017 17:09:09.698013   28215 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I1017 17:09:10.199925   28215 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I1017 17:09:15.200660   28215 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I1017 17:09:15.200743   28215 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I1017 17:09:20.201885   28215 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I1017 17:09:20.699959   28215 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I1017 17:09:25.700669   28215 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I1017 17:09:26.199817   28215 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I1017 17:09:31.200429   28215 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I1017 17:09:31.200453   28215 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I1017 17:09:36.202482   28215 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I1017 17:09:36.202498   28215 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I1017 17:09:41.202912   28215 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I1017 17:09:41.701751   28215 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I1017 17:09:46.702450   28215 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": dial tcp 10.0.2.15:8443: i/o timeout (Client.Timeout exceeded while awaiting headers)
I1017 17:09:47.201626   28215 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I1017 17:09:52.203007   28215 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I1017 17:09:52.701255   28215 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I1017 17:09:57.703039   28215 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I1017 17:09:58.202709   28215 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I1017 17:10:03.202971   28215 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I1017 17:10:03.702953   28215 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I1017 17:10:08.707278   28215 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I1017 17:10:09.199188   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I1017 17:10:09.222366   28215 logs.go:279] 2 containers: [a4953fa9a9a9 793d0a98cfba]
I1017 17:10:09.222491   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I1017 17:10:09.232728   28215 logs.go:279] 2 containers: [d68a4772ec61 87638495abba]
I1017 17:10:09.232820   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I1017 17:10:09.241940   28215 logs.go:279] 1 containers: [9d8ce9c34f4f]
I1017 17:10:09.242054   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I1017 17:10:09.252016   28215 logs.go:279] 2 containers: [f4a15e9e42a9 d7899b5676a6]
I1017 17:10:09.252123   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I1017 17:10:09.262073   28215 logs.go:279] 2 containers: [7683deae11fa 067e7d061ba4]
I1017 17:10:09.262202   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I1017 17:10:09.275460   28215 logs.go:279] 0 containers: []
W1017 17:10:09.275469   28215 logs.go:281] No container was found matching "kubernetes-dashboard"
I1017 17:10:09.275561   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I1017 17:10:09.285125   28215 logs.go:279] 2 containers: [7b133da22f8c a898719c42cf]
I1017 17:10:09.285238   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I1017 17:10:09.295543   28215 logs.go:279] 2 containers: [9d5cc400d287 b069ae6fcb01]
I1017 17:10:09.295556   28215 logs.go:124] Gathering logs for kube-scheduler [f4a15e9e42a9] ...
I1017 17:10:09.295561   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f4a15e9e42a9"
I1017 17:10:09.307857   28215 logs.go:124] Gathering logs for kube-controller-manager [b069ae6fcb01] ...
I1017 17:10:09.307866   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b069ae6fcb01"
I1017 17:10:09.329328   28215 logs.go:124] Gathering logs for Docker ...
I1017 17:10:09.329339   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I1017 17:10:09.352625   28215 logs.go:124] Gathering logs for kube-apiserver [a4953fa9a9a9] ...
I1017 17:10:09.352635   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a4953fa9a9a9"
I1017 17:10:09.368044   28215 logs.go:124] Gathering logs for kube-apiserver [793d0a98cfba] ...
I1017 17:10:09.368064   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 793d0a98cfba"
I1017 17:10:09.391957   28215 logs.go:124] Gathering logs for etcd [87638495abba] ...
I1017 17:10:09.391968   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 87638495abba"
I1017 17:10:09.409885   28215 logs.go:124] Gathering logs for dmesg ...
I1017 17:10:09.409922   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I1017 17:10:09.416977   28215 logs.go:124] Gathering logs for kube-proxy [7683deae11fa] ...
I1017 17:10:09.416987   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7683deae11fa"
I1017 17:10:09.430945   28215 logs.go:124] Gathering logs for container status ...
I1017 17:10:09.430957   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I1017 17:10:09.459638   28215 logs.go:124] Gathering logs for coredns [9d8ce9c34f4f] ...
I1017 17:10:09.459648   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9d8ce9c34f4f"
I1017 17:10:09.472016   28215 logs.go:124] Gathering logs for storage-provisioner [7b133da22f8c] ...
I1017 17:10:09.472025   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7b133da22f8c"
I1017 17:10:09.485029   28215 logs.go:124] Gathering logs for kube-controller-manager [9d5cc400d287] ...
I1017 17:10:09.485053   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9d5cc400d287"
I1017 17:10:09.505501   28215 logs.go:124] Gathering logs for kube-scheduler [d7899b5676a6] ...
I1017 17:10:09.505512   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d7899b5676a6"
I1017 17:10:09.519827   28215 logs.go:124] Gathering logs for kube-proxy [067e7d061ba4] ...
I1017 17:10:09.519837   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 067e7d061ba4"
I1017 17:10:09.533616   28215 logs.go:124] Gathering logs for storage-provisioner [a898719c42cf] ...
I1017 17:10:09.533626   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a898719c42cf"
I1017 17:10:09.546459   28215 logs.go:124] Gathering logs for kubelet ...
I1017 17:10:09.546469   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I1017 17:10:09.621468   28215 logs.go:124] Gathering logs for describe nodes ...
I1017 17:10:09.621487   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.26.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I1017 17:10:09.831726   28215 logs.go:124] Gathering logs for etcd [d68a4772ec61] ...
I1017 17:10:09.831737   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d68a4772ec61"
I1017 17:10:12.354611   28215 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I1017 17:10:17.355330   28215 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": dial tcp 10.0.2.15:8443: i/o timeout (Client.Timeout exceeded while awaiting headers)
I1017 17:10:17.711228   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I1017 17:10:17.729973   28215 logs.go:279] 2 containers: [a4953fa9a9a9 793d0a98cfba]
I1017 17:10:17.730077   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I1017 17:10:17.740519   28215 logs.go:279] 2 containers: [d68a4772ec61 87638495abba]
I1017 17:10:17.740640   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I1017 17:10:17.750441   28215 logs.go:279] 1 containers: [9d8ce9c34f4f]
I1017 17:10:17.750563   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I1017 17:10:17.764391   28215 logs.go:279] 2 containers: [f4a15e9e42a9 d7899b5676a6]
I1017 17:10:17.764498   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I1017 17:10:17.776290   28215 logs.go:279] 2 containers: [7683deae11fa 067e7d061ba4]
I1017 17:10:17.776393   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I1017 17:10:17.788762   28215 logs.go:279] 0 containers: []
W1017 17:10:17.788770   28215 logs.go:281] No container was found matching "kubernetes-dashboard"
I1017 17:10:17.788872   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I1017 17:10:17.802552   28215 logs.go:279] 2 containers: [7b133da22f8c a898719c42cf]
I1017 17:10:17.802663   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I1017 17:10:17.827848   28215 logs.go:279] 2 containers: [9d5cc400d287 b069ae6fcb01]
I1017 17:10:17.827864   28215 logs.go:124] Gathering logs for kube-apiserver [793d0a98cfba] ...
I1017 17:10:17.827868   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 793d0a98cfba"
I1017 17:10:17.855429   28215 logs.go:124] Gathering logs for etcd [87638495abba] ...
I1017 17:10:17.855442   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 87638495abba"
I1017 17:10:17.874876   28215 logs.go:124] Gathering logs for kube-proxy [7683deae11fa] ...
I1017 17:10:17.874886   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7683deae11fa"
I1017 17:10:17.887510   28215 logs.go:124] Gathering logs for kube-proxy [067e7d061ba4] ...
I1017 17:10:17.887520   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 067e7d061ba4"
I1017 17:10:17.903637   28215 logs.go:124] Gathering logs for storage-provisioner [a898719c42cf] ...
I1017 17:10:17.903648   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a898719c42cf"
I1017 17:10:17.917595   28215 logs.go:124] Gathering logs for container status ...
I1017 17:10:17.917605   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I1017 17:10:17.941077   28215 logs.go:124] Gathering logs for kubelet ...
I1017 17:10:17.941088   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I1017 17:10:18.028014   28215 logs.go:124] Gathering logs for dmesg ...
I1017 17:10:18.028036   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I1017 17:10:18.036494   28215 logs.go:124] Gathering logs for kube-controller-manager [b069ae6fcb01] ...
I1017 17:10:18.036506   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b069ae6fcb01"
I1017 17:10:18.062678   28215 logs.go:124] Gathering logs for kube-controller-manager [9d5cc400d287] ...
I1017 17:10:18.062692   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9d5cc400d287"
I1017 17:10:18.086834   28215 logs.go:124] Gathering logs for Docker ...
I1017 17:10:18.086851   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I1017 17:10:18.116726   28215 logs.go:124] Gathering logs for etcd [d68a4772ec61] ...
I1017 17:10:18.116742   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d68a4772ec61"
I1017 17:10:18.140091   28215 logs.go:124] Gathering logs for storage-provisioner [7b133da22f8c] ...
I1017 17:10:18.140105   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7b133da22f8c"
I1017 17:10:18.155691   28215 logs.go:124] Gathering logs for coredns [9d8ce9c34f4f] ...
I1017 17:10:18.155702   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9d8ce9c34f4f"
I1017 17:10:18.171336   28215 logs.go:124] Gathering logs for kube-scheduler [f4a15e9e42a9] ...
I1017 17:10:18.171353   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f4a15e9e42a9"
I1017 17:10:18.193954   28215 logs.go:124] Gathering logs for kube-scheduler [d7899b5676a6] ...
I1017 17:10:18.193966   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d7899b5676a6"
I1017 17:10:18.210899   28215 logs.go:124] Gathering logs for describe nodes ...
I1017 17:10:18.210910   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.26.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I1017 17:10:18.305615   28215 logs.go:124] Gathering logs for kube-apiserver [a4953fa9a9a9] ...
I1017 17:10:18.305626   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a4953fa9a9a9"
I1017 17:10:20.831603   28215 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I1017 17:10:25.834846   28215 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I1017 17:10:26.200436   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I1017 17:10:26.214700   28215 logs.go:279] 2 containers: [a4953fa9a9a9 793d0a98cfba]
I1017 17:10:26.214813   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I1017 17:10:26.224032   28215 logs.go:279] 2 containers: [d68a4772ec61 87638495abba]
I1017 17:10:26.224163   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I1017 17:10:26.234880   28215 logs.go:279] 1 containers: [9d8ce9c34f4f]
I1017 17:10:26.234969   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I1017 17:10:26.245236   28215 logs.go:279] 2 containers: [f4a15e9e42a9 d7899b5676a6]
I1017 17:10:26.245337   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I1017 17:10:26.255623   28215 logs.go:279] 2 containers: [7683deae11fa 067e7d061ba4]
I1017 17:10:26.255771   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I1017 17:10:26.264501   28215 logs.go:279] 0 containers: []
W1017 17:10:26.264509   28215 logs.go:281] No container was found matching "kubernetes-dashboard"
I1017 17:10:26.264609   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I1017 17:10:26.287698   28215 logs.go:279] 2 containers: [7b133da22f8c a898719c42cf]
I1017 17:10:26.287798   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I1017 17:10:26.313683   28215 logs.go:279] 2 containers: [9d5cc400d287 b069ae6fcb01]
I1017 17:10:26.313707   28215 logs.go:124] Gathering logs for kubelet ...
I1017 17:10:26.313716   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I1017 17:10:26.396316   28215 logs.go:124] Gathering logs for describe nodes ...
I1017 17:10:26.396329   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.26.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I1017 17:10:26.491815   28215 logs.go:124] Gathering logs for kube-scheduler [f4a15e9e42a9] ...
I1017 17:10:26.491827   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f4a15e9e42a9"
I1017 17:10:26.509170   28215 logs.go:124] Gathering logs for storage-provisioner [7b133da22f8c] ...
I1017 17:10:26.509185   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7b133da22f8c"
I1017 17:10:26.525888   28215 logs.go:124] Gathering logs for kube-controller-manager [9d5cc400d287] ...
I1017 17:10:26.525899   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9d5cc400d287"
I1017 17:10:26.560294   28215 logs.go:124] Gathering logs for kube-controller-manager [b069ae6fcb01] ...
I1017 17:10:26.560309   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b069ae6fcb01"
I1017 17:10:26.584898   28215 logs.go:124] Gathering logs for container status ...
I1017 17:10:26.584911   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I1017 17:10:26.617220   28215 logs.go:124] Gathering logs for etcd [87638495abba] ...
I1017 17:10:26.617232   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 87638495abba"
I1017 17:10:26.637285   28215 logs.go:124] Gathering logs for kube-scheduler [d7899b5676a6] ...
I1017 17:10:26.637298   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d7899b5676a6"
I1017 17:10:26.652477   28215 logs.go:124] Gathering logs for storage-provisioner [a898719c42cf] ...
I1017 17:10:26.652488   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a898719c42cf"
I1017 17:10:26.666785   28215 logs.go:124] Gathering logs for Docker ...
I1017 17:10:26.666796   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I1017 17:10:26.693819   28215 logs.go:124] Gathering logs for dmesg ...
I1017 17:10:26.693831   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I1017 17:10:26.702077   28215 logs.go:124] Gathering logs for kube-apiserver [a4953fa9a9a9] ...
I1017 17:10:26.702088   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a4953fa9a9a9"
I1017 17:10:26.723156   28215 logs.go:124] Gathering logs for kube-apiserver [793d0a98cfba] ...
I1017 17:10:26.723169   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 793d0a98cfba"
I1017 17:10:26.749968   28215 logs.go:124] Gathering logs for etcd [d68a4772ec61] ...
I1017 17:10:26.749980   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d68a4772ec61"
I1017 17:10:26.771253   28215 logs.go:124] Gathering logs for coredns [9d8ce9c34f4f] ...
I1017 17:10:26.771265   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9d8ce9c34f4f"
I1017 17:10:26.788202   28215 logs.go:124] Gathering logs for kube-proxy [7683deae11fa] ...
I1017 17:10:26.788213   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7683deae11fa"
I1017 17:10:26.805627   28215 logs.go:124] Gathering logs for kube-proxy [067e7d061ba4] ...
I1017 17:10:26.805639   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 067e7d061ba4"
I1017 17:10:29.325725   28215 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I1017 17:10:34.328041   28215 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I1017 17:10:34.702292   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I1017 17:10:34.731918   28215 logs.go:279] 2 containers: [a4953fa9a9a9 793d0a98cfba]
I1017 17:10:34.732018   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I1017 17:10:34.744452   28215 logs.go:279] 2 containers: [d68a4772ec61 87638495abba]
I1017 17:10:34.744686   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I1017 17:10:34.759262   28215 logs.go:279] 1 containers: [9d8ce9c34f4f]
I1017 17:10:34.759388   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I1017 17:10:34.769751   28215 logs.go:279] 2 containers: [f4a15e9e42a9 d7899b5676a6]
I1017 17:10:34.769863   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I1017 17:10:34.779994   28215 logs.go:279] 2 containers: [7683deae11fa 067e7d061ba4]
I1017 17:10:34.780157   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I1017 17:10:34.790149   28215 logs.go:279] 0 containers: []
W1017 17:10:34.790159   28215 logs.go:281] No container was found matching "kubernetes-dashboard"
I1017 17:10:34.790291   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I1017 17:10:34.799969   28215 logs.go:279] 2 containers: [7b133da22f8c a898719c42cf]
I1017 17:10:34.800084   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I1017 17:10:34.810587   28215 logs.go:279] 2 containers: [9d5cc400d287 b069ae6fcb01]
I1017 17:10:34.810600   28215 logs.go:124] Gathering logs for kube-controller-manager [b069ae6fcb01] ...
I1017 17:10:34.810605   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b069ae6fcb01"
I1017 17:10:34.828648   28215 logs.go:124] Gathering logs for container status ...
I1017 17:10:34.828657   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I1017 17:10:34.850054   28215 logs.go:124] Gathering logs for describe nodes ...
I1017 17:10:34.850064   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.26.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I1017 17:10:34.922810   28215 logs.go:124] Gathering logs for kube-apiserver [a4953fa9a9a9] ...
I1017 17:10:34.922821   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a4953fa9a9a9"
I1017 17:10:34.939900   28215 logs.go:124] Gathering logs for kube-proxy [067e7d061ba4] ...
I1017 17:10:34.939911   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 067e7d061ba4"
I1017 17:10:34.953176   28215 logs.go:124] Gathering logs for storage-provisioner [7b133da22f8c] ...
I1017 17:10:34.953186   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7b133da22f8c"
I1017 17:10:34.966601   28215 logs.go:124] Gathering logs for storage-provisioner [a898719c42cf] ...
I1017 17:10:34.966612   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a898719c42cf"
I1017 17:10:34.979281   28215 logs.go:124] Gathering logs for kube-proxy [7683deae11fa] ...
I1017 17:10:34.979292   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7683deae11fa"
I1017 17:10:34.992964   28215 logs.go:124] Gathering logs for kubelet ...
I1017 17:10:34.992973   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I1017 17:10:35.070309   28215 logs.go:124] Gathering logs for kube-apiserver [793d0a98cfba] ...
I1017 17:10:35.070331   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 793d0a98cfba"
I1017 17:10:35.095180   28215 logs.go:124] Gathering logs for etcd [87638495abba] ...
I1017 17:10:35.095192   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 87638495abba"
I1017 17:10:35.114805   28215 logs.go:124] Gathering logs for coredns [9d8ce9c34f4f] ...
I1017 17:10:35.114818   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9d8ce9c34f4f"
I1017 17:10:35.128274   28215 logs.go:124] Gathering logs for kube-scheduler [d7899b5676a6] ...
I1017 17:10:35.128284   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d7899b5676a6"
I1017 17:10:35.142374   28215 logs.go:124] Gathering logs for dmesg ...
I1017 17:10:35.142384   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I1017 17:10:35.149892   28215 logs.go:124] Gathering logs for kube-scheduler [f4a15e9e42a9] ...
I1017 17:10:35.149902   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f4a15e9e42a9"
I1017 17:10:35.163743   28215 logs.go:124] Gathering logs for etcd [d68a4772ec61] ...
I1017 17:10:35.163753   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d68a4772ec61"
I1017 17:10:35.184671   28215 logs.go:124] Gathering logs for kube-controller-manager [9d5cc400d287] ...
I1017 17:10:35.184684   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9d5cc400d287"
I1017 17:10:35.208749   28215 logs.go:124] Gathering logs for Docker ...
I1017 17:10:35.208761   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I1017 17:10:37.739377   28215 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I1017 17:10:42.742668   28215 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I1017 17:10:43.203134   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I1017 17:10:43.237033   28215 logs.go:279] 2 containers: [a4953fa9a9a9 793d0a98cfba]
I1017 17:10:43.237125   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I1017 17:10:43.246584   28215 logs.go:279] 2 containers: [d68a4772ec61 87638495abba]
I1017 17:10:43.246679   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I1017 17:10:43.255967   28215 logs.go:279] 1 containers: [9d8ce9c34f4f]
I1017 17:10:43.256070   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I1017 17:10:43.267984   28215 logs.go:279] 2 containers: [f4a15e9e42a9 d7899b5676a6]
I1017 17:10:43.268088   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I1017 17:10:43.281875   28215 logs.go:279] 2 containers: [7683deae11fa 067e7d061ba4]
I1017 17:10:43.281976   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I1017 17:10:43.291895   28215 logs.go:279] 0 containers: []
W1017 17:10:43.291903   28215 logs.go:281] No container was found matching "kubernetes-dashboard"
I1017 17:10:43.291990   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I1017 17:10:43.310133   28215 logs.go:279] 2 containers: [7b133da22f8c a898719c42cf]
I1017 17:10:43.310235   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I1017 17:10:43.328143   28215 logs.go:279] 2 containers: [9d5cc400d287 b069ae6fcb01]
I1017 17:10:43.328157   28215 logs.go:124] Gathering logs for etcd [d68a4772ec61] ...
I1017 17:10:43.328162   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d68a4772ec61"
I1017 17:10:43.346541   28215 logs.go:124] Gathering logs for kube-proxy [067e7d061ba4] ...
I1017 17:10:43.346551   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 067e7d061ba4"
I1017 17:10:43.360388   28215 logs.go:124] Gathering logs for storage-provisioner [7b133da22f8c] ...
I1017 17:10:43.360405   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7b133da22f8c"
I1017 17:10:43.372890   28215 logs.go:124] Gathering logs for kube-controller-manager [9d5cc400d287] ...
I1017 17:10:43.372899   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9d5cc400d287"
I1017 17:10:43.391746   28215 logs.go:124] Gathering logs for kube-controller-manager [b069ae6fcb01] ...
I1017 17:10:43.391758   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b069ae6fcb01"
I1017 17:10:43.416252   28215 logs.go:124] Gathering logs for Docker ...
I1017 17:10:43.416263   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I1017 17:10:43.442286   28215 logs.go:124] Gathering logs for describe nodes ...
I1017 17:10:43.442298   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.26.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I1017 17:10:43.519539   28215 logs.go:124] Gathering logs for coredns [9d8ce9c34f4f] ...
I1017 17:10:43.519551   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9d8ce9c34f4f"
I1017 17:10:43.543797   28215 logs.go:124] Gathering logs for kube-scheduler [d7899b5676a6] ...
I1017 17:10:43.543809   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d7899b5676a6"
I1017 17:10:43.558878   28215 logs.go:124] Gathering logs for kube-proxy [7683deae11fa] ...
I1017 17:10:43.558889   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7683deae11fa"
I1017 17:10:43.573490   28215 logs.go:124] Gathering logs for storage-provisioner [a898719c42cf] ...
I1017 17:10:43.573502   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a898719c42cf"
I1017 17:10:43.588171   28215 logs.go:124] Gathering logs for dmesg ...
I1017 17:10:43.588181   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I1017 17:10:43.597182   28215 logs.go:124] Gathering logs for container status ...
I1017 17:10:43.597193   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I1017 17:10:43.635537   28215 logs.go:124] Gathering logs for etcd [87638495abba] ...
I1017 17:10:43.635549   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 87638495abba"
I1017 17:10:43.667858   28215 logs.go:124] Gathering logs for kube-apiserver [a4953fa9a9a9] ...
I1017 17:10:43.667870   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a4953fa9a9a9"
I1017 17:10:43.695707   28215 logs.go:124] Gathering logs for kube-apiserver [793d0a98cfba] ...
I1017 17:10:43.695809   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 793d0a98cfba"
I1017 17:10:43.733700   28215 logs.go:124] Gathering logs for kube-scheduler [f4a15e9e42a9] ...
I1017 17:10:43.733714   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f4a15e9e42a9"
I1017 17:10:43.757111   28215 logs.go:124] Gathering logs for kubelet ...
I1017 17:10:43.757128   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I1017 17:10:46.366152   28215 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I1017 17:10:51.371304   28215 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I1017 17:10:51.703336   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I1017 17:10:51.723955   28215 logs.go:279] 2 containers: [a4953fa9a9a9 793d0a98cfba]
I1017 17:10:51.724081   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I1017 17:10:51.736041   28215 logs.go:279] 2 containers: [d68a4772ec61 87638495abba]
I1017 17:10:51.736152   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I1017 17:10:51.748031   28215 logs.go:279] 1 containers: [9d8ce9c34f4f]
I1017 17:10:51.748136   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I1017 17:10:51.758677   28215 logs.go:279] 2 containers: [f4a15e9e42a9 d7899b5676a6]
I1017 17:10:51.758808   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I1017 17:10:51.768936   28215 logs.go:279] 2 containers: [7683deae11fa 067e7d061ba4]
I1017 17:10:51.769052   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I1017 17:10:51.780712   28215 logs.go:279] 0 containers: []
W1017 17:10:51.780721   28215 logs.go:281] No container was found matching "kubernetes-dashboard"
I1017 17:10:51.780812   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I1017 17:10:51.793196   28215 logs.go:279] 2 containers: [7b133da22f8c a898719c42cf]
I1017 17:10:51.793308   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I1017 17:10:51.805406   28215 logs.go:279] 2 containers: [9d5cc400d287 b069ae6fcb01]
I1017 17:10:51.805420   28215 logs.go:124] Gathering logs for kube-apiserver [a4953fa9a9a9] ...
I1017 17:10:51.805426   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a4953fa9a9a9"
I1017 17:10:51.822412   28215 logs.go:124] Gathering logs for describe nodes ...
I1017 17:10:51.822423   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.26.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I1017 17:10:51.902140   28215 logs.go:124] Gathering logs for kube-proxy [7683deae11fa] ...
I1017 17:10:51.902151   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7683deae11fa"
I1017 17:10:51.920126   28215 logs.go:124] Gathering logs for kube-proxy [067e7d061ba4] ...
I1017 17:10:51.920137   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 067e7d061ba4"
I1017 17:10:51.945588   28215 logs.go:124] Gathering logs for storage-provisioner [a898719c42cf] ...
I1017 17:10:51.945600   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a898719c42cf"
I1017 17:10:51.963637   28215 logs.go:124] Gathering logs for Docker ...
I1017 17:10:51.963656   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I1017 17:10:51.988925   28215 logs.go:124] Gathering logs for kube-scheduler [d7899b5676a6] ...
I1017 17:10:51.988939   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d7899b5676a6"
I1017 17:10:52.004413   28215 logs.go:124] Gathering logs for kube-apiserver [793d0a98cfba] ...
I1017 17:10:52.004424   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 793d0a98cfba"
I1017 17:10:52.035706   28215 logs.go:124] Gathering logs for coredns [9d8ce9c34f4f] ...
I1017 17:10:52.035719   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9d8ce9c34f4f"
I1017 17:10:52.050323   28215 logs.go:124] Gathering logs for storage-provisioner [7b133da22f8c] ...
I1017 17:10:52.050334   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7b133da22f8c"
I1017 17:10:52.064619   28215 logs.go:124] Gathering logs for container status ...
I1017 17:10:52.064630   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I1017 17:10:52.090880   28215 logs.go:124] Gathering logs for dmesg ...
I1017 17:10:52.090891   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I1017 17:10:52.097879   28215 logs.go:124] Gathering logs for etcd [d68a4772ec61] ...
I1017 17:10:52.097890   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d68a4772ec61"
I1017 17:10:52.117760   28215 logs.go:124] Gathering logs for etcd [87638495abba] ...
I1017 17:10:52.117772   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 87638495abba"
I1017 17:10:52.136900   28215 logs.go:124] Gathering logs for kube-scheduler [f4a15e9e42a9] ...
I1017 17:10:52.136933   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f4a15e9e42a9"
I1017 17:10:52.152783   28215 logs.go:124] Gathering logs for kube-controller-manager [9d5cc400d287] ...
I1017 17:10:52.152793   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9d5cc400d287"
I1017 17:10:52.178091   28215 logs.go:124] Gathering logs for kube-controller-manager [b069ae6fcb01] ...
I1017 17:10:52.178103   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b069ae6fcb01"
I1017 17:10:52.201220   28215 logs.go:124] Gathering logs for kubelet ...
I1017 17:10:52.201236   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I1017 17:10:54.790989   28215 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I1017 17:10:59.795358   28215 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I1017 17:11:00.202849   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I1017 17:11:00.213084   28215 logs.go:279] 2 containers: [a4953fa9a9a9 793d0a98cfba]
I1017 17:11:00.213171   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I1017 17:11:00.222825   28215 logs.go:279] 2 containers: [d68a4772ec61 87638495abba]
I1017 17:11:00.222925   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I1017 17:11:00.232758   28215 logs.go:279] 1 containers: [9d8ce9c34f4f]
I1017 17:11:00.232931   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I1017 17:11:00.242413   28215 logs.go:279] 2 containers: [f4a15e9e42a9 d7899b5676a6]
I1017 17:11:00.242526   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I1017 17:11:00.252875   28215 logs.go:279] 2 containers: [7683deae11fa 067e7d061ba4]
I1017 17:11:00.252990   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I1017 17:11:00.264332   28215 logs.go:279] 0 containers: []
W1017 17:11:00.264340   28215 logs.go:281] No container was found matching "kubernetes-dashboard"
I1017 17:11:00.264427   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I1017 17:11:00.276061   28215 logs.go:279] 2 containers: [7b133da22f8c a898719c42cf]
I1017 17:11:00.276171   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I1017 17:11:00.285873   28215 logs.go:279] 2 containers: [9d5cc400d287 b069ae6fcb01]
I1017 17:11:00.285886   28215 logs.go:124] Gathering logs for kube-proxy [7683deae11fa] ...
I1017 17:11:00.285891   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7683deae11fa"
I1017 17:11:00.297092   28215 logs.go:124] Gathering logs for kube-controller-manager [9d5cc400d287] ...
I1017 17:11:00.297101   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9d5cc400d287"
I1017 17:11:00.314012   28215 logs.go:124] Gathering logs for dmesg ...
I1017 17:11:00.314020   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I1017 17:11:00.320252   28215 logs.go:124] Gathering logs for kube-apiserver [a4953fa9a9a9] ...
I1017 17:11:00.320261   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a4953fa9a9a9"
I1017 17:11:00.337600   28215 logs.go:124] Gathering logs for etcd [87638495abba] ...
I1017 17:11:00.337611   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 87638495abba"
I1017 17:11:00.354218   28215 logs.go:124] Gathering logs for storage-provisioner [7b133da22f8c] ...
I1017 17:11:00.354230   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7b133da22f8c"
I1017 17:11:00.366303   28215 logs.go:124] Gathering logs for storage-provisioner [a898719c42cf] ...
I1017 17:11:00.366317   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a898719c42cf"
I1017 17:11:00.378757   28215 logs.go:124] Gathering logs for Docker ...
I1017 17:11:00.378766   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I1017 17:11:00.402909   28215 logs.go:124] Gathering logs for kubelet ...
I1017 17:11:00.402923   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I1017 17:11:00.476143   28215 logs.go:124] Gathering logs for describe nodes ...
I1017 17:11:00.476165   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.26.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I1017 17:11:00.556006   28215 logs.go:124] Gathering logs for kube-apiserver [793d0a98cfba] ...
I1017 17:11:00.556040   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 793d0a98cfba"
I1017 17:11:00.584714   28215 logs.go:124] Gathering logs for coredns [9d8ce9c34f4f] ...
I1017 17:11:00.584727   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9d8ce9c34f4f"
I1017 17:11:00.599961   28215 logs.go:124] Gathering logs for kube-proxy [067e7d061ba4] ...
I1017 17:11:00.599972   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 067e7d061ba4"
I1017 17:11:00.614778   28215 logs.go:124] Gathering logs for etcd [d68a4772ec61] ...
I1017 17:11:00.614788   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d68a4772ec61"
I1017 17:11:00.633356   28215 logs.go:124] Gathering logs for kube-scheduler [f4a15e9e42a9] ...
I1017 17:11:00.633370   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f4a15e9e42a9"
I1017 17:11:00.647660   28215 logs.go:124] Gathering logs for kube-scheduler [d7899b5676a6] ...
I1017 17:11:00.647671   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d7899b5676a6"
I1017 17:11:00.663526   28215 logs.go:124] Gathering logs for kube-controller-manager [b069ae6fcb01] ...
I1017 17:11:00.663537   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b069ae6fcb01"
I1017 17:11:00.686929   28215 logs.go:124] Gathering logs for container status ...
I1017 17:11:00.686941   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I1017 17:11:03.212348   28215 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I1017 17:11:08.215881   28215 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I1017 17:11:08.702908   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I1017 17:11:08.719270   28215 logs.go:279] 2 containers: [a4953fa9a9a9 793d0a98cfba]
I1017 17:11:08.719406   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I1017 17:11:08.728667   28215 logs.go:279] 2 containers: [d68a4772ec61 87638495abba]
I1017 17:11:08.728762   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I1017 17:11:08.739605   28215 logs.go:279] 1 containers: [9d8ce9c34f4f]
I1017 17:11:08.739699   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I1017 17:11:08.749573   28215 logs.go:279] 2 containers: [f4a15e9e42a9 d7899b5676a6]
I1017 17:11:08.749676   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I1017 17:11:08.759561   28215 logs.go:279] 2 containers: [7683deae11fa 067e7d061ba4]
I1017 17:11:08.759663   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I1017 17:11:08.769703   28215 logs.go:279] 0 containers: []
W1017 17:11:08.769711   28215 logs.go:281] No container was found matching "kubernetes-dashboard"
I1017 17:11:08.769791   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I1017 17:11:08.780416   28215 logs.go:279] 2 containers: [7b133da22f8c a898719c42cf]
I1017 17:11:08.780522   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I1017 17:11:08.789982   28215 logs.go:279] 2 containers: [9d5cc400d287 b069ae6fcb01]
I1017 17:11:08.789997   28215 logs.go:124] Gathering logs for dmesg ...
I1017 17:11:08.790006   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I1017 17:11:08.796247   28215 logs.go:124] Gathering logs for kube-apiserver [793d0a98cfba] ...
I1017 17:11:08.796256   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 793d0a98cfba"
I1017 17:11:08.814405   28215 logs.go:124] Gathering logs for coredns [9d8ce9c34f4f] ...
I1017 17:11:08.814415   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9d8ce9c34f4f"
I1017 17:11:08.825638   28215 logs.go:124] Gathering logs for kube-proxy [7683deae11fa] ...
I1017 17:11:08.825647   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7683deae11fa"
I1017 17:11:08.837466   28215 logs.go:124] Gathering logs for storage-provisioner [7b133da22f8c] ...
I1017 17:11:08.837477   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7b133da22f8c"
I1017 17:11:08.850138   28215 logs.go:124] Gathering logs for storage-provisioner [a898719c42cf] ...
I1017 17:11:08.850147   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a898719c42cf"
I1017 17:11:08.861455   28215 logs.go:124] Gathering logs for kube-controller-manager [9d5cc400d287] ...
I1017 17:11:08.861465   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9d5cc400d287"
I1017 17:11:08.881551   28215 logs.go:124] Gathering logs for describe nodes ...
I1017 17:11:08.881561   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.26.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I1017 17:11:08.953318   28215 logs.go:124] Gathering logs for kube-apiserver [a4953fa9a9a9] ...
I1017 17:11:08.953328   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a4953fa9a9a9"
I1017 17:11:08.970277   28215 logs.go:124] Gathering logs for etcd [d68a4772ec61] ...
I1017 17:11:08.970287   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d68a4772ec61"
I1017 17:11:08.988051   28215 logs.go:124] Gathering logs for etcd [87638495abba] ...
I1017 17:11:08.988061   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 87638495abba"
I1017 17:11:09.006574   28215 logs.go:124] Gathering logs for kube-scheduler [f4a15e9e42a9] ...
I1017 17:11:09.006586   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f4a15e9e42a9"
I1017 17:11:09.020392   28215 logs.go:124] Gathering logs for Docker ...
I1017 17:11:09.020402   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I1017 17:11:09.043349   28215 logs.go:124] Gathering logs for kubelet ...
I1017 17:11:09.043362   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I1017 17:11:09.124697   28215 logs.go:124] Gathering logs for kube-scheduler [d7899b5676a6] ...
I1017 17:11:09.124712   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d7899b5676a6"
I1017 17:11:09.140609   28215 logs.go:124] Gathering logs for kube-proxy [067e7d061ba4] ...
I1017 17:11:09.140620   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 067e7d061ba4"
I1017 17:11:09.157336   28215 logs.go:124] Gathering logs for kube-controller-manager [b069ae6fcb01] ...
I1017 17:11:09.157346   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b069ae6fcb01"
I1017 17:11:09.182573   28215 logs.go:124] Gathering logs for container status ...
I1017 17:11:09.182586   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I1017 17:11:11.705347   28215 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I1017 17:11:16.706150   28215 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I1017 17:11:17.203173   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I1017 17:11:17.236554   28215 logs.go:279] 2 containers: [a4953fa9a9a9 793d0a98cfba]
I1017 17:11:17.236673   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I1017 17:11:17.246080   28215 logs.go:279] 2 containers: [d68a4772ec61 87638495abba]
I1017 17:11:17.246168   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I1017 17:11:17.255038   28215 logs.go:279] 1 containers: [9d8ce9c34f4f]
I1017 17:11:17.255130   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I1017 17:11:17.271839   28215 logs.go:279] 2 containers: [f4a15e9e42a9 d7899b5676a6]
I1017 17:11:17.271942   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I1017 17:11:17.282443   28215 logs.go:279] 2 containers: [7683deae11fa 067e7d061ba4]
I1017 17:11:17.282553   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I1017 17:11:17.292770   28215 logs.go:279] 0 containers: []
W1017 17:11:17.292779   28215 logs.go:281] No container was found matching "kubernetes-dashboard"
I1017 17:11:17.292881   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I1017 17:11:17.302461   28215 logs.go:279] 2 containers: [7b133da22f8c a898719c42cf]
I1017 17:11:17.302562   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I1017 17:11:17.313227   28215 logs.go:279] 2 containers: [9d5cc400d287 b069ae6fcb01]
I1017 17:11:17.313241   28215 logs.go:124] Gathering logs for kube-apiserver [793d0a98cfba] ...
I1017 17:11:17.313245   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 793d0a98cfba"
I1017 17:11:17.335484   28215 logs.go:124] Gathering logs for etcd [87638495abba] ...
I1017 17:11:17.335495   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 87638495abba"
I1017 17:11:17.351132   28215 logs.go:124] Gathering logs for coredns [9d8ce9c34f4f] ...
I1017 17:11:17.351143   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9d8ce9c34f4f"
I1017 17:11:17.362787   28215 logs.go:124] Gathering logs for kube-proxy [067e7d061ba4] ...
I1017 17:11:17.362802   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 067e7d061ba4"
I1017 17:11:17.374915   28215 logs.go:124] Gathering logs for kube-controller-manager [b069ae6fcb01] ...
I1017 17:11:17.374924   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b069ae6fcb01"
I1017 17:11:17.394488   28215 logs.go:124] Gathering logs for kubelet ...
I1017 17:11:17.394498   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I1017 17:11:17.468461   28215 logs.go:124] Gathering logs for describe nodes ...
I1017 17:11:17.468473   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.26.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I1017 17:11:17.535353   28215 logs.go:124] Gathering logs for kube-scheduler [f4a15e9e42a9] ...
I1017 17:11:17.535362   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f4a15e9e42a9"
I1017 17:11:17.550104   28215 logs.go:124] Gathering logs for kube-proxy [7683deae11fa] ...
I1017 17:11:17.550114   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7683deae11fa"
I1017 17:11:17.564151   28215 logs.go:124] Gathering logs for storage-provisioner [a898719c42cf] ...
I1017 17:11:17.564161   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a898719c42cf"
I1017 17:11:17.579004   28215 logs.go:124] Gathering logs for kube-controller-manager [9d5cc400d287] ...
I1017 17:11:17.579016   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9d5cc400d287"
I1017 17:11:17.602327   28215 logs.go:124] Gathering logs for etcd [d68a4772ec61] ...
I1017 17:11:17.602338   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d68a4772ec61"
I1017 17:11:17.621520   28215 logs.go:124] Gathering logs for kube-scheduler [d7899b5676a6] ...
I1017 17:11:17.621531   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d7899b5676a6"
I1017 17:11:17.637101   28215 logs.go:124] Gathering logs for storage-provisioner [7b133da22f8c] ...
I1017 17:11:17.637113   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7b133da22f8c"
I1017 17:11:17.650691   28215 logs.go:124] Gathering logs for container status ...
I1017 17:11:17.650704   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I1017 17:11:17.673808   28215 logs.go:124] Gathering logs for dmesg ...
I1017 17:11:17.673821   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I1017 17:11:17.680900   28215 logs.go:124] Gathering logs for kube-apiserver [a4953fa9a9a9] ...
I1017 17:11:17.680911   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a4953fa9a9a9"
I1017 17:11:17.699238   28215 logs.go:124] Gathering logs for Docker ...
I1017 17:11:17.699252   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I1017 17:11:20.228901   28215 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I1017 17:11:25.234355   28215 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I1017 17:11:25.702796   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I1017 17:11:25.721809   28215 logs.go:279] 2 containers: [a4953fa9a9a9 793d0a98cfba]
I1017 17:11:25.721963   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I1017 17:11:25.735237   28215 logs.go:279] 2 containers: [d68a4772ec61 87638495abba]
I1017 17:11:25.735351   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I1017 17:11:25.748477   28215 logs.go:279] 1 containers: [9d8ce9c34f4f]
I1017 17:11:25.748587   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I1017 17:11:25.761348   28215 logs.go:279] 2 containers: [f4a15e9e42a9 d7899b5676a6]
I1017 17:11:25.761476   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I1017 17:11:25.775874   28215 logs.go:279] 2 containers: [7683deae11fa 067e7d061ba4]
I1017 17:11:25.775992   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I1017 17:11:25.790482   28215 logs.go:279] 0 containers: []
W1017 17:11:25.790492   28215 logs.go:281] No container was found matching "kubernetes-dashboard"
I1017 17:11:25.790656   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I1017 17:11:25.807455   28215 logs.go:279] 2 containers: [7b133da22f8c a898719c42cf]
I1017 17:11:25.808522   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I1017 17:11:25.823516   28215 logs.go:279] 2 containers: [9d5cc400d287 b069ae6fcb01]
I1017 17:11:25.823541   28215 logs.go:124] Gathering logs for dmesg ...
I1017 17:11:25.823547   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I1017 17:11:25.831638   28215 logs.go:124] Gathering logs for kube-apiserver [a4953fa9a9a9] ...
I1017 17:11:25.831650   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a4953fa9a9a9"
I1017 17:11:25.850764   28215 logs.go:124] Gathering logs for kube-scheduler [d7899b5676a6] ...
I1017 17:11:25.850775   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d7899b5676a6"
I1017 17:11:25.866604   28215 logs.go:124] Gathering logs for Docker ...
I1017 17:11:25.866615   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I1017 17:11:25.897868   28215 logs.go:124] Gathering logs for kube-apiserver [793d0a98cfba] ...
I1017 17:11:25.897882   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 793d0a98cfba"
I1017 17:11:25.933019   28215 logs.go:124] Gathering logs for describe nodes ...
I1017 17:11:25.933032   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.26.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I1017 17:11:26.030300   28215 logs.go:124] Gathering logs for etcd [87638495abba] ...
I1017 17:11:26.030313   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 87638495abba"
I1017 17:11:26.053229   28215 logs.go:124] Gathering logs for kube-scheduler [f4a15e9e42a9] ...
I1017 17:11:26.053241   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f4a15e9e42a9"
I1017 17:11:26.069568   28215 logs.go:124] Gathering logs for kube-proxy [7683deae11fa] ...
I1017 17:11:26.069579   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7683deae11fa"
I1017 17:11:26.086547   28215 logs.go:124] Gathering logs for kube-controller-manager [9d5cc400d287] ...
I1017 17:11:26.086559   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9d5cc400d287"
I1017 17:11:26.112642   28215 logs.go:124] Gathering logs for container status ...
I1017 17:11:26.112655   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I1017 17:11:26.142547   28215 logs.go:124] Gathering logs for kubelet ...
I1017 17:11:26.142560   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I1017 17:11:26.234883   28215 logs.go:124] Gathering logs for etcd [d68a4772ec61] ...
I1017 17:11:26.234896   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d68a4772ec61"
I1017 17:11:26.259934   28215 logs.go:124] Gathering logs for coredns [9d8ce9c34f4f] ...
I1017 17:11:26.259949   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9d8ce9c34f4f"
I1017 17:11:26.284202   28215 logs.go:124] Gathering logs for kube-proxy [067e7d061ba4] ...
I1017 17:11:26.284215   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 067e7d061ba4"
I1017 17:11:26.309844   28215 logs.go:124] Gathering logs for storage-provisioner [7b133da22f8c] ...
I1017 17:11:26.309860   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7b133da22f8c"
I1017 17:11:26.331588   28215 logs.go:124] Gathering logs for storage-provisioner [a898719c42cf] ...
I1017 17:11:26.331600   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a898719c42cf"
I1017 17:11:26.356703   28215 logs.go:124] Gathering logs for kube-controller-manager [b069ae6fcb01] ...
I1017 17:11:26.356716   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b069ae6fcb01"
I1017 17:11:28.893683   28215 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I1017 17:11:33.898781   28215 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I1017 17:11:34.204270   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I1017 17:11:34.215131   28215 logs.go:279] 2 containers: [a4953fa9a9a9 793d0a98cfba]
I1017 17:11:34.215219   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I1017 17:11:34.224087   28215 logs.go:279] 2 containers: [d68a4772ec61 87638495abba]
I1017 17:11:34.224197   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I1017 17:11:34.233148   28215 logs.go:279] 1 containers: [9d8ce9c34f4f]
I1017 17:11:34.233246   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I1017 17:11:34.243713   28215 logs.go:279] 2 containers: [f4a15e9e42a9 d7899b5676a6]
I1017 17:11:34.243840   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I1017 17:11:34.253108   28215 logs.go:279] 2 containers: [7683deae11fa 067e7d061ba4]
I1017 17:11:34.253199   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I1017 17:11:34.262365   28215 logs.go:279] 0 containers: []
W1017 17:11:34.262372   28215 logs.go:281] No container was found matching "kubernetes-dashboard"
I1017 17:11:34.262467   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I1017 17:11:34.272760   28215 logs.go:279] 2 containers: [7b133da22f8c a898719c42cf]
I1017 17:11:34.272859   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I1017 17:11:34.285040   28215 logs.go:279] 2 containers: [9d5cc400d287 b069ae6fcb01]
I1017 17:11:34.285054   28215 logs.go:124] Gathering logs for etcd [d68a4772ec61] ...
I1017 17:11:34.285058   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d68a4772ec61"
I1017 17:11:34.302077   28215 logs.go:124] Gathering logs for storage-provisioner [a898719c42cf] ...
I1017 17:11:34.302087   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a898719c42cf"
I1017 17:11:34.313817   28215 logs.go:124] Gathering logs for Docker ...
I1017 17:11:34.313827   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I1017 17:11:34.335244   28215 logs.go:124] Gathering logs for container status ...
I1017 17:11:34.335256   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I1017 17:11:34.364411   28215 logs.go:124] Gathering logs for dmesg ...
I1017 17:11:34.364420   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I1017 17:11:34.370493   28215 logs.go:124] Gathering logs for describe nodes ...
I1017 17:11:34.370502   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.26.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I1017 17:11:34.445792   28215 logs.go:124] Gathering logs for kube-scheduler [f4a15e9e42a9] ...
I1017 17:11:34.445801   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f4a15e9e42a9"
I1017 17:11:34.459408   28215 logs.go:124] Gathering logs for kube-scheduler [d7899b5676a6] ...
I1017 17:11:34.459418   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d7899b5676a6"
I1017 17:11:34.476218   28215 logs.go:124] Gathering logs for kube-proxy [067e7d061ba4] ...
I1017 17:11:34.476228   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 067e7d061ba4"
I1017 17:11:34.489091   28215 logs.go:124] Gathering logs for storage-provisioner [7b133da22f8c] ...
I1017 17:11:34.489101   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7b133da22f8c"
I1017 17:11:34.502919   28215 logs.go:124] Gathering logs for kube-controller-manager [9d5cc400d287] ...
I1017 17:11:34.502929   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9d5cc400d287"
I1017 17:11:34.525962   28215 logs.go:124] Gathering logs for kube-controller-manager [b069ae6fcb01] ...
I1017 17:11:34.525973   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b069ae6fcb01"
I1017 17:11:34.551080   28215 logs.go:124] Gathering logs for kube-apiserver [793d0a98cfba] ...
I1017 17:11:34.551091   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 793d0a98cfba"
I1017 17:11:34.572690   28215 logs.go:124] Gathering logs for etcd [87638495abba] ...
I1017 17:11:34.572700   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 87638495abba"
I1017 17:11:34.592120   28215 logs.go:124] Gathering logs for coredns [9d8ce9c34f4f] ...
I1017 17:11:34.592131   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9d8ce9c34f4f"
I1017 17:11:34.606390   28215 logs.go:124] Gathering logs for kube-proxy [7683deae11fa] ...
I1017 17:11:34.606401   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7683deae11fa"
I1017 17:11:34.626015   28215 logs.go:124] Gathering logs for kubelet ...
I1017 17:11:34.626026   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I1017 17:11:34.712381   28215 logs.go:124] Gathering logs for kube-apiserver [a4953fa9a9a9] ...
I1017 17:11:34.712393   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a4953fa9a9a9"
I1017 17:11:37.236745   28215 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I1017 17:11:42.237556   28215 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I1017 17:11:42.700920   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I1017 17:11:42.719369   28215 logs.go:279] 2 containers: [a4953fa9a9a9 793d0a98cfba]
I1017 17:11:42.719476   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I1017 17:11:42.735130   28215 logs.go:279] 2 containers: [d68a4772ec61 87638495abba]
I1017 17:11:42.735232   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I1017 17:11:42.756178   28215 logs.go:279] 1 containers: [9d8ce9c34f4f]
I1017 17:11:42.756271   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I1017 17:11:42.766209   28215 logs.go:279] 2 containers: [f4a15e9e42a9 d7899b5676a6]
I1017 17:11:42.766308   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I1017 17:11:42.776561   28215 logs.go:279] 2 containers: [7683deae11fa 067e7d061ba4]
I1017 17:11:42.776659   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I1017 17:11:42.787913   28215 logs.go:279] 0 containers: []
W1017 17:11:42.787921   28215 logs.go:281] No container was found matching "kubernetes-dashboard"
I1017 17:11:42.788012   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I1017 17:11:42.800600   28215 logs.go:279] 2 containers: [7b133da22f8c a898719c42cf]
I1017 17:11:42.800700   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I1017 17:11:42.811472   28215 logs.go:279] 2 containers: [9d5cc400d287 b069ae6fcb01]
I1017 17:11:42.811487   28215 logs.go:124] Gathering logs for kube-scheduler [d7899b5676a6] ...
I1017 17:11:42.811492   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d7899b5676a6"
I1017 17:11:42.824400   28215 logs.go:124] Gathering logs for dmesg ...
I1017 17:11:42.824410   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I1017 17:11:42.830915   28215 logs.go:124] Gathering logs for kube-scheduler [f4a15e9e42a9] ...
I1017 17:11:42.830925   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f4a15e9e42a9"
I1017 17:11:42.842786   28215 logs.go:124] Gathering logs for kube-controller-manager [9d5cc400d287] ...
I1017 17:11:42.842801   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9d5cc400d287"
I1017 17:11:42.862457   28215 logs.go:124] Gathering logs for Docker ...
I1017 17:11:42.862468   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I1017 17:11:42.888833   28215 logs.go:124] Gathering logs for etcd [87638495abba] ...
I1017 17:11:42.888849   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 87638495abba"
I1017 17:11:42.906946   28215 logs.go:124] Gathering logs for coredns [9d8ce9c34f4f] ...
I1017 17:11:42.906959   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9d8ce9c34f4f"
I1017 17:11:42.920785   28215 logs.go:124] Gathering logs for kube-apiserver [793d0a98cfba] ...
I1017 17:11:42.920796   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 793d0a98cfba"
I1017 17:11:42.944251   28215 logs.go:124] Gathering logs for kube-proxy [067e7d061ba4] ...
I1017 17:11:42.944262   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 067e7d061ba4"
I1017 17:11:42.957675   28215 logs.go:124] Gathering logs for kube-apiserver [a4953fa9a9a9] ...
I1017 17:11:42.957685   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a4953fa9a9a9"
I1017 17:11:42.975416   28215 logs.go:124] Gathering logs for etcd [d68a4772ec61] ...
I1017 17:11:42.975436   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d68a4772ec61"
I1017 17:11:42.995088   28215 logs.go:124] Gathering logs for kube-proxy [7683deae11fa] ...
I1017 17:11:42.995099   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7683deae11fa"
I1017 17:11:43.011156   28215 logs.go:124] Gathering logs for storage-provisioner [7b133da22f8c] ...
I1017 17:11:43.011167   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7b133da22f8c"
I1017 17:11:43.024544   28215 logs.go:124] Gathering logs for storage-provisioner [a898719c42cf] ...
I1017 17:11:43.024566   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a898719c42cf"
I1017 17:11:43.039479   28215 logs.go:124] Gathering logs for kube-controller-manager [b069ae6fcb01] ...
I1017 17:11:43.039491   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b069ae6fcb01"
I1017 17:11:43.062381   28215 logs.go:124] Gathering logs for kubelet ...
I1017 17:11:43.062392   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I1017 17:11:43.145618   28215 logs.go:124] Gathering logs for describe nodes ...
I1017 17:11:43.145630   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.26.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I1017 17:11:43.224738   28215 logs.go:124] Gathering logs for container status ...
I1017 17:11:43.224750   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I1017 17:11:45.753314   28215 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I1017 17:11:50.758469   28215 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I1017 17:11:51.200833   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I1017 17:11:51.219289   28215 logs.go:279] 2 containers: [a4953fa9a9a9 793d0a98cfba]
I1017 17:11:51.219383   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I1017 17:11:51.228594   28215 logs.go:279] 2 containers: [d68a4772ec61 87638495abba]
I1017 17:11:51.228698   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I1017 17:11:51.239185   28215 logs.go:279] 1 containers: [9d8ce9c34f4f]
I1017 17:11:51.239305   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I1017 17:11:51.252918   28215 logs.go:279] 2 containers: [f4a15e9e42a9 d7899b5676a6]
I1017 17:11:51.253010   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I1017 17:11:51.262580   28215 logs.go:279] 2 containers: [7683deae11fa 067e7d061ba4]
I1017 17:11:51.262668   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I1017 17:11:51.275518   28215 logs.go:279] 0 containers: []
W1017 17:11:51.275527   28215 logs.go:281] No container was found matching "kubernetes-dashboard"
I1017 17:11:51.275617   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I1017 17:11:51.285628   28215 logs.go:279] 2 containers: [7b133da22f8c a898719c42cf]
I1017 17:11:51.285736   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I1017 17:11:51.295628   28215 logs.go:279] 2 containers: [9d5cc400d287 b069ae6fcb01]
I1017 17:11:51.295642   28215 logs.go:124] Gathering logs for coredns [9d8ce9c34f4f] ...
I1017 17:11:51.295646   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9d8ce9c34f4f"
I1017 17:11:51.307159   28215 logs.go:124] Gathering logs for describe nodes ...
I1017 17:11:51.307169   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.26.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I1017 17:11:51.368828   28215 logs.go:124] Gathering logs for kube-apiserver [a4953fa9a9a9] ...
I1017 17:11:51.368837   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a4953fa9a9a9"
I1017 17:11:51.385206   28215 logs.go:124] Gathering logs for kube-scheduler [d7899b5676a6] ...
I1017 17:11:51.385218   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d7899b5676a6"
I1017 17:11:51.398469   28215 logs.go:124] Gathering logs for kube-proxy [7683deae11fa] ...
I1017 17:11:51.398479   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7683deae11fa"
I1017 17:11:51.411004   28215 logs.go:124] Gathering logs for storage-provisioner [7b133da22f8c] ...
I1017 17:11:51.411013   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7b133da22f8c"
I1017 17:11:51.424212   28215 logs.go:124] Gathering logs for kube-controller-manager [b069ae6fcb01] ...
I1017 17:11:51.424222   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b069ae6fcb01"
I1017 17:11:51.445230   28215 logs.go:124] Gathering logs for container status ...
I1017 17:11:51.445242   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I1017 17:11:51.469716   28215 logs.go:124] Gathering logs for dmesg ...
I1017 17:11:51.469726   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I1017 17:11:51.476260   28215 logs.go:124] Gathering logs for etcd [87638495abba] ...
I1017 17:11:51.476268   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 87638495abba"
I1017 17:11:51.493790   28215 logs.go:124] Gathering logs for kube-scheduler [f4a15e9e42a9] ...
I1017 17:11:51.493800   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f4a15e9e42a9"
I1017 17:11:51.507039   28215 logs.go:124] Gathering logs for storage-provisioner [a898719c42cf] ...
I1017 17:11:51.507050   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a898719c42cf"
I1017 17:11:51.518599   28215 logs.go:124] Gathering logs for kube-controller-manager [9d5cc400d287] ...
I1017 17:11:51.518609   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9d5cc400d287"
I1017 17:11:51.539374   28215 logs.go:124] Gathering logs for Docker ...
I1017 17:11:51.539386   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I1017 17:11:51.566566   28215 logs.go:124] Gathering logs for kubelet ...
I1017 17:11:51.566578   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I1017 17:11:51.650944   28215 logs.go:124] Gathering logs for kube-apiserver [793d0a98cfba] ...
I1017 17:11:51.650957   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 793d0a98cfba"
I1017 17:11:51.673574   28215 logs.go:124] Gathering logs for etcd [d68a4772ec61] ...
I1017 17:11:51.673586   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d68a4772ec61"
I1017 17:11:51.692515   28215 logs.go:124] Gathering logs for kube-proxy [067e7d061ba4] ...
I1017 17:11:51.692527   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 067e7d061ba4"
I1017 17:11:54.207525   28215 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I1017 17:11:59.208560   28215 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I1017 17:11:59.699970   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I1017 17:11:59.728664   28215 logs.go:279] 2 containers: [a4953fa9a9a9 793d0a98cfba]
I1017 17:11:59.728755   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I1017 17:11:59.740494   28215 logs.go:279] 2 containers: [d68a4772ec61 87638495abba]
I1017 17:11:59.740594   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I1017 17:11:59.751172   28215 logs.go:279] 1 containers: [9d8ce9c34f4f]
I1017 17:11:59.751271   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I1017 17:11:59.761584   28215 logs.go:279] 2 containers: [f4a15e9e42a9 d7899b5676a6]
I1017 17:11:59.761691   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I1017 17:11:59.773676   28215 logs.go:279] 2 containers: [7683deae11fa 067e7d061ba4]
I1017 17:11:59.773767   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I1017 17:11:59.784597   28215 logs.go:279] 0 containers: []
W1017 17:11:59.784607   28215 logs.go:281] No container was found matching "kubernetes-dashboard"
I1017 17:11:59.784703   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I1017 17:11:59.795488   28215 logs.go:279] 2 containers: [7b133da22f8c a898719c42cf]
I1017 17:11:59.795584   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I1017 17:11:59.805403   28215 logs.go:279] 2 containers: [9d5cc400d287 b069ae6fcb01]
I1017 17:11:59.805417   28215 logs.go:124] Gathering logs for Docker ...
I1017 17:11:59.805421   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I1017 17:11:59.827444   28215 logs.go:124] Gathering logs for describe nodes ...
I1017 17:11:59.827455   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.26.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I1017 17:11:59.897608   28215 logs.go:124] Gathering logs for kube-controller-manager [b069ae6fcb01] ...
I1017 17:11:59.897617   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b069ae6fcb01"
I1017 17:11:59.921176   28215 logs.go:124] Gathering logs for storage-provisioner [7b133da22f8c] ...
I1017 17:11:59.921187   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7b133da22f8c"
I1017 17:11:59.934432   28215 logs.go:124] Gathering logs for kube-scheduler [f4a15e9e42a9] ...
I1017 17:11:59.934441   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f4a15e9e42a9"
I1017 17:11:59.947401   28215 logs.go:124] Gathering logs for kube-proxy [067e7d061ba4] ...
I1017 17:11:59.947421   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 067e7d061ba4"
I1017 17:11:59.960680   28215 logs.go:124] Gathering logs for etcd [d68a4772ec61] ...
I1017 17:11:59.960690   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d68a4772ec61"
I1017 17:11:59.991525   28215 logs.go:124] Gathering logs for etcd [87638495abba] ...
I1017 17:11:59.991538   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 87638495abba"
I1017 17:12:00.009614   28215 logs.go:124] Gathering logs for kube-apiserver [a4953fa9a9a9] ...
I1017 17:12:00.009630   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a4953fa9a9a9"
I1017 17:12:00.026346   28215 logs.go:124] Gathering logs for kube-apiserver [793d0a98cfba] ...
I1017 17:12:00.026356   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 793d0a98cfba"
I1017 17:12:00.049051   28215 logs.go:124] Gathering logs for coredns [9d8ce9c34f4f] ...
I1017 17:12:00.049066   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9d8ce9c34f4f"
I1017 17:12:00.063812   28215 logs.go:124] Gathering logs for kube-scheduler [d7899b5676a6] ...
I1017 17:12:00.063823   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d7899b5676a6"
I1017 17:12:00.079019   28215 logs.go:124] Gathering logs for kube-proxy [7683deae11fa] ...
I1017 17:12:00.079030   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7683deae11fa"
I1017 17:12:00.093417   28215 logs.go:124] Gathering logs for storage-provisioner [a898719c42cf] ...
I1017 17:12:00.093429   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a898719c42cf"
I1017 17:12:00.107128   28215 logs.go:124] Gathering logs for kubelet ...
I1017 17:12:00.107138   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I1017 17:12:00.189904   28215 logs.go:124] Gathering logs for dmesg ...
I1017 17:12:00.189920   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I1017 17:12:00.197853   28215 logs.go:124] Gathering logs for kube-controller-manager [9d5cc400d287] ...
I1017 17:12:00.197863   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9d5cc400d287"
I1017 17:12:00.222592   28215 logs.go:124] Gathering logs for container status ...
I1017 17:12:00.222605   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I1017 17:12:02.753837   28215 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I1017 17:12:07.758988   28215 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I1017 17:12:08.202517   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I1017 17:12:08.212852   28215 logs.go:279] 2 containers: [a4953fa9a9a9 793d0a98cfba]
I1017 17:12:08.212964   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I1017 17:12:08.222044   28215 logs.go:279] 2 containers: [d68a4772ec61 87638495abba]
I1017 17:12:08.222137   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I1017 17:12:08.232521   28215 logs.go:279] 1 containers: [9d8ce9c34f4f]
I1017 17:12:08.232636   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I1017 17:12:08.241683   28215 logs.go:279] 2 containers: [f4a15e9e42a9 d7899b5676a6]
I1017 17:12:08.242050   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I1017 17:12:08.253813   28215 logs.go:279] 2 containers: [7683deae11fa 067e7d061ba4]
I1017 17:12:08.253912   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I1017 17:12:08.263523   28215 logs.go:279] 0 containers: []
W1017 17:12:08.263531   28215 logs.go:281] No container was found matching "kubernetes-dashboard"
I1017 17:12:08.263618   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I1017 17:12:08.276285   28215 logs.go:279] 2 containers: [7b133da22f8c a898719c42cf]
I1017 17:12:08.276393   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I1017 17:12:08.287721   28215 logs.go:279] 2 containers: [9d5cc400d287 b069ae6fcb01]
I1017 17:12:08.287734   28215 logs.go:124] Gathering logs for kubelet ...
I1017 17:12:08.287740   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I1017 17:12:08.354243   28215 logs.go:124] Gathering logs for kube-apiserver [793d0a98cfba] ...
I1017 17:12:08.354254   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 793d0a98cfba"
I1017 17:12:08.375318   28215 logs.go:124] Gathering logs for kube-scheduler [d7899b5676a6] ...
I1017 17:12:08.375332   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d7899b5676a6"
I1017 17:12:08.389545   28215 logs.go:124] Gathering logs for coredns [9d8ce9c34f4f] ...
I1017 17:12:08.389555   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9d8ce9c34f4f"
I1017 17:12:08.401990   28215 logs.go:124] Gathering logs for kube-scheduler [f4a15e9e42a9] ...
I1017 17:12:08.402004   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f4a15e9e42a9"
I1017 17:12:08.415353   28215 logs.go:124] Gathering logs for kube-proxy [7683deae11fa] ...
I1017 17:12:08.415364   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7683deae11fa"
I1017 17:12:08.427889   28215 logs.go:124] Gathering logs for dmesg ...
I1017 17:12:08.427898   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I1017 17:12:08.433904   28215 logs.go:124] Gathering logs for describe nodes ...
I1017 17:12:08.433915   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.26.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I1017 17:12:08.505733   28215 logs.go:124] Gathering logs for kube-apiserver [a4953fa9a9a9] ...
I1017 17:12:08.505745   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a4953fa9a9a9"
I1017 17:12:08.523625   28215 logs.go:124] Gathering logs for kube-proxy [067e7d061ba4] ...
I1017 17:12:08.523639   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 067e7d061ba4"
I1017 17:12:08.541709   28215 logs.go:124] Gathering logs for storage-provisioner [a898719c42cf] ...
I1017 17:12:08.541721   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a898719c42cf"
I1017 17:12:08.556771   28215 logs.go:124] Gathering logs for Docker ...
I1017 17:12:08.556782   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I1017 17:12:08.582938   28215 logs.go:124] Gathering logs for kube-controller-manager [9d5cc400d287] ...
I1017 17:12:08.582951   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9d5cc400d287"
I1017 17:12:08.605763   28215 logs.go:124] Gathering logs for kube-controller-manager [b069ae6fcb01] ...
I1017 17:12:08.605774   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b069ae6fcb01"
I1017 17:12:08.630847   28215 logs.go:124] Gathering logs for container status ...
I1017 17:12:08.630859   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I1017 17:12:08.653295   28215 logs.go:124] Gathering logs for etcd [d68a4772ec61] ...
I1017 17:12:08.653308   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d68a4772ec61"
I1017 17:12:08.674094   28215 logs.go:124] Gathering logs for etcd [87638495abba] ...
I1017 17:12:08.674106   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 87638495abba"
I1017 17:12:08.706588   28215 logs.go:124] Gathering logs for storage-provisioner [7b133da22f8c] ...
I1017 17:12:08.706601   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7b133da22f8c"
I1017 17:12:11.227977   28215 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I1017 17:12:16.228293   28215 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I1017 17:12:16.704651   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I1017 17:12:16.725746   28215 logs.go:279] 2 containers: [a4953fa9a9a9 793d0a98cfba]
I1017 17:12:16.725831   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I1017 17:12:16.734685   28215 logs.go:279] 2 containers: [d68a4772ec61 87638495abba]
I1017 17:12:16.734775   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I1017 17:12:16.743692   28215 logs.go:279] 1 containers: [9d8ce9c34f4f]
I1017 17:12:16.743789   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I1017 17:12:16.753299   28215 logs.go:279] 2 containers: [f4a15e9e42a9 d7899b5676a6]
I1017 17:12:16.753402   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I1017 17:12:16.762664   28215 logs.go:279] 2 containers: [7683deae11fa 067e7d061ba4]
I1017 17:12:16.762753   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I1017 17:12:16.774878   28215 logs.go:279] 0 containers: []
W1017 17:12:16.774887   28215 logs.go:281] No container was found matching "kubernetes-dashboard"
I1017 17:12:16.774973   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I1017 17:12:16.785791   28215 logs.go:279] 2 containers: [7b133da22f8c a898719c42cf]
I1017 17:12:16.785910   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I1017 17:12:16.796216   28215 logs.go:279] 2 containers: [9d5cc400d287 b069ae6fcb01]
I1017 17:12:16.796232   28215 logs.go:124] Gathering logs for dmesg ...
I1017 17:12:16.796238   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I1017 17:12:16.801925   28215 logs.go:124] Gathering logs for etcd [87638495abba] ...
I1017 17:12:16.801935   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 87638495abba"
I1017 17:12:16.818181   28215 logs.go:124] Gathering logs for coredns [9d8ce9c34f4f] ...
I1017 17:12:16.818190   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9d8ce9c34f4f"
I1017 17:12:16.829078   28215 logs.go:124] Gathering logs for kube-scheduler [f4a15e9e42a9] ...
I1017 17:12:16.829087   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f4a15e9e42a9"
I1017 17:12:16.842852   28215 logs.go:124] Gathering logs for storage-provisioner [7b133da22f8c] ...
I1017 17:12:16.842862   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7b133da22f8c"
I1017 17:12:16.856112   28215 logs.go:124] Gathering logs for Docker ...
I1017 17:12:16.856121   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I1017 17:12:16.878086   28215 logs.go:124] Gathering logs for kubelet ...
I1017 17:12:16.878104   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I1017 17:12:16.949829   28215 logs.go:124] Gathering logs for kube-scheduler [d7899b5676a6] ...
I1017 17:12:16.949841   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d7899b5676a6"
I1017 17:12:16.963497   28215 logs.go:124] Gathering logs for container status ...
I1017 17:12:16.963506   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I1017 17:12:16.984349   28215 logs.go:124] Gathering logs for describe nodes ...
I1017 17:12:16.984359   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.26.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I1017 17:12:17.058043   28215 logs.go:124] Gathering logs for kube-apiserver [a4953fa9a9a9] ...
I1017 17:12:17.058054   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a4953fa9a9a9"
I1017 17:12:17.086661   28215 logs.go:124] Gathering logs for kube-apiserver [793d0a98cfba] ...
I1017 17:12:17.086672   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 793d0a98cfba"
I1017 17:12:17.112399   28215 logs.go:124] Gathering logs for kube-proxy [7683deae11fa] ...
I1017 17:12:17.112412   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7683deae11fa"
I1017 17:12:17.127253   28215 logs.go:124] Gathering logs for kube-controller-manager [b069ae6fcb01] ...
I1017 17:12:17.127264   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b069ae6fcb01"
I1017 17:12:17.150840   28215 logs.go:124] Gathering logs for etcd [d68a4772ec61] ...
I1017 17:12:17.150851   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d68a4772ec61"
I1017 17:12:17.169737   28215 logs.go:124] Gathering logs for kube-proxy [067e7d061ba4] ...
I1017 17:12:17.169746   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 067e7d061ba4"
I1017 17:12:17.183280   28215 logs.go:124] Gathering logs for storage-provisioner [a898719c42cf] ...
I1017 17:12:17.183290   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a898719c42cf"
I1017 17:12:17.201038   28215 logs.go:124] Gathering logs for kube-controller-manager [9d5cc400d287] ...
I1017 17:12:17.201049   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9d5cc400d287"
I1017 17:12:19.730774   28215 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I1017 17:12:24.735951   28215 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I1017 17:12:25.209050   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I1017 17:12:25.218140   28215 logs.go:279] 2 containers: [a4953fa9a9a9 793d0a98cfba]
I1017 17:12:25.218228   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I1017 17:12:25.230612   28215 logs.go:279] 2 containers: [d68a4772ec61 87638495abba]
I1017 17:12:25.230700   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I1017 17:12:25.239499   28215 logs.go:279] 1 containers: [9d8ce9c34f4f]
I1017 17:12:25.239588   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I1017 17:12:25.248708   28215 logs.go:279] 2 containers: [f4a15e9e42a9 d7899b5676a6]
I1017 17:12:25.248803   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I1017 17:12:25.257995   28215 logs.go:279] 2 containers: [7683deae11fa 067e7d061ba4]
I1017 17:12:25.258091   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I1017 17:12:25.267221   28215 logs.go:279] 0 containers: []
W1017 17:12:25.267228   28215 logs.go:281] No container was found matching "kubernetes-dashboard"
I1017 17:12:25.267312   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I1017 17:12:25.287153   28215 logs.go:279] 2 containers: [7b133da22f8c a898719c42cf]
I1017 17:12:25.287247   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I1017 17:12:25.297302   28215 logs.go:279] 2 containers: [9d5cc400d287 b069ae6fcb01]
I1017 17:12:25.297314   28215 logs.go:124] Gathering logs for kube-apiserver [a4953fa9a9a9] ...
I1017 17:12:25.297318   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a4953fa9a9a9"
I1017 17:12:25.311304   28215 logs.go:124] Gathering logs for kube-apiserver [793d0a98cfba] ...
I1017 17:12:25.311314   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 793d0a98cfba"
I1017 17:12:25.330760   28215 logs.go:124] Gathering logs for kube-proxy [7683deae11fa] ...
I1017 17:12:25.330772   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7683deae11fa"
I1017 17:12:25.343038   28215 logs.go:124] Gathering logs for kube-controller-manager [b069ae6fcb01] ...
I1017 17:12:25.343048   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b069ae6fcb01"
I1017 17:12:25.363280   28215 logs.go:124] Gathering logs for container status ...
I1017 17:12:25.363293   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I1017 17:12:25.382469   28215 logs.go:124] Gathering logs for describe nodes ...
I1017 17:12:25.382478   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.26.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I1017 17:12:25.445338   28215 logs.go:124] Gathering logs for kube-scheduler [f4a15e9e42a9] ...
I1017 17:12:25.445350   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f4a15e9e42a9"
I1017 17:12:25.458217   28215 logs.go:124] Gathering logs for kube-scheduler [d7899b5676a6] ...
I1017 17:12:25.458228   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d7899b5676a6"
I1017 17:12:25.472505   28215 logs.go:124] Gathering logs for kube-proxy [067e7d061ba4] ...
I1017 17:12:25.472516   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 067e7d061ba4"
I1017 17:12:25.485975   28215 logs.go:124] Gathering logs for Docker ...
I1017 17:12:25.485988   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I1017 17:12:25.509325   28215 logs.go:124] Gathering logs for kubelet ...
I1017 17:12:25.509337   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I1017 17:12:25.586510   28215 logs.go:124] Gathering logs for coredns [9d8ce9c34f4f] ...
I1017 17:12:25.586524   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9d8ce9c34f4f"
I1017 17:12:25.600162   28215 logs.go:124] Gathering logs for storage-provisioner [a898719c42cf] ...
I1017 17:12:25.600173   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a898719c42cf"
I1017 17:12:25.614537   28215 logs.go:124] Gathering logs for kube-controller-manager [9d5cc400d287] ...
I1017 17:12:25.614548   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9d5cc400d287"
I1017 17:12:25.636841   28215 logs.go:124] Gathering logs for dmesg ...
I1017 17:12:25.636854   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I1017 17:12:25.643620   28215 logs.go:124] Gathering logs for etcd [d68a4772ec61] ...
I1017 17:12:25.643630   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d68a4772ec61"
I1017 17:12:25.663868   28215 logs.go:124] Gathering logs for etcd [87638495abba] ...
I1017 17:12:25.663879   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 87638495abba"
I1017 17:12:25.683254   28215 logs.go:124] Gathering logs for storage-provisioner [7b133da22f8c] ...
I1017 17:12:25.683266   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7b133da22f8c"
I1017 17:12:28.201019   28215 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I1017 17:12:33.201326   28215 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I1017 17:12:33.699913   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I1017 17:12:33.712412   28215 logs.go:279] 2 containers: [a4953fa9a9a9 793d0a98cfba]
I1017 17:12:33.712506   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I1017 17:12:33.722420   28215 logs.go:279] 2 containers: [d68a4772ec61 87638495abba]
I1017 17:12:33.722509   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I1017 17:12:33.732263   28215 logs.go:279] 1 containers: [9d8ce9c34f4f]
I1017 17:12:33.732358   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I1017 17:12:33.747529   28215 logs.go:279] 2 containers: [f4a15e9e42a9 d7899b5676a6]
I1017 17:12:33.747630   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I1017 17:12:33.756779   28215 logs.go:279] 2 containers: [7683deae11fa 067e7d061ba4]
I1017 17:12:33.756924   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I1017 17:12:33.766588   28215 logs.go:279] 0 containers: []
W1017 17:12:33.766596   28215 logs.go:281] No container was found matching "kubernetes-dashboard"
I1017 17:12:33.766702   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I1017 17:12:33.776557   28215 logs.go:279] 2 containers: [7b133da22f8c a898719c42cf]
I1017 17:12:33.776674   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I1017 17:12:33.786649   28215 logs.go:279] 2 containers: [9d5cc400d287 b069ae6fcb01]
I1017 17:12:33.786662   28215 logs.go:124] Gathering logs for kube-scheduler [d7899b5676a6] ...
I1017 17:12:33.786667   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d7899b5676a6"
I1017 17:12:33.798300   28215 logs.go:124] Gathering logs for container status ...
I1017 17:12:33.798308   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I1017 17:12:33.817765   28215 logs.go:124] Gathering logs for dmesg ...
I1017 17:12:33.817774   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I1017 17:12:33.824270   28215 logs.go:124] Gathering logs for kube-apiserver [a4953fa9a9a9] ...
I1017 17:12:33.824279   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a4953fa9a9a9"
I1017 17:12:33.840254   28215 logs.go:124] Gathering logs for kube-apiserver [793d0a98cfba] ...
I1017 17:12:33.840264   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 793d0a98cfba"
I1017 17:12:33.868100   28215 logs.go:124] Gathering logs for etcd [87638495abba] ...
I1017 17:12:33.868110   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 87638495abba"
I1017 17:12:33.884356   28215 logs.go:124] Gathering logs for coredns [9d8ce9c34f4f] ...
I1017 17:12:33.884364   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9d8ce9c34f4f"
I1017 17:12:33.897044   28215 logs.go:124] Gathering logs for kube-proxy [067e7d061ba4] ...
I1017 17:12:33.897054   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 067e7d061ba4"
I1017 17:12:33.911018   28215 logs.go:124] Gathering logs for kube-controller-manager [b069ae6fcb01] ...
I1017 17:12:33.911028   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b069ae6fcb01"
I1017 17:12:33.932654   28215 logs.go:124] Gathering logs for Docker ...
I1017 17:12:33.932664   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I1017 17:12:33.956059   28215 logs.go:124] Gathering logs for describe nodes ...
I1017 17:12:33.956070   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.26.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I1017 17:12:34.030966   28215 logs.go:124] Gathering logs for etcd [d68a4772ec61] ...
I1017 17:12:34.030977   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d68a4772ec61"
I1017 17:12:34.049130   28215 logs.go:124] Gathering logs for kube-scheduler [f4a15e9e42a9] ...
I1017 17:12:34.049141   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f4a15e9e42a9"
I1017 17:12:34.062761   28215 logs.go:124] Gathering logs for storage-provisioner [a898719c42cf] ...
I1017 17:12:34.062772   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a898719c42cf"
I1017 17:12:34.084335   28215 logs.go:124] Gathering logs for kubelet ...
I1017 17:12:34.084349   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I1017 17:12:34.165934   28215 logs.go:124] Gathering logs for kube-proxy [7683deae11fa] ...
I1017 17:12:34.165946   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7683deae11fa"
I1017 17:12:34.182469   28215 logs.go:124] Gathering logs for storage-provisioner [7b133da22f8c] ...
I1017 17:12:34.182479   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7b133da22f8c"
I1017 17:12:34.196554   28215 logs.go:124] Gathering logs for kube-controller-manager [9d5cc400d287] ...
I1017 17:12:34.196607   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9d5cc400d287"
I1017 17:12:36.723608   28215 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I1017 17:12:41.728764   28215 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I1017 17:12:42.201571   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I1017 17:12:42.215375   28215 logs.go:279] 2 containers: [a4953fa9a9a9 793d0a98cfba]
I1017 17:12:42.215467   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I1017 17:12:42.225533   28215 logs.go:279] 2 containers: [d68a4772ec61 87638495abba]
I1017 17:12:42.225691   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I1017 17:12:42.234892   28215 logs.go:279] 1 containers: [9d8ce9c34f4f]
I1017 17:12:42.234991   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I1017 17:12:42.245141   28215 logs.go:279] 2 containers: [f4a15e9e42a9 d7899b5676a6]
I1017 17:12:42.245238   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I1017 17:12:42.255250   28215 logs.go:279] 2 containers: [7683deae11fa 067e7d061ba4]
I1017 17:12:42.255343   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I1017 17:12:42.265714   28215 logs.go:279] 0 containers: []
W1017 17:12:42.265722   28215 logs.go:281] No container was found matching "kubernetes-dashboard"
I1017 17:12:42.265813   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I1017 17:12:42.278506   28215 logs.go:279] 2 containers: [7b133da22f8c a898719c42cf]
I1017 17:12:42.278608   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I1017 17:12:42.290158   28215 logs.go:279] 2 containers: [9d5cc400d287 b069ae6fcb01]
I1017 17:12:42.290170   28215 logs.go:124] Gathering logs for kube-apiserver [793d0a98cfba] ...
I1017 17:12:42.290179   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 793d0a98cfba"
I1017 17:12:42.308465   28215 logs.go:124] Gathering logs for etcd [d68a4772ec61] ...
I1017 17:12:42.308475   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d68a4772ec61"
I1017 17:12:42.323036   28215 logs.go:124] Gathering logs for etcd [87638495abba] ...
I1017 17:12:42.323046   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 87638495abba"
I1017 17:12:42.339881   28215 logs.go:124] Gathering logs for kube-scheduler [d7899b5676a6] ...
I1017 17:12:42.339891   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d7899b5676a6"
I1017 17:12:42.352765   28215 logs.go:124] Gathering logs for container status ...
I1017 17:12:42.352776   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I1017 17:12:42.383869   28215 logs.go:124] Gathering logs for dmesg ...
I1017 17:12:42.383881   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I1017 17:12:42.392211   28215 logs.go:124] Gathering logs for describe nodes ...
I1017 17:12:42.392220   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.26.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I1017 17:12:42.462641   28215 logs.go:124] Gathering logs for kube-apiserver [a4953fa9a9a9] ...
I1017 17:12:42.462654   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a4953fa9a9a9"
I1017 17:12:42.479764   28215 logs.go:124] Gathering logs for kube-proxy [7683deae11fa] ...
I1017 17:12:42.493749   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7683deae11fa"
I1017 17:12:42.506812   28215 logs.go:124] Gathering logs for kube-proxy [067e7d061ba4] ...
I1017 17:12:42.506823   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 067e7d061ba4"
I1017 17:12:42.519922   28215 logs.go:124] Gathering logs for kube-scheduler [f4a15e9e42a9] ...
I1017 17:12:42.519932   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f4a15e9e42a9"
I1017 17:12:42.534865   28215 logs.go:124] Gathering logs for storage-provisioner [a898719c42cf] ...
I1017 17:12:42.534875   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a898719c42cf"
I1017 17:12:42.547776   28215 logs.go:124] Gathering logs for kube-controller-manager [9d5cc400d287] ...
I1017 17:12:42.547787   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9d5cc400d287"
I1017 17:12:42.568486   28215 logs.go:124] Gathering logs for kube-controller-manager [b069ae6fcb01] ...
I1017 17:12:42.568497   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b069ae6fcb01"
I1017 17:12:42.589610   28215 logs.go:124] Gathering logs for kubelet ...
I1017 17:12:42.589621   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I1017 17:12:42.673509   28215 logs.go:124] Gathering logs for coredns [9d8ce9c34f4f] ...
I1017 17:12:42.673525   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9d8ce9c34f4f"
I1017 17:12:42.688161   28215 logs.go:124] Gathering logs for storage-provisioner [7b133da22f8c] ...
I1017 17:12:42.688174   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7b133da22f8c"
I1017 17:12:42.703102   28215 logs.go:124] Gathering logs for Docker ...
I1017 17:12:42.703113   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I1017 17:12:45.230146   28215 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I1017 17:12:50.232570   28215 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I1017 17:12:50.700255   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I1017 17:12:50.710094   28215 logs.go:279] 2 containers: [a4953fa9a9a9 793d0a98cfba]
I1017 17:12:50.710268   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I1017 17:12:50.719747   28215 logs.go:279] 2 containers: [d68a4772ec61 87638495abba]
I1017 17:12:50.719842   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I1017 17:12:50.729341   28215 logs.go:279] 1 containers: [9d8ce9c34f4f]
I1017 17:12:50.729449   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I1017 17:12:50.739073   28215 logs.go:279] 2 containers: [f4a15e9e42a9 d7899b5676a6]
I1017 17:12:50.739170   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I1017 17:12:50.748516   28215 logs.go:279] 2 containers: [7683deae11fa 067e7d061ba4]
I1017 17:12:50.748628   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I1017 17:12:50.758374   28215 logs.go:279] 0 containers: []
W1017 17:12:50.758383   28215 logs.go:281] No container was found matching "kubernetes-dashboard"
I1017 17:12:50.758508   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I1017 17:12:50.771806   28215 logs.go:279] 2 containers: [7b133da22f8c a898719c42cf]
I1017 17:12:50.771910   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I1017 17:12:50.782253   28215 logs.go:279] 2 containers: [9d5cc400d287 b069ae6fcb01]
I1017 17:12:50.782266   28215 logs.go:124] Gathering logs for describe nodes ...
I1017 17:12:50.782271   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.26.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I1017 17:12:50.846403   28215 logs.go:124] Gathering logs for etcd [87638495abba] ...
I1017 17:12:50.846413   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 87638495abba"
I1017 17:12:50.862640   28215 logs.go:124] Gathering logs for kube-proxy [7683deae11fa] ...
I1017 17:12:50.862653   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7683deae11fa"
I1017 17:12:50.874477   28215 logs.go:124] Gathering logs for Docker ...
I1017 17:12:50.874486   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I1017 17:12:50.897534   28215 logs.go:124] Gathering logs for storage-provisioner [a898719c42cf] ...
I1017 17:12:50.897545   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a898719c42cf"
I1017 17:12:50.913314   28215 logs.go:124] Gathering logs for kube-controller-manager [9d5cc400d287] ...
I1017 17:12:50.913324   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9d5cc400d287"
I1017 17:12:50.934262   28215 logs.go:124] Gathering logs for container status ...
I1017 17:12:50.934272   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I1017 17:12:50.955070   28215 logs.go:124] Gathering logs for kubelet ...
I1017 17:12:50.955081   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I1017 17:12:51.032021   28215 logs.go:124] Gathering logs for dmesg ...
I1017 17:12:51.032033   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I1017 17:12:51.038328   28215 logs.go:124] Gathering logs for coredns [9d8ce9c34f4f] ...
I1017 17:12:51.038337   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9d8ce9c34f4f"
I1017 17:12:51.051301   28215 logs.go:124] Gathering logs for kube-scheduler [d7899b5676a6] ...
I1017 17:12:51.051311   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d7899b5676a6"
I1017 17:12:51.064727   28215 logs.go:124] Gathering logs for kube-controller-manager [b069ae6fcb01] ...
I1017 17:12:51.064737   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b069ae6fcb01"
I1017 17:12:51.089482   28215 logs.go:124] Gathering logs for kube-proxy [067e7d061ba4] ...
I1017 17:12:51.089494   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 067e7d061ba4"
I1017 17:12:51.105217   28215 logs.go:124] Gathering logs for storage-provisioner [7b133da22f8c] ...
I1017 17:12:51.105228   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7b133da22f8c"
I1017 17:12:51.119944   28215 logs.go:124] Gathering logs for kube-apiserver [a4953fa9a9a9] ...
I1017 17:12:51.119954   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a4953fa9a9a9"
I1017 17:12:51.138588   28215 logs.go:124] Gathering logs for kube-apiserver [793d0a98cfba] ...
I1017 17:12:51.138599   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 793d0a98cfba"
I1017 17:12:51.161688   28215 logs.go:124] Gathering logs for etcd [d68a4772ec61] ...
I1017 17:12:51.161700   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d68a4772ec61"
I1017 17:12:51.181420   28215 logs.go:124] Gathering logs for kube-scheduler [f4a15e9e42a9] ...
I1017 17:12:51.181431   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f4a15e9e42a9"
I1017 17:12:53.700328   28215 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I1017 17:12:58.702435   28215 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": dial tcp 10.0.2.15:8443: i/o timeout (Client.Timeout exceeded while awaiting headers)
I1017 17:12:58.702722   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I1017 17:12:58.714830   28215 logs.go:279] 2 containers: [a4953fa9a9a9 793d0a98cfba]
I1017 17:12:58.714934   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I1017 17:12:58.724349   28215 logs.go:279] 2 containers: [d68a4772ec61 87638495abba]
I1017 17:12:58.724442   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I1017 17:12:58.734510   28215 logs.go:279] 1 containers: [9d8ce9c34f4f]
I1017 17:12:58.734610   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I1017 17:12:58.743819   28215 logs.go:279] 2 containers: [f4a15e9e42a9 d7899b5676a6]
I1017 17:12:58.743925   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I1017 17:12:58.753437   28215 logs.go:279] 2 containers: [7683deae11fa 067e7d061ba4]
I1017 17:12:58.753531   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I1017 17:12:58.763463   28215 logs.go:279] 0 containers: []
W1017 17:12:58.763471   28215 logs.go:281] No container was found matching "kubernetes-dashboard"
I1017 17:12:58.763594   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I1017 17:12:58.773710   28215 logs.go:279] 2 containers: [7b133da22f8c a898719c42cf]
I1017 17:12:58.773811   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I1017 17:12:58.783841   28215 logs.go:279] 2 containers: [9d5cc400d287 b069ae6fcb01]
I1017 17:12:58.783859   28215 logs.go:124] Gathering logs for kube-proxy [067e7d061ba4] ...
I1017 17:12:58.783864   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 067e7d061ba4"
I1017 17:12:58.795169   28215 logs.go:124] Gathering logs for storage-provisioner [7b133da22f8c] ...
I1017 17:12:58.795177   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7b133da22f8c"
I1017 17:12:58.805489   28215 logs.go:124] Gathering logs for storage-provisioner [a898719c42cf] ...
I1017 17:12:58.805498   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a898719c42cf"
I1017 17:12:58.816684   28215 logs.go:124] Gathering logs for dmesg ...
I1017 17:12:58.816694   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I1017 17:12:58.822102   28215 logs.go:124] Gathering logs for describe nodes ...
I1017 17:12:58.822111   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.26.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I1017 17:12:58.887674   28215 logs.go:124] Gathering logs for etcd [d68a4772ec61] ...
I1017 17:12:58.887685   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d68a4772ec61"
I1017 17:12:58.905149   28215 logs.go:124] Gathering logs for kube-scheduler [f4a15e9e42a9] ...
I1017 17:12:58.905158   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f4a15e9e42a9"
I1017 17:12:58.918340   28215 logs.go:124] Gathering logs for kube-proxy [7683deae11fa] ...
I1017 17:12:58.918351   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7683deae11fa"
I1017 17:12:58.933425   28215 logs.go:124] Gathering logs for kube-controller-manager [9d5cc400d287] ...
I1017 17:12:58.933435   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9d5cc400d287"
I1017 17:12:58.954982   28215 logs.go:124] Gathering logs for kubelet ...
I1017 17:12:58.954993   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I1017 17:12:59.031351   28215 logs.go:124] Gathering logs for kube-apiserver [a4953fa9a9a9] ...
I1017 17:12:59.031362   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a4953fa9a9a9"
I1017 17:12:59.049395   28215 logs.go:124] Gathering logs for kube-controller-manager [b069ae6fcb01] ...
I1017 17:12:59.049406   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b069ae6fcb01"
I1017 17:12:59.072368   28215 logs.go:124] Gathering logs for container status ...
I1017 17:12:59.072380   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I1017 17:12:59.095425   28215 logs.go:124] Gathering logs for kube-apiserver [793d0a98cfba] ...
I1017 17:12:59.095437   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 793d0a98cfba"
I1017 17:12:59.120166   28215 logs.go:124] Gathering logs for etcd [87638495abba] ...
I1017 17:12:59.120180   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 87638495abba"
I1017 17:12:59.140208   28215 logs.go:124] Gathering logs for coredns [9d8ce9c34f4f] ...
I1017 17:12:59.140219   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9d8ce9c34f4f"
I1017 17:12:59.154619   28215 logs.go:124] Gathering logs for kube-scheduler [d7899b5676a6] ...
I1017 17:12:59.154630   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d7899b5676a6"
I1017 17:12:59.169275   28215 logs.go:124] Gathering logs for Docker ...
I1017 17:12:59.169286   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I1017 17:13:01.699074   28215 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I1017 17:13:06.699472   28215 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I1017 17:13:07.202409   28215 kubeadm.go:637] restartCluster took 4m15.922856583s
W1017 17:13:07.202939   28215 out.go:239] 🤦  Unable to restart cluster, will reset it: apiserver health: apiserver healthz never reported healthy: cluster wait timed out during healthz check
I1017 17:13:07.202971   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.26.1:$PATH" kubeadm reset --cri-socket /var/run/cri-dockerd.sock --force"
I1017 17:13:10.320074   28215 ssh_runner.go:235] Completed: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.26.1:$PATH" kubeadm reset --cri-socket /var/run/cri-dockerd.sock --force": (3.117098958s)
I1017 17:13:10.321143   28215 ssh_runner.go:195] Run: sudo systemctl is-active --quiet service kubelet
I1017 17:13:10.328983   28215 ssh_runner.go:195] Run: sudo cp /var/tmp/minikube/kubeadm.yaml.new /var/tmp/minikube/kubeadm.yaml
I1017 17:13:10.334148   28215 ssh_runner.go:195] Run: sudo ls -la /etc/kubernetes/admin.conf /etc/kubernetes/kubelet.conf /etc/kubernetes/controller-manager.conf /etc/kubernetes/scheduler.conf
I1017 17:13:10.338978   28215 kubeadm.go:152] config check failed, skipping stale config cleanup: sudo ls -la /etc/kubernetes/admin.conf /etc/kubernetes/kubelet.conf /etc/kubernetes/controller-manager.conf /etc/kubernetes/scheduler.conf: Process exited with status 2
stdout:

stderr:
ls: cannot access '/etc/kubernetes/admin.conf': No such file or directory
ls: cannot access '/etc/kubernetes/kubelet.conf': No such file or directory
ls: cannot access '/etc/kubernetes/controller-manager.conf': No such file or directory
ls: cannot access '/etc/kubernetes/scheduler.conf': No such file or directory
I1017 17:13:10.339001   28215 ssh_runner.go:286] Start: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.26.1:$PATH" kubeadm init --config /var/tmp/minikube/kubeadm.yaml  --ignore-preflight-errors=DirAvailable--etc-kubernetes-manifests,DirAvailable--var-lib-minikube,DirAvailable--var-lib-minikube-etcd,FileAvailable--etc-kubernetes-manifests-kube-scheduler.yaml,FileAvailable--etc-kubernetes-manifests-kube-apiserver.yaml,FileAvailable--etc-kubernetes-manifests-kube-controller-manager.yaml,FileAvailable--etc-kubernetes-manifests-etcd.yaml,Port-10250,Swap,NumCPU,Mem"
I1017 17:13:10.371758   28215 kubeadm.go:322] [init] Using Kubernetes version: v1.26.1
I1017 17:13:10.371794   28215 kubeadm.go:322] [preflight] Running pre-flight checks
I1017 17:13:10.463855   28215 kubeadm.go:322] [preflight] Pulling images required for setting up a Kubernetes cluster
I1017 17:13:10.463947   28215 kubeadm.go:322] [preflight] This might take a minute or two, depending on the speed of your internet connection
I1017 17:13:10.464048   28215 kubeadm.go:322] [preflight] You can also perform this action in beforehand using 'kubeadm config images pull'
I1017 17:13:10.549537   28215 kubeadm.go:322] [certs] Using certificateDir folder "/var/lib/minikube/certs"
I1017 17:13:10.588147   28215 out.go:204]     ▪ Generating certificates and keys ...
I1017 17:13:10.588246   28215 kubeadm.go:322] [certs] Using existing ca certificate authority
I1017 17:13:10.588288   28215 kubeadm.go:322] [certs] Using existing apiserver certificate and key on disk
I1017 17:13:10.588340   28215 kubeadm.go:322] [certs] Using existing apiserver-kubelet-client certificate and key on disk
I1017 17:13:10.588380   28215 kubeadm.go:322] [certs] Using existing front-proxy-ca certificate authority
I1017 17:13:10.588448   28215 kubeadm.go:322] [certs] Using existing front-proxy-client certificate and key on disk
I1017 17:13:10.588486   28215 kubeadm.go:322] [certs] Using existing etcd/ca certificate authority
I1017 17:13:10.588532   28215 kubeadm.go:322] [certs] Using existing etcd/server certificate and key on disk
I1017 17:13:10.588601   28215 kubeadm.go:322] [certs] Using existing etcd/peer certificate and key on disk
I1017 17:13:10.588659   28215 kubeadm.go:322] [certs] Using existing etcd/healthcheck-client certificate and key on disk
I1017 17:13:10.588731   28215 kubeadm.go:322] [certs] Using existing apiserver-etcd-client certificate and key on disk
I1017 17:13:10.588775   28215 kubeadm.go:322] [certs] Using the existing "sa" key
I1017 17:13:10.588823   28215 kubeadm.go:322] [kubeconfig] Using kubeconfig folder "/etc/kubernetes"
I1017 17:13:10.744160   28215 kubeadm.go:322] [kubeconfig] Writing "admin.conf" kubeconfig file
I1017 17:13:10.828519   28215 kubeadm.go:322] [kubeconfig] Writing "kubelet.conf" kubeconfig file
I1017 17:13:11.144798   28215 kubeadm.go:322] [kubeconfig] Writing "controller-manager.conf" kubeconfig file
I1017 17:13:11.328231   28215 kubeadm.go:322] [kubeconfig] Writing "scheduler.conf" kubeconfig file
I1017 17:13:11.339258   28215 kubeadm.go:322] [kubelet-start] Writing kubelet environment file with flags to file "/var/lib/kubelet/kubeadm-flags.env"
I1017 17:13:11.339342   28215 kubeadm.go:322] [kubelet-start] Writing kubelet configuration to file "/var/lib/kubelet/config.yaml"
I1017 17:13:11.339384   28215 kubeadm.go:322] [kubelet-start] Starting the kubelet
I1017 17:13:11.448900   28215 kubeadm.go:322] [control-plane] Using manifest folder "/etc/kubernetes/manifests"
I1017 17:13:11.467541   28215 out.go:204]     ▪ Booting up control plane ...
I1017 17:13:11.467677   28215 kubeadm.go:322] [control-plane] Creating static Pod manifest for "kube-apiserver"
I1017 17:13:11.467740   28215 kubeadm.go:322] [control-plane] Creating static Pod manifest for "kube-controller-manager"
I1017 17:13:11.467786   28215 kubeadm.go:322] [control-plane] Creating static Pod manifest for "kube-scheduler"
I1017 17:13:11.467861   28215 kubeadm.go:322] [etcd] Creating static Pod manifest for local etcd in "/etc/kubernetes/manifests"
I1017 17:13:11.468011   28215 kubeadm.go:322] [wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory "/etc/kubernetes/manifests". This can take up to 4m0s
I1017 17:13:17.457019   28215 kubeadm.go:322] [apiclient] All control plane components are healthy after 6.001621 seconds
I1017 17:13:17.457080   28215 kubeadm.go:322] [upload-config] Storing the configuration used in ConfigMap "kubeadm-config" in the "kube-system" Namespace
I1017 17:13:17.463370   28215 kubeadm.go:322] [kubelet] Creating a ConfigMap "kubelet-config" in namespace kube-system with the configuration for the kubelets in the cluster
I1017 17:13:17.976989   28215 kubeadm.go:322] [upload-certs] Skipping phase. Please see --upload-certs
I1017 17:13:17.977108   28215 kubeadm.go:322] [mark-control-plane] Marking the node minikube as control-plane by adding the labels: [node-role.kubernetes.io/control-plane node.kubernetes.io/exclude-from-external-load-balancers]
I1017 17:13:18.487350   28215 kubeadm.go:322] [bootstrap-token] Using token: qicyoh.eypvrjm2sb5rxqo0
I1017 17:13:18.522843   28215 out.go:204]     ▪ Configuring RBAC rules ...
I1017 17:13:18.522923   28215 kubeadm.go:322] [bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles
I1017 17:13:18.524836   28215 kubeadm.go:322] [bootstrap-token] Configured RBAC rules to allow Node Bootstrap tokens to get nodes
I1017 17:13:18.563471   28215 kubeadm.go:322] [bootstrap-token] Configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials
I1017 17:13:18.565803   28215 kubeadm.go:322] [bootstrap-token] Configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token
I1017 17:13:18.568388   28215 kubeadm.go:322] [bootstrap-token] Configured RBAC rules to allow certificate rotation for all node client certificates in the cluster
I1017 17:13:18.569968   28215 kubeadm.go:322] [bootstrap-token] Creating the "cluster-info" ConfigMap in the "kube-public" namespace
I1017 17:13:18.576409   28215 kubeadm.go:322] [kubelet-finalize] Updating "/etc/kubernetes/kubelet.conf" to point to a rotatable kubelet client certificate and key
I1017 17:13:18.801473   28215 kubeadm.go:322] [addons] Applied essential addon: CoreDNS
I1017 17:13:18.928828   28215 kubeadm.go:322] [addons] Applied essential addon: kube-proxy
I1017 17:13:18.929648   28215 kubeadm.go:322] 
I1017 17:13:18.929686   28215 kubeadm.go:322] Your Kubernetes control-plane has initialized successfully!
I1017 17:13:18.929741   28215 kubeadm.go:322] 
I1017 17:13:18.929820   28215 kubeadm.go:322] To start using your cluster, you need to run the following as a regular user:
I1017 17:13:18.929828   28215 kubeadm.go:322] 
I1017 17:13:18.929843   28215 kubeadm.go:322]   mkdir -p $HOME/.kube
I1017 17:13:18.929891   28215 kubeadm.go:322]   sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
I1017 17:13:18.929924   28215 kubeadm.go:322]   sudo chown $(id -u):$(id -g) $HOME/.kube/config
I1017 17:13:18.929926   28215 kubeadm.go:322] 
I1017 17:13:18.929972   28215 kubeadm.go:322] Alternatively, if you are the root user, you can run:
I1017 17:13:18.929976   28215 kubeadm.go:322] 
I1017 17:13:18.930019   28215 kubeadm.go:322]   export KUBECONFIG=/etc/kubernetes/admin.conf
I1017 17:13:18.930023   28215 kubeadm.go:322] 
I1017 17:13:18.930064   28215 kubeadm.go:322] You should now deploy a pod network to the cluster.
I1017 17:13:18.930117   28215 kubeadm.go:322] Run "kubectl apply -f [podnetwork].yaml" with one of the options listed at:
I1017 17:13:18.930171   28215 kubeadm.go:322]   https://kubernetes.io/docs/concepts/cluster-administration/addons/
I1017 17:13:18.930174   28215 kubeadm.go:322] 
I1017 17:13:18.930253   28215 kubeadm.go:322] You can now join any number of control-plane nodes by copying certificate authorities
I1017 17:13:18.930304   28215 kubeadm.go:322] and service account keys on each node and then running the following as root:
I1017 17:13:18.930306   28215 kubeadm.go:322] 
I1017 17:13:18.930379   28215 kubeadm.go:322]   kubeadm join control-plane.minikube.internal:8443 --token qicyoh.eypvrjm2sb5rxqo0 \
I1017 17:13:18.930442   28215 kubeadm.go:322] 	--discovery-token-ca-cert-hash sha256:d1003e6a29515f0d0fb76199b7d3e71211dcf6223bba982db606c6c5a7b29297 \
I1017 17:13:18.930454   28215 kubeadm.go:322] 	--control-plane 
I1017 17:13:18.930456   28215 kubeadm.go:322] 
I1017 17:13:18.930507   28215 kubeadm.go:322] Then you can join any number of worker nodes by running the following on each as root:
I1017 17:13:18.930509   28215 kubeadm.go:322] 
I1017 17:13:18.930557   28215 kubeadm.go:322] kubeadm join control-plane.minikube.internal:8443 --token qicyoh.eypvrjm2sb5rxqo0 \
I1017 17:13:18.930619   28215 kubeadm.go:322] 	--discovery-token-ca-cert-hash sha256:d1003e6a29515f0d0fb76199b7d3e71211dcf6223bba982db606c6c5a7b29297 
I1017 17:13:18.931054   28215 kubeadm.go:322] W1017 11:43:10.500962   10228 initconfiguration.go:119] Usage of CRI endpoints without URL scheme is deprecated and can cause kubelet errors in the future. Automatically prepending scheme "unix" to the "criSocket" with value "/var/run/cri-dockerd.sock". Please update your configuration!
I1017 17:13:18.931142   28215 kubeadm.go:322] 	[WARNING Service-Kubelet]: kubelet service is not enabled, please run 'systemctl enable kubelet.service'
I1017 17:13:18.931162   28215 cni.go:84] Creating CNI manager for ""
I1017 17:13:18.931178   28215 cni.go:157] "qemu2" driver + "docker" container runtime found on kubernetes v1.24+, recommending bridge
I1017 17:13:18.968295   28215 out.go:177] 🔗  Configuring bridge CNI (Container Networking Interface) ...
I1017 17:13:19.039063   28215 ssh_runner.go:195] Run: sudo mkdir -p /etc/cni/net.d
I1017 17:13:19.049994   28215 ssh_runner.go:362] scp memory --> /etc/cni/net.d/1-k8s.conflist (457 bytes)
I1017 17:13:19.059556   28215 ssh_runner.go:195] Run: /bin/bash -c "cat /proc/$(pgrep kube-apiserver)/oom_adj"
I1017 17:13:19.059714   28215 ssh_runner.go:195] Run: sudo /var/lib/minikube/binaries/v1.26.1/kubectl create clusterrolebinding minikube-rbac --clusterrole=cluster-admin --serviceaccount=kube-system:default --kubeconfig=/var/lib/minikube/kubeconfig
I1017 17:13:19.060248   28215 ssh_runner.go:195] Run: sudo /var/lib/minikube/binaries/v1.26.1/kubectl label nodes minikube.k8s.io/version=v1.29.0 minikube.k8s.io/commit=ddac20b4b34a9c8c857fc602203b6ba2679794d3 minikube.k8s.io/name=minikube minikube.k8s.io/updated_at=2023_10_17T17_13_19_0700 minikube.k8s.io/primary=true --all --overwrite --kubeconfig=/var/lib/minikube/kubeconfig
I1017 17:13:19.127709   28215 kubeadm.go:1073] duration metric: took 68.100083ms to wait for elevateKubeSystemPrivileges.
I1017 17:13:19.127925   28215 ops.go:34] apiserver oom_adj: -16
I1017 17:13:19.145242   28215 host.go:66] Checking if "minikube" exists ...
I1017 17:13:19.147162   28215 main.go:141] libmachine: Using SSH client type: external
I1017 17:13:19.147209   28215 main.go:141] libmachine: Using SSH private key: /Users/ashujauhari/.minikube/machines/minikube/id_rsa (-rw-------)
I1017 17:13:19.147230   28215 main.go:141] libmachine: &{[-F /dev/null -o ConnectionAttempts=3 -o ConnectTimeout=10 -o ControlMaster=no -o ControlPath=none -o LogLevel=quiet -o PasswordAuthentication=no -o ServerAliveInterval=60 -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null docker@localhost -o IdentitiesOnly=yes -i /Users/ashujauhari/.minikube/machines/minikube/id_rsa -p 55250] /usr/bin/ssh <nil>}
I1017 17:13:19.147246   28215 main.go:141] libmachine: /usr/bin/ssh -F /dev/null -o ConnectionAttempts=3 -o ConnectTimeout=10 -o ControlMaster=no -o ControlPath=none -o LogLevel=quiet -o PasswordAuthentication=no -o ServerAliveInterval=60 -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null docker@localhost -o IdentitiesOnly=yes -i /Users/ashujauhari/.minikube/machines/minikube/id_rsa -p 55250 -f -NTL 49338:localhost:8443
I1017 17:13:19.253951   28215 kubeadm.go:403] StartCluster complete in 4m28.085672s
I1017 17:13:19.254001   28215 settings.go:142] acquiring lock: {Name:mk2d78b39fdffd2c25552a4c483022296cada60d Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I1017 17:13:19.254330   28215 settings.go:150] Updating kubeconfig:  /Users/ashujauhari/.kube/config
I1017 17:13:19.257464   28215 lock.go:35] WriteFile acquiring /Users/ashujauhari/.kube/config: {Name:mke38aee53c70a24ab9bd1ba88bb9a09437bd913 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I1017 17:13:19.258397   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.26.1/kubectl --kubeconfig=/var/lib/minikube/kubeconfig -n kube-system get configmap coredns -o yaml"
I1017 17:13:19.258660   28215 addons.go:489] enable addons start: toEnable=map[ambassador:false auto-pause:false cloud-spanner:false csi-hostpath-driver:false dashboard:false default-storageclass:true efk:false freshpod:false gcp-auth:false gvisor:false headlamp:false helm-tiller:false inaccel:false ingress:false ingress-dns:false istio:false istio-provisioner:false kong:false kubevirt:false logviewer:false metallb:false metrics-server:false nvidia-driver-installer:false nvidia-gpu-device-plugin:false olm:false pod-security-policy:false portainer:false registry:false registry-aliases:false registry-creds:false storage-provisioner:true storage-provisioner-gluster:false volumesnapshots:false]
I1017 17:13:19.258720   28215 addons.go:65] Setting storage-provisioner=true in profile "minikube"
I1017 17:13:19.258729   28215 addons.go:227] Setting addon storage-provisioner=true in "minikube"
I1017 17:13:19.258724   28215 config.go:180] Loaded profile config "minikube": Driver=qemu2, ContainerRuntime=docker, KubernetesVersion=v1.26.1
W1017 17:13:19.258732   28215 addons.go:236] addon storage-provisioner should already be in state true
I1017 17:13:19.258943   28215 addons.go:65] Setting default-storageclass=true in profile "minikube"
I1017 17:13:19.258964   28215 addons_storage_classes.go:33] enableOrDisableStorageClasses default-storageclass=true on "minikube"
I1017 17:13:19.259063   28215 host.go:66] Checking if "minikube" exists ...
I1017 17:13:19.282686   28215 out.go:177]     ▪ Using image gcr.io/k8s-minikube/storage-provisioner:v5
I1017 17:13:19.301863   28215 addons.go:419] installing /etc/kubernetes/addons/storage-provisioner.yaml
I1017 17:13:19.301871   28215 ssh_runner.go:362] scp memory --> /etc/kubernetes/addons/storage-provisioner.yaml (2676 bytes)
I1017 17:13:19.301883   28215 sshutil.go:53] new ssh client: &{IP:localhost Port:55250 SSHKeyPath:/Users/ashujauhari/.minikube/machines/minikube/id_rsa Username:docker}
I1017 17:13:19.311752   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.26.1/kubectl --kubeconfig=/var/lib/minikube/kubeconfig -n kube-system get configmap coredns -o yaml | sed -e '/^        forward . \/etc\/resolv.conf.*/i \        hosts {\n           10.0.2.2 host.minikube.internal\n           fallthrough\n        }' -e '/^        errors *$/i \        log' | sudo /var/lib/minikube/binaries/v1.26.1/kubectl --kubeconfig=/var/lib/minikube/kubeconfig replace -f -"
I1017 17:13:19.397367   28215 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.26.1/kubectl apply -f /etc/kubernetes/addons/storage-provisioner.yaml
I1017 17:13:19.985356   28215 start.go:919] {"host.minikube.internal": 10.0.2.2} host record injected into CoreDNS's ConfigMap
W1017 17:13:49.267360   28215 out.go:239] ❗  Enabling 'default-storageclass' returned an error: running callbacks: [Error making standard the default storage class: Error listing StorageClasses: Get "https://10.0.2.15:8443/apis/storage.k8s.io/v1/storageclasses": dial tcp 10.0.2.15:8443: i/o timeout]
W1017 17:13:49.267553   28215 kapi.go:245] failed rescaling "coredns" deployment in "kube-system" namespace and "minikube" context to 1 replicas: non-retryable failure while getting "coredns" deployment scale: Get "https://10.0.2.15:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": dial tcp 10.0.2.15:8443: i/o timeout
I1017 17:13:49.287635   28215 out.go:177] 🌟  Enabled addons: storage-provisioner
E1017 17:13:49.287637   28215 start.go:219] Unable to scale down deployment "coredns" in namespace "kube-system" to 1 replica: non-retryable failure while getting "coredns" deployment scale: Get "https://10.0.2.15:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": dial tcp 10.0.2.15:8443: i/o timeout
I1017 17:13:49.287943   28215 start.go:223] Will wait 6m0s for node &{Name: IP:10.0.2.15 Port:8443 KubernetesVersion:v1.26.1 ContainerRuntime:docker ControlPlane:true Worker:true}
I1017 17:13:49.345105   28215 addons.go:492] enable addons completed in 30.086518125s: enabled=[storage-provisioner]
I1017 17:13:49.364225   28215 out.go:177] 🔎  Verifying Kubernetes components...
I1017 17:13:49.401776   28215 ssh_runner.go:195] Run: sudo systemctl is-active --quiet service kubelet
I1017 17:13:49.414980   28215 api_server.go:51] waiting for apiserver process to appear ...
I1017 17:13:49.415680   28215 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I1017 17:13:49.428199   28215 api_server.go:71] duration metric: took 83.07075ms to wait for apiserver process to appear ...
I1017 17:13:49.428209   28215 api_server.go:87] waiting for apiserver healthz status ...
I1017 17:13:49.428216   28215 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I1017 17:13:54.433624   28215 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I1017 17:13:54.938670   28215 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I1017 17:13:59.938881   28215 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": dial tcp 10.0.2.15:8443: i/o timeout (Client.Timeout exceeded while awaiting headers)
I1017 17:14:00.438784   28215 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I1017 17:14:05.439140   28215 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I1017 17:14:05.935827   28215 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I1017 17:14:10.938562   28215 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I1017 17:14:11.438629   28215 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I1017 17:14:16.439147   28215 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I1017 17:14:16.938178   28215 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I1017 17:14:21.938608   28215 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I1017 17:14:22.435966   28215 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I1017 17:14:27.438813   28215 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": dial tcp 10.0.2.15:8443: i/o timeout (Client.Timeout exceeded while awaiting headers)
I1017 17:14:27.438842   28215 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I1017 17:14:32.439550   28215 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I1017 17:14:32.937715   28215 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I1017 17:14:37.937929   28215 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I1017 17:14:38.438604   28215 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I1017 17:14:43.438887   28215 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I1017 17:14:43.937432   28215 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I1017 17:14:48.938349   28215 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I1017 17:14:49.438225   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I1017 17:14:49.456979   28215 logs.go:279] 1 containers: [d8959036328f]
I1017 17:14:49.457079   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I1017 17:14:49.465503   28215 logs.go:279] 1 containers: [2730cc2aef95]
I1017 17:14:49.465591   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I1017 17:14:49.474123   28215 logs.go:279] 2 containers: [926759e7f212 ba6cf9e5453e]
I1017 17:14:49.474214   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I1017 17:14:49.484057   28215 logs.go:279] 1 containers: [31cc51d3bc7c]
I1017 17:14:49.484323   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I1017 17:14:49.494886   28215 logs.go:279] 1 containers: [468210b9872f]
I1017 17:14:49.494972   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I1017 17:14:49.504941   28215 logs.go:279] 0 containers: []
W1017 17:14:49.504949   28215 logs.go:281] No container was found matching "kubernetes-dashboard"
I1017 17:14:49.505076   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I1017 17:14:49.513445   28215 logs.go:279] 1 containers: [6106b035dda1]
I1017 17:14:49.513640   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I1017 17:14:49.522381   28215 logs.go:279] 1 containers: [001ef48cc07d]
I1017 17:14:49.522395   28215 logs.go:124] Gathering logs for describe nodes ...
I1017 17:14:49.522400   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.26.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I1017 17:14:49.574497   28215 logs.go:124] Gathering logs for etcd [2730cc2aef95] ...
I1017 17:14:49.574506   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2730cc2aef95"
I1017 17:14:49.587372   28215 logs.go:124] Gathering logs for coredns [926759e7f212] ...
I1017 17:14:49.587381   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 926759e7f212"
I1017 17:14:49.597844   28215 logs.go:124] Gathering logs for kube-scheduler [31cc51d3bc7c] ...
I1017 17:14:49.597853   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 31cc51d3bc7c"
I1017 17:14:49.612540   28215 logs.go:124] Gathering logs for storage-provisioner [6106b035dda1] ...
I1017 17:14:49.612550   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 6106b035dda1"
I1017 17:14:49.622575   28215 logs.go:124] Gathering logs for Docker ...
I1017 17:14:49.622583   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I1017 17:14:49.649768   28215 logs.go:124] Gathering logs for container status ...
I1017 17:14:49.649778   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I1017 17:14:49.665225   28215 logs.go:124] Gathering logs for dmesg ...
I1017 17:14:49.665234   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I1017 17:14:49.670306   28215 logs.go:124] Gathering logs for kube-apiserver [d8959036328f] ...
I1017 17:14:49.670314   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d8959036328f"
I1017 17:14:49.682894   28215 logs.go:124] Gathering logs for coredns [ba6cf9e5453e] ...
I1017 17:14:49.682903   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 ba6cf9e5453e"
I1017 17:14:49.692080   28215 logs.go:124] Gathering logs for kube-proxy [468210b9872f] ...
I1017 17:14:49.692088   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 468210b9872f"
I1017 17:14:49.703492   28215 logs.go:124] Gathering logs for kube-controller-manager [001ef48cc07d] ...
I1017 17:14:49.703505   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 001ef48cc07d"
I1017 17:14:49.719275   28215 logs.go:124] Gathering logs for kubelet ...
I1017 17:14:49.719285   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I1017 17:14:52.267558   28215 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I1017 17:14:57.272691   28215 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I1017 17:14:57.438576   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I1017 17:14:57.449581   28215 logs.go:279] 1 containers: [d8959036328f]
I1017 17:14:57.449666   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I1017 17:14:57.458683   28215 logs.go:279] 1 containers: [2730cc2aef95]
I1017 17:14:57.458774   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I1017 17:14:57.467732   28215 logs.go:279] 2 containers: [926759e7f212 ba6cf9e5453e]
I1017 17:14:57.467828   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I1017 17:14:57.476657   28215 logs.go:279] 1 containers: [31cc51d3bc7c]
I1017 17:14:57.497781   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I1017 17:14:57.507720   28215 logs.go:279] 1 containers: [468210b9872f]
I1017 17:14:57.507809   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I1017 17:14:57.516542   28215 logs.go:279] 0 containers: []
W1017 17:14:57.516549   28215 logs.go:281] No container was found matching "kubernetes-dashboard"
I1017 17:14:57.516644   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I1017 17:14:57.526081   28215 logs.go:279] 1 containers: [6106b035dda1]
I1017 17:14:57.526176   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I1017 17:14:57.536352   28215 logs.go:279] 1 containers: [001ef48cc07d]
I1017 17:14:57.536364   28215 logs.go:124] Gathering logs for describe nodes ...
I1017 17:14:57.536368   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.26.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I1017 17:14:57.580944   28215 logs.go:124] Gathering logs for coredns [926759e7f212] ...
I1017 17:14:57.580953   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 926759e7f212"
I1017 17:14:57.590460   28215 logs.go:124] Gathering logs for kube-scheduler [31cc51d3bc7c] ...
I1017 17:14:57.590469   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 31cc51d3bc7c"
I1017 17:14:57.604391   28215 logs.go:124] Gathering logs for kube-proxy [468210b9872f] ...
I1017 17:14:57.604401   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 468210b9872f"
I1017 17:14:57.616216   28215 logs.go:124] Gathering logs for storage-provisioner [6106b035dda1] ...
I1017 17:14:57.616225   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 6106b035dda1"
I1017 17:14:57.625768   28215 logs.go:124] Gathering logs for Docker ...
I1017 17:14:57.625777   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I1017 17:14:57.652186   28215 logs.go:124] Gathering logs for container status ...
I1017 17:14:57.652197   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I1017 17:14:57.665999   28215 logs.go:124] Gathering logs for kubelet ...
I1017 17:14:57.666009   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I1017 17:14:57.709004   28215 logs.go:124] Gathering logs for kube-apiserver [d8959036328f] ...
I1017 17:14:57.709014   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d8959036328f"
I1017 17:14:57.723375   28215 logs.go:124] Gathering logs for etcd [2730cc2aef95] ...
I1017 17:14:57.723384   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2730cc2aef95"
I1017 17:14:57.735991   28215 logs.go:124] Gathering logs for coredns [ba6cf9e5453e] ...
I1017 17:14:57.736000   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 ba6cf9e5453e"
I1017 17:14:57.747527   28215 logs.go:124] Gathering logs for kube-controller-manager [001ef48cc07d] ...
I1017 17:14:57.747537   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 001ef48cc07d"
I1017 17:14:57.764756   28215 logs.go:124] Gathering logs for dmesg ...
I1017 17:14:57.764786   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I1017 17:15:00.274808   28215 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I1017 17:15:05.277880   28215 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I1017 17:15:05.438697   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I1017 17:15:05.454237   28215 logs.go:279] 1 containers: [d8959036328f]
I1017 17:15:05.454339   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I1017 17:15:05.462772   28215 logs.go:279] 1 containers: [2730cc2aef95]
I1017 17:15:05.462868   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I1017 17:15:05.472429   28215 logs.go:279] 2 containers: [926759e7f212 ba6cf9e5453e]
I1017 17:15:05.472526   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I1017 17:15:05.485161   28215 logs.go:279] 1 containers: [31cc51d3bc7c]
I1017 17:15:05.485242   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I1017 17:15:05.494011   28215 logs.go:279] 1 containers: [468210b9872f]
I1017 17:15:05.494108   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I1017 17:15:05.504078   28215 logs.go:279] 0 containers: []
W1017 17:15:05.504086   28215 logs.go:281] No container was found matching "kubernetes-dashboard"
I1017 17:15:05.504177   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I1017 17:15:05.514439   28215 logs.go:279] 1 containers: [6106b035dda1]
I1017 17:15:05.514523   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I1017 17:15:05.522979   28215 logs.go:279] 1 containers: [001ef48cc07d]
I1017 17:15:05.522990   28215 logs.go:124] Gathering logs for kube-scheduler [31cc51d3bc7c] ...
I1017 17:15:05.522994   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 31cc51d3bc7c"
I1017 17:15:05.537563   28215 logs.go:124] Gathering logs for storage-provisioner [6106b035dda1] ...
I1017 17:15:05.537573   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 6106b035dda1"
I1017 17:15:05.548218   28215 logs.go:124] Gathering logs for kube-controller-manager [001ef48cc07d] ...
I1017 17:15:05.548227   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 001ef48cc07d"
I1017 17:15:05.565736   28215 logs.go:124] Gathering logs for Docker ...
I1017 17:15:05.565748   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I1017 17:15:05.590460   28215 logs.go:124] Gathering logs for dmesg ...
I1017 17:15:05.590477   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I1017 17:15:05.595592   28215 logs.go:124] Gathering logs for describe nodes ...
I1017 17:15:05.595601   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.26.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I1017 17:15:05.641574   28215 logs.go:124] Gathering logs for etcd [2730cc2aef95] ...
I1017 17:15:05.641585   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2730cc2aef95"
I1017 17:15:05.654744   28215 logs.go:124] Gathering logs for coredns [926759e7f212] ...
I1017 17:15:05.654753   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 926759e7f212"
I1017 17:15:05.664950   28215 logs.go:124] Gathering logs for container status ...
I1017 17:15:05.664958   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I1017 17:15:05.678376   28215 logs.go:124] Gathering logs for kubelet ...
I1017 17:15:05.678384   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I1017 17:15:05.722766   28215 logs.go:124] Gathering logs for kube-apiserver [d8959036328f] ...
I1017 17:15:05.722777   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d8959036328f"
I1017 17:15:05.737183   28215 logs.go:124] Gathering logs for coredns [ba6cf9e5453e] ...
I1017 17:15:05.737191   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 ba6cf9e5453e"
I1017 17:15:05.746801   28215 logs.go:124] Gathering logs for kube-proxy [468210b9872f] ...
I1017 17:15:05.746809   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 468210b9872f"
I1017 17:15:08.260094   28215 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I1017 17:15:13.262381   28215 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I1017 17:15:13.438695   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I1017 17:15:13.451321   28215 logs.go:279] 1 containers: [d8959036328f]
I1017 17:15:13.451406   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I1017 17:15:13.460071   28215 logs.go:279] 1 containers: [2730cc2aef95]
I1017 17:15:13.460161   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I1017 17:15:13.468797   28215 logs.go:279] 2 containers: [926759e7f212 ba6cf9e5453e]
I1017 17:15:13.468889   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I1017 17:15:13.478039   28215 logs.go:279] 1 containers: [31cc51d3bc7c]
I1017 17:15:13.478127   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I1017 17:15:13.486811   28215 logs.go:279] 1 containers: [468210b9872f]
I1017 17:15:13.486905   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I1017 17:15:13.496447   28215 logs.go:279] 0 containers: []
W1017 17:15:13.496456   28215 logs.go:281] No container was found matching "kubernetes-dashboard"
I1017 17:15:13.496563   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I1017 17:15:13.509152   28215 logs.go:279] 1 containers: [6106b035dda1]
I1017 17:15:13.509237   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I1017 17:15:13.518301   28215 logs.go:279] 1 containers: [001ef48cc07d]
I1017 17:15:13.518313   28215 logs.go:124] Gathering logs for kubelet ...
I1017 17:15:13.518317   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I1017 17:15:13.561057   28215 logs.go:124] Gathering logs for coredns [926759e7f212] ...
I1017 17:15:13.561067   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 926759e7f212"
I1017 17:15:13.571163   28215 logs.go:124] Gathering logs for coredns [ba6cf9e5453e] ...
I1017 17:15:13.571172   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 ba6cf9e5453e"
I1017 17:15:13.580459   28215 logs.go:124] Gathering logs for storage-provisioner [6106b035dda1] ...
I1017 17:15:13.580468   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 6106b035dda1"
I1017 17:15:13.592661   28215 logs.go:124] Gathering logs for container status ...
I1017 17:15:13.592670   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I1017 17:15:13.605859   28215 logs.go:124] Gathering logs for Docker ...
I1017 17:15:13.605867   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I1017 17:15:13.629095   28215 logs.go:124] Gathering logs for dmesg ...
I1017 17:15:13.629107   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I1017 17:15:13.634294   28215 logs.go:124] Gathering logs for describe nodes ...
I1017 17:15:13.634303   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.26.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I1017 17:15:13.680995   28215 logs.go:124] Gathering logs for kube-apiserver [d8959036328f] ...
I1017 17:15:13.681010   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d8959036328f"
I1017 17:15:13.694206   28215 logs.go:124] Gathering logs for etcd [2730cc2aef95] ...
I1017 17:15:13.694215   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2730cc2aef95"
I1017 17:15:13.706828   28215 logs.go:124] Gathering logs for kube-scheduler [31cc51d3bc7c] ...
I1017 17:15:13.706837   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 31cc51d3bc7c"
I1017 17:15:13.721504   28215 logs.go:124] Gathering logs for kube-proxy [468210b9872f] ...
I1017 17:15:13.721513   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 468210b9872f"
I1017 17:15:13.732744   28215 logs.go:124] Gathering logs for kube-controller-manager [001ef48cc07d] ...
I1017 17:15:13.732753   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 001ef48cc07d"
I1017 17:15:16.250905   28215 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I1017 17:15:21.256032   28215 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I1017 17:15:21.439647   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I1017 17:15:21.449355   28215 logs.go:279] 1 containers: [d8959036328f]
I1017 17:15:21.449458   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I1017 17:15:21.458916   28215 logs.go:279] 1 containers: [2730cc2aef95]
I1017 17:15:21.459001   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I1017 17:15:21.467715   28215 logs.go:279] 2 containers: [926759e7f212 ba6cf9e5453e]
I1017 17:15:21.467806   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I1017 17:15:21.476803   28215 logs.go:279] 1 containers: [31cc51d3bc7c]
I1017 17:15:21.476885   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I1017 17:15:21.485639   28215 logs.go:279] 1 containers: [468210b9872f]
I1017 17:15:21.485731   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I1017 17:15:21.494487   28215 logs.go:279] 0 containers: []
W1017 17:15:21.494496   28215 logs.go:281] No container was found matching "kubernetes-dashboard"
I1017 17:15:21.494583   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I1017 17:15:21.503716   28215 logs.go:279] 1 containers: [6106b035dda1]
I1017 17:15:21.503796   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I1017 17:15:21.512300   28215 logs.go:279] 1 containers: [001ef48cc07d]
I1017 17:15:21.512312   28215 logs.go:124] Gathering logs for coredns [ba6cf9e5453e] ...
I1017 17:15:21.512316   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 ba6cf9e5453e"
I1017 17:15:21.521664   28215 logs.go:124] Gathering logs for kube-proxy [468210b9872f] ...
I1017 17:15:21.521674   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 468210b9872f"
I1017 17:15:21.531873   28215 logs.go:124] Gathering logs for storage-provisioner [6106b035dda1] ...
I1017 17:15:21.531880   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 6106b035dda1"
I1017 17:15:21.541811   28215 logs.go:124] Gathering logs for container status ...
I1017 17:15:21.541826   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I1017 17:15:21.555132   28215 logs.go:124] Gathering logs for kubelet ...
I1017 17:15:21.555141   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I1017 17:15:21.595089   28215 logs.go:124] Gathering logs for dmesg ...
I1017 17:15:21.595100   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I1017 17:15:21.600199   28215 logs.go:124] Gathering logs for kube-apiserver [d8959036328f] ...
I1017 17:15:21.600207   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d8959036328f"
I1017 17:15:21.612642   28215 logs.go:124] Gathering logs for kube-scheduler [31cc51d3bc7c] ...
I1017 17:15:21.612650   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 31cc51d3bc7c"
I1017 17:15:21.628184   28215 logs.go:124] Gathering logs for kube-controller-manager [001ef48cc07d] ...
I1017 17:15:21.628193   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 001ef48cc07d"
I1017 17:15:21.645086   28215 logs.go:124] Gathering logs for Docker ...
I1017 17:15:21.645095   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I1017 17:15:21.674490   28215 logs.go:124] Gathering logs for describe nodes ...
I1017 17:15:21.674507   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.26.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I1017 17:15:21.720953   28215 logs.go:124] Gathering logs for etcd [2730cc2aef95] ...
I1017 17:15:21.720981   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2730cc2aef95"
I1017 17:15:21.735632   28215 logs.go:124] Gathering logs for coredns [926759e7f212] ...
I1017 17:15:21.735642   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 926759e7f212"
I1017 17:15:24.251126   28215 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I1017 17:15:29.253588   28215 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I1017 17:15:29.438640   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I1017 17:15:29.454681   28215 logs.go:279] 1 containers: [d8959036328f]
I1017 17:15:29.454866   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I1017 17:15:29.464422   28215 logs.go:279] 1 containers: [2730cc2aef95]
I1017 17:15:29.464508   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I1017 17:15:29.473085   28215 logs.go:279] 2 containers: [926759e7f212 ba6cf9e5453e]
I1017 17:15:29.473181   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I1017 17:15:29.481190   28215 logs.go:279] 1 containers: [31cc51d3bc7c]
I1017 17:15:29.481295   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I1017 17:15:29.490541   28215 logs.go:279] 1 containers: [468210b9872f]
I1017 17:15:29.490631   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I1017 17:15:29.499502   28215 logs.go:279] 0 containers: []
W1017 17:15:29.499511   28215 logs.go:281] No container was found matching "kubernetes-dashboard"
I1017 17:15:29.499605   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I1017 17:15:29.510043   28215 logs.go:279] 1 containers: [6106b035dda1]
I1017 17:15:29.510130   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I1017 17:15:29.519081   28215 logs.go:279] 1 containers: [001ef48cc07d]
I1017 17:15:29.519093   28215 logs.go:124] Gathering logs for storage-provisioner [6106b035dda1] ...
I1017 17:15:29.519097   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 6106b035dda1"
I1017 17:15:29.528550   28215 logs.go:124] Gathering logs for Docker ...
I1017 17:15:29.528559   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I1017 17:15:29.553802   28215 logs.go:124] Gathering logs for container status ...
I1017 17:15:29.553812   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I1017 17:15:29.567486   28215 logs.go:124] Gathering logs for dmesg ...
I1017 17:15:29.567494   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I1017 17:15:29.572322   28215 logs.go:124] Gathering logs for describe nodes ...
I1017 17:15:29.572335   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.26.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I1017 17:15:29.620987   28215 logs.go:124] Gathering logs for coredns [ba6cf9e5453e] ...
I1017 17:15:29.620996   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 ba6cf9e5453e"
I1017 17:15:29.630503   28215 logs.go:124] Gathering logs for kube-scheduler [31cc51d3bc7c] ...
I1017 17:15:29.630513   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 31cc51d3bc7c"
I1017 17:15:29.646476   28215 logs.go:124] Gathering logs for kube-proxy [468210b9872f] ...
I1017 17:15:29.646486   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 468210b9872f"
I1017 17:15:29.656635   28215 logs.go:124] Gathering logs for kubelet ...
I1017 17:15:29.656644   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I1017 17:15:29.698821   28215 logs.go:124] Gathering logs for kube-apiserver [d8959036328f] ...
I1017 17:15:29.698834   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d8959036328f"
I1017 17:15:29.712187   28215 logs.go:124] Gathering logs for etcd [2730cc2aef95] ...
I1017 17:15:29.712195   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2730cc2aef95"
I1017 17:15:29.724765   28215 logs.go:124] Gathering logs for coredns [926759e7f212] ...
I1017 17:15:29.724776   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 926759e7f212"
I1017 17:15:29.734271   28215 logs.go:124] Gathering logs for kube-controller-manager [001ef48cc07d] ...
I1017 17:15:29.734281   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 001ef48cc07d"
I1017 17:15:32.254404   28215 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I1017 17:15:37.259580   28215 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I1017 17:15:37.436847   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I1017 17:15:37.448503   28215 logs.go:279] 1 containers: [d8959036328f]
I1017 17:15:37.448586   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I1017 17:15:37.457526   28215 logs.go:279] 1 containers: [2730cc2aef95]
I1017 17:15:37.457617   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I1017 17:15:37.466203   28215 logs.go:279] 2 containers: [926759e7f212 ba6cf9e5453e]
I1017 17:15:37.466323   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I1017 17:15:37.475034   28215 logs.go:279] 1 containers: [31cc51d3bc7c]
I1017 17:15:37.493939   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I1017 17:15:37.502353   28215 logs.go:279] 1 containers: [468210b9872f]
I1017 17:15:37.502452   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I1017 17:15:37.512047   28215 logs.go:279] 0 containers: []
W1017 17:15:37.512056   28215 logs.go:281] No container was found matching "kubernetes-dashboard"
I1017 17:15:37.512138   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I1017 17:15:37.524732   28215 logs.go:279] 1 containers: [6106b035dda1]
I1017 17:15:37.524821   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I1017 17:15:37.533491   28215 logs.go:279] 1 containers: [001ef48cc07d]
I1017 17:15:37.533501   28215 logs.go:124] Gathering logs for kubelet ...
I1017 17:15:37.533505   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I1017 17:15:37.573915   28215 logs.go:124] Gathering logs for dmesg ...
I1017 17:15:37.573926   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I1017 17:15:37.578975   28215 logs.go:124] Gathering logs for etcd [2730cc2aef95] ...
I1017 17:15:37.578984   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2730cc2aef95"
I1017 17:15:37.591426   28215 logs.go:124] Gathering logs for kube-scheduler [31cc51d3bc7c] ...
I1017 17:15:37.591435   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 31cc51d3bc7c"
I1017 17:15:37.604838   28215 logs.go:124] Gathering logs for kube-proxy [468210b9872f] ...
I1017 17:15:37.604848   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 468210b9872f"
I1017 17:15:37.614776   28215 logs.go:124] Gathering logs for storage-provisioner [6106b035dda1] ...
I1017 17:15:37.614785   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 6106b035dda1"
I1017 17:15:37.624270   28215 logs.go:124] Gathering logs for kube-controller-manager [001ef48cc07d] ...
I1017 17:15:37.624280   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 001ef48cc07d"
I1017 17:15:37.640190   28215 logs.go:124] Gathering logs for container status ...
I1017 17:15:37.640198   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I1017 17:15:37.653014   28215 logs.go:124] Gathering logs for describe nodes ...
I1017 17:15:37.653023   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.26.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I1017 17:15:37.719263   28215 logs.go:124] Gathering logs for kube-apiserver [d8959036328f] ...
I1017 17:15:37.719274   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d8959036328f"
I1017 17:15:37.734391   28215 logs.go:124] Gathering logs for coredns [926759e7f212] ...
I1017 17:15:37.734400   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 926759e7f212"
I1017 17:15:37.746966   28215 logs.go:124] Gathering logs for coredns [ba6cf9e5453e] ...
I1017 17:15:37.746975   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 ba6cf9e5453e"
I1017 17:15:37.757305   28215 logs.go:124] Gathering logs for Docker ...
I1017 17:15:37.757315   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I1017 17:15:40.295386   28215 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I1017 17:15:45.300529   28215 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I1017 17:15:45.440362   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I1017 17:15:45.463178   28215 logs.go:279] 1 containers: [d8959036328f]
I1017 17:15:45.463266   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I1017 17:15:45.472036   28215 logs.go:279] 1 containers: [2730cc2aef95]
I1017 17:15:45.472127   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I1017 17:15:45.482037   28215 logs.go:279] 2 containers: [926759e7f212 ba6cf9e5453e]
I1017 17:15:45.482125   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I1017 17:15:45.490961   28215 logs.go:279] 1 containers: [31cc51d3bc7c]
I1017 17:15:45.491047   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I1017 17:15:45.501162   28215 logs.go:279] 1 containers: [468210b9872f]
I1017 17:15:45.501255   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I1017 17:15:45.519968   28215 logs.go:279] 0 containers: []
W1017 17:15:45.519977   28215 logs.go:281] No container was found matching "kubernetes-dashboard"
I1017 17:15:45.520058   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I1017 17:15:45.528400   28215 logs.go:279] 1 containers: [6106b035dda1]
I1017 17:15:45.528481   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I1017 17:15:45.536866   28215 logs.go:279] 1 containers: [001ef48cc07d]
I1017 17:15:45.536886   28215 logs.go:124] Gathering logs for container status ...
I1017 17:15:45.536892   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I1017 17:15:45.550663   28215 logs.go:124] Gathering logs for dmesg ...
I1017 17:15:45.550671   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I1017 17:15:45.555241   28215 logs.go:124] Gathering logs for coredns [ba6cf9e5453e] ...
I1017 17:15:45.555248   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 ba6cf9e5453e"
I1017 17:15:45.564117   28215 logs.go:124] Gathering logs for kube-controller-manager [001ef48cc07d] ...
I1017 17:15:45.564125   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 001ef48cc07d"
I1017 17:15:45.580367   28215 logs.go:124] Gathering logs for etcd [2730cc2aef95] ...
I1017 17:15:45.580376   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2730cc2aef95"
I1017 17:15:45.595176   28215 logs.go:124] Gathering logs for coredns [926759e7f212] ...
I1017 17:15:45.595186   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 926759e7f212"
I1017 17:15:45.604904   28215 logs.go:124] Gathering logs for kube-scheduler [31cc51d3bc7c] ...
I1017 17:15:45.604914   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 31cc51d3bc7c"
I1017 17:15:45.618834   28215 logs.go:124] Gathering logs for kube-proxy [468210b9872f] ...
I1017 17:15:45.618843   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 468210b9872f"
I1017 17:15:45.630118   28215 logs.go:124] Gathering logs for storage-provisioner [6106b035dda1] ...
I1017 17:15:45.630127   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 6106b035dda1"
I1017 17:15:45.640140   28215 logs.go:124] Gathering logs for kubelet ...
I1017 17:15:45.640149   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I1017 17:15:45.680472   28215 logs.go:124] Gathering logs for describe nodes ...
I1017 17:15:45.680482   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.26.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I1017 17:15:45.733003   28215 logs.go:124] Gathering logs for kube-apiserver [d8959036328f] ...
I1017 17:15:45.733012   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d8959036328f"
I1017 17:15:45.749312   28215 logs.go:124] Gathering logs for Docker ...
I1017 17:15:45.749321   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I1017 17:15:48.275392   28215 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I1017 17:15:53.280471   28215 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I1017 17:15:53.440266   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I1017 17:15:53.455443   28215 logs.go:279] 1 containers: [d8959036328f]
I1017 17:15:53.455536   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I1017 17:15:53.464362   28215 logs.go:279] 1 containers: [2730cc2aef95]
I1017 17:15:53.464453   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I1017 17:15:53.472969   28215 logs.go:279] 2 containers: [926759e7f212 ba6cf9e5453e]
I1017 17:15:53.473062   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I1017 17:15:53.485584   28215 logs.go:279] 1 containers: [31cc51d3bc7c]
I1017 17:15:53.485674   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I1017 17:15:53.494346   28215 logs.go:279] 1 containers: [468210b9872f]
I1017 17:15:53.494429   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I1017 17:15:53.503757   28215 logs.go:279] 0 containers: []
W1017 17:15:53.503765   28215 logs.go:281] No container was found matching "kubernetes-dashboard"
I1017 17:15:53.503849   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I1017 17:15:53.513629   28215 logs.go:279] 1 containers: [6106b035dda1]
I1017 17:15:53.513719   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I1017 17:15:53.523466   28215 logs.go:279] 1 containers: [001ef48cc07d]
I1017 17:15:53.523479   28215 logs.go:124] Gathering logs for dmesg ...
I1017 17:15:53.523484   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I1017 17:15:53.528415   28215 logs.go:124] Gathering logs for kube-apiserver [d8959036328f] ...
I1017 17:15:53.528423   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d8959036328f"
I1017 17:15:53.541651   28215 logs.go:124] Gathering logs for etcd [2730cc2aef95] ...
I1017 17:15:53.541661   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2730cc2aef95"
I1017 17:15:53.556491   28215 logs.go:124] Gathering logs for coredns [926759e7f212] ...
I1017 17:15:53.556499   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 926759e7f212"
I1017 17:15:53.566741   28215 logs.go:124] Gathering logs for coredns [ba6cf9e5453e] ...
I1017 17:15:53.566750   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 ba6cf9e5453e"
I1017 17:15:53.576399   28215 logs.go:124] Gathering logs for kube-scheduler [31cc51d3bc7c] ...
I1017 17:15:53.576407   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 31cc51d3bc7c"
I1017 17:15:53.589909   28215 logs.go:124] Gathering logs for storage-provisioner [6106b035dda1] ...
I1017 17:15:53.589918   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 6106b035dda1"
I1017 17:15:53.599864   28215 logs.go:124] Gathering logs for kubelet ...
I1017 17:15:53.599872   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I1017 17:15:53.641630   28215 logs.go:124] Gathering logs for kube-controller-manager [001ef48cc07d] ...
I1017 17:15:53.641640   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 001ef48cc07d"
I1017 17:15:53.658510   28215 logs.go:124] Gathering logs for kube-proxy [468210b9872f] ...
I1017 17:15:53.658519   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 468210b9872f"
I1017 17:15:53.668913   28215 logs.go:124] Gathering logs for Docker ...
I1017 17:15:53.668921   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I1017 17:15:53.696407   28215 logs.go:124] Gathering logs for container status ...
I1017 17:15:53.696418   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I1017 17:15:53.710168   28215 logs.go:124] Gathering logs for describe nodes ...
I1017 17:15:53.710178   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.26.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I1017 17:15:56.263383   28215 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I1017 17:16:01.268533   28215 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I1017 17:16:01.439530   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I1017 17:16:01.448775   28215 logs.go:279] 1 containers: [d8959036328f]
I1017 17:16:01.448888   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I1017 17:16:01.458274   28215 logs.go:279] 1 containers: [2730cc2aef95]
I1017 17:16:01.458358   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I1017 17:16:01.466991   28215 logs.go:279] 2 containers: [926759e7f212 ba6cf9e5453e]
I1017 17:16:01.467079   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I1017 17:16:01.476641   28215 logs.go:279] 1 containers: [31cc51d3bc7c]
I1017 17:16:01.476744   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I1017 17:16:01.485734   28215 logs.go:279] 1 containers: [468210b9872f]
I1017 17:16:01.485829   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I1017 17:16:01.495538   28215 logs.go:279] 0 containers: []
W1017 17:16:01.495545   28215 logs.go:281] No container was found matching "kubernetes-dashboard"
I1017 17:16:01.495627   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I1017 17:16:01.505086   28215 logs.go:279] 1 containers: [6106b035dda1]
I1017 17:16:01.505173   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I1017 17:16:01.513833   28215 logs.go:279] 1 containers: [001ef48cc07d]
I1017 17:16:01.513843   28215 logs.go:124] Gathering logs for kube-scheduler [31cc51d3bc7c] ...
I1017 17:16:01.513846   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 31cc51d3bc7c"
I1017 17:16:01.530627   28215 logs.go:124] Gathering logs for kube-proxy [468210b9872f] ...
I1017 17:16:01.530636   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 468210b9872f"
I1017 17:16:01.540991   28215 logs.go:124] Gathering logs for kube-controller-manager [001ef48cc07d] ...
I1017 17:16:01.541000   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 001ef48cc07d"
I1017 17:16:01.559060   28215 logs.go:124] Gathering logs for Docker ...
I1017 17:16:01.559069   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I1017 17:16:01.583891   28215 logs.go:124] Gathering logs for container status ...
I1017 17:16:01.583900   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I1017 17:16:01.597835   28215 logs.go:124] Gathering logs for kube-apiserver [d8959036328f] ...
I1017 17:16:01.597844   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d8959036328f"
I1017 17:16:01.610752   28215 logs.go:124] Gathering logs for coredns [926759e7f212] ...
I1017 17:16:01.610761   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 926759e7f212"
I1017 17:16:01.620281   28215 logs.go:124] Gathering logs for coredns [ba6cf9e5453e] ...
I1017 17:16:01.620290   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 ba6cf9e5453e"
I1017 17:16:01.631526   28215 logs.go:124] Gathering logs for etcd [2730cc2aef95] ...
I1017 17:16:01.631536   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2730cc2aef95"
I1017 17:16:01.644292   28215 logs.go:124] Gathering logs for storage-provisioner [6106b035dda1] ...
I1017 17:16:01.644301   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 6106b035dda1"
I1017 17:16:01.654198   28215 logs.go:124] Gathering logs for kubelet ...
I1017 17:16:01.654209   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I1017 17:16:01.694597   28215 logs.go:124] Gathering logs for dmesg ...
I1017 17:16:01.694607   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I1017 17:16:01.699900   28215 logs.go:124] Gathering logs for describe nodes ...
I1017 17:16:01.699910   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.26.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I1017 17:16:04.262277   28215 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I1017 17:16:09.267017   28215 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I1017 17:16:09.438556   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I1017 17:16:09.454297   28215 logs.go:279] 1 containers: [d8959036328f]
I1017 17:16:09.454399   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I1017 17:16:09.463039   28215 logs.go:279] 1 containers: [2730cc2aef95]
I1017 17:16:09.463132   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I1017 17:16:09.472181   28215 logs.go:279] 2 containers: [926759e7f212 ba6cf9e5453e]
I1017 17:16:09.472261   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I1017 17:16:09.480403   28215 logs.go:279] 1 containers: [31cc51d3bc7c]
I1017 17:16:09.480501   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I1017 17:16:09.489272   28215 logs.go:279] 1 containers: [468210b9872f]
I1017 17:16:09.489368   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I1017 17:16:09.497698   28215 logs.go:279] 0 containers: []
W1017 17:16:09.497707   28215 logs.go:281] No container was found matching "kubernetes-dashboard"
I1017 17:16:09.497789   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I1017 17:16:09.506505   28215 logs.go:279] 1 containers: [6106b035dda1]
I1017 17:16:09.506593   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I1017 17:16:09.515084   28215 logs.go:279] 1 containers: [001ef48cc07d]
I1017 17:16:09.515096   28215 logs.go:124] Gathering logs for kube-controller-manager [001ef48cc07d] ...
I1017 17:16:09.515101   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 001ef48cc07d"
I1017 17:16:09.531289   28215 logs.go:124] Gathering logs for Docker ...
I1017 17:16:09.531298   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I1017 17:16:09.556711   28215 logs.go:124] Gathering logs for kubelet ...
I1017 17:16:09.556721   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I1017 17:16:09.599979   28215 logs.go:124] Gathering logs for describe nodes ...
I1017 17:16:09.599990   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.26.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I1017 17:16:09.645177   28215 logs.go:124] Gathering logs for coredns [ba6cf9e5453e] ...
I1017 17:16:09.645186   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 ba6cf9e5453e"
I1017 17:16:09.659262   28215 logs.go:124] Gathering logs for kube-proxy [468210b9872f] ...
I1017 17:16:09.659271   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 468210b9872f"
I1017 17:16:09.670426   28215 logs.go:124] Gathering logs for storage-provisioner [6106b035dda1] ...
I1017 17:16:09.670434   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 6106b035dda1"
I1017 17:16:09.679863   28215 logs.go:124] Gathering logs for container status ...
I1017 17:16:09.679872   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I1017 17:16:09.692767   28215 logs.go:124] Gathering logs for dmesg ...
I1017 17:16:09.692777   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I1017 17:16:09.697873   28215 logs.go:124] Gathering logs for kube-apiserver [d8959036328f] ...
I1017 17:16:09.697881   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d8959036328f"
I1017 17:16:09.711232   28215 logs.go:124] Gathering logs for etcd [2730cc2aef95] ...
I1017 17:16:09.711242   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2730cc2aef95"
I1017 17:16:09.723646   28215 logs.go:124] Gathering logs for coredns [926759e7f212] ...
I1017 17:16:09.723655   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 926759e7f212"
I1017 17:16:09.733610   28215 logs.go:124] Gathering logs for kube-scheduler [31cc51d3bc7c] ...
I1017 17:16:09.733618   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 31cc51d3bc7c"
I1017 17:16:12.254187   28215 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I1017 17:16:17.254937   28215 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I1017 17:16:17.435732   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I1017 17:16:17.447113   28215 logs.go:279] 1 containers: [d8959036328f]
I1017 17:16:17.447196   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I1017 17:16:17.460420   28215 logs.go:279] 1 containers: [2730cc2aef95]
I1017 17:16:17.460511   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I1017 17:16:17.469954   28215 logs.go:279] 2 containers: [926759e7f212 ba6cf9e5453e]
I1017 17:16:17.470043   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I1017 17:16:17.478576   28215 logs.go:279] 1 containers: [31cc51d3bc7c]
I1017 17:16:17.493048   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I1017 17:16:17.502356   28215 logs.go:279] 1 containers: [468210b9872f]
I1017 17:16:17.502444   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I1017 17:16:17.511001   28215 logs.go:279] 0 containers: []
W1017 17:16:17.511010   28215 logs.go:281] No container was found matching "kubernetes-dashboard"
I1017 17:16:17.511100   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I1017 17:16:17.519703   28215 logs.go:279] 1 containers: [6106b035dda1]
I1017 17:16:17.519791   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I1017 17:16:17.528218   28215 logs.go:279] 1 containers: [001ef48cc07d]
I1017 17:16:17.528231   28215 logs.go:124] Gathering logs for coredns [926759e7f212] ...
I1017 17:16:17.528235   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 926759e7f212"
I1017 17:16:17.538400   28215 logs.go:124] Gathering logs for kube-scheduler [31cc51d3bc7c] ...
I1017 17:16:17.538433   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 31cc51d3bc7c"
I1017 17:16:17.553849   28215 logs.go:124] Gathering logs for kube-proxy [468210b9872f] ...
I1017 17:16:17.553857   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 468210b9872f"
I1017 17:16:17.563716   28215 logs.go:124] Gathering logs for storage-provisioner [6106b035dda1] ...
I1017 17:16:17.563724   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 6106b035dda1"
I1017 17:16:17.573105   28215 logs.go:124] Gathering logs for kube-controller-manager [001ef48cc07d] ...
I1017 17:16:17.573114   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 001ef48cc07d"
I1017 17:16:17.588255   28215 logs.go:124] Gathering logs for container status ...
I1017 17:16:17.588263   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I1017 17:16:17.609162   28215 logs.go:124] Gathering logs for kubelet ...
I1017 17:16:17.609172   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I1017 17:16:17.651589   28215 logs.go:124] Gathering logs for dmesg ...
I1017 17:16:17.651599   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I1017 17:16:17.657295   28215 logs.go:124] Gathering logs for describe nodes ...
I1017 17:16:17.657304   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.26.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I1017 17:16:17.702935   28215 logs.go:124] Gathering logs for kube-apiserver [d8959036328f] ...
I1017 17:16:17.702944   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d8959036328f"
I1017 17:16:17.715551   28215 logs.go:124] Gathering logs for etcd [2730cc2aef95] ...
I1017 17:16:17.715560   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2730cc2aef95"
I1017 17:16:17.730950   28215 logs.go:124] Gathering logs for coredns [ba6cf9e5453e] ...
I1017 17:16:17.730959   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 ba6cf9e5453e"
I1017 17:16:17.742136   28215 logs.go:124] Gathering logs for Docker ...
I1017 17:16:17.742144   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I1017 17:16:20.270928   28215 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I1017 17:16:25.274844   28215 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I1017 17:16:25.438500   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I1017 17:16:25.454608   28215 logs.go:279] 1 containers: [d8959036328f]
I1017 17:16:25.454704   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I1017 17:16:25.462682   28215 logs.go:279] 1 containers: [2730cc2aef95]
I1017 17:16:25.462763   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I1017 17:16:25.471380   28215 logs.go:279] 2 containers: [926759e7f212 ba6cf9e5453e]
I1017 17:16:25.471468   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I1017 17:16:25.479800   28215 logs.go:279] 1 containers: [31cc51d3bc7c]
I1017 17:16:25.479882   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I1017 17:16:25.488192   28215 logs.go:279] 1 containers: [468210b9872f]
I1017 17:16:25.488305   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I1017 17:16:25.496895   28215 logs.go:279] 0 containers: []
W1017 17:16:25.496902   28215 logs.go:281] No container was found matching "kubernetes-dashboard"
I1017 17:16:25.496979   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I1017 17:16:25.506309   28215 logs.go:279] 1 containers: [6106b035dda1]
I1017 17:16:25.506396   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I1017 17:16:25.515700   28215 logs.go:279] 1 containers: [001ef48cc07d]
I1017 17:16:25.515712   28215 logs.go:124] Gathering logs for kube-proxy [468210b9872f] ...
I1017 17:16:25.515717   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 468210b9872f"
I1017 17:16:25.526976   28215 logs.go:124] Gathering logs for storage-provisioner [6106b035dda1] ...
I1017 17:16:25.526987   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 6106b035dda1"
I1017 17:16:25.536433   28215 logs.go:124] Gathering logs for kube-controller-manager [001ef48cc07d] ...
I1017 17:16:25.536442   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 001ef48cc07d"
I1017 17:16:25.552415   28215 logs.go:124] Gathering logs for describe nodes ...
I1017 17:16:25.552424   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.26.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I1017 17:16:25.602863   28215 logs.go:124] Gathering logs for coredns [926759e7f212] ...
I1017 17:16:25.602871   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 926759e7f212"
I1017 17:16:25.612360   28215 logs.go:124] Gathering logs for coredns [ba6cf9e5453e] ...
I1017 17:16:25.612368   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 ba6cf9e5453e"
I1017 17:16:25.622579   28215 logs.go:124] Gathering logs for etcd [2730cc2aef95] ...
I1017 17:16:25.622589   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2730cc2aef95"
I1017 17:16:25.634980   28215 logs.go:124] Gathering logs for kube-scheduler [31cc51d3bc7c] ...
I1017 17:16:25.634989   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 31cc51d3bc7c"
I1017 17:16:25.649608   28215 logs.go:124] Gathering logs for Docker ...
I1017 17:16:25.649618   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I1017 17:16:25.674797   28215 logs.go:124] Gathering logs for container status ...
I1017 17:16:25.674807   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I1017 17:16:25.689045   28215 logs.go:124] Gathering logs for kubelet ...
I1017 17:16:25.689053   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I1017 17:16:25.731495   28215 logs.go:124] Gathering logs for dmesg ...
I1017 17:16:25.731505   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I1017 17:16:25.737777   28215 logs.go:124] Gathering logs for kube-apiserver [d8959036328f] ...
I1017 17:16:25.737785   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d8959036328f"
I1017 17:16:28.256940   28215 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I1017 17:16:33.259847   28215 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I1017 17:16:33.439596   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I1017 17:16:33.454173   28215 logs.go:279] 1 containers: [d8959036328f]
I1017 17:16:33.454261   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I1017 17:16:33.463119   28215 logs.go:279] 1 containers: [2730cc2aef95]
I1017 17:16:33.463201   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I1017 17:16:33.472362   28215 logs.go:279] 2 containers: [926759e7f212 ba6cf9e5453e]
I1017 17:16:33.472443   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I1017 17:16:33.481340   28215 logs.go:279] 1 containers: [31cc51d3bc7c]
I1017 17:16:33.481426   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I1017 17:16:33.489910   28215 logs.go:279] 1 containers: [468210b9872f]
I1017 17:16:33.490046   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I1017 17:16:33.498436   28215 logs.go:279] 0 containers: []
W1017 17:16:33.498443   28215 logs.go:281] No container was found matching "kubernetes-dashboard"
I1017 17:16:33.498519   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I1017 17:16:33.506948   28215 logs.go:279] 1 containers: [6106b035dda1]
I1017 17:16:33.507032   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I1017 17:16:33.516650   28215 logs.go:279] 1 containers: [001ef48cc07d]
I1017 17:16:33.516662   28215 logs.go:124] Gathering logs for coredns [926759e7f212] ...
I1017 17:16:33.516667   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 926759e7f212"
I1017 17:16:33.526165   28215 logs.go:124] Gathering logs for coredns [ba6cf9e5453e] ...
I1017 17:16:33.526174   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 ba6cf9e5453e"
I1017 17:16:33.535904   28215 logs.go:124] Gathering logs for kube-scheduler [31cc51d3bc7c] ...
I1017 17:16:33.535912   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 31cc51d3bc7c"
I1017 17:16:33.550518   28215 logs.go:124] Gathering logs for storage-provisioner [6106b035dda1] ...
I1017 17:16:33.550528   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 6106b035dda1"
I1017 17:16:33.559913   28215 logs.go:124] Gathering logs for kube-controller-manager [001ef48cc07d] ...
I1017 17:16:33.559920   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 001ef48cc07d"
I1017 17:16:33.577117   28215 logs.go:124] Gathering logs for container status ...
I1017 17:16:33.577126   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I1017 17:16:33.589540   28215 logs.go:124] Gathering logs for kubelet ...
I1017 17:16:33.589576   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I1017 17:16:33.629952   28215 logs.go:124] Gathering logs for dmesg ...
I1017 17:16:33.629961   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I1017 17:16:33.635368   28215 logs.go:124] Gathering logs for etcd [2730cc2aef95] ...
I1017 17:16:33.635376   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2730cc2aef95"
I1017 17:16:33.647724   28215 logs.go:124] Gathering logs for kube-proxy [468210b9872f] ...
I1017 17:16:33.647733   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 468210b9872f"
I1017 17:16:33.659403   28215 logs.go:124] Gathering logs for Docker ...
I1017 17:16:33.659413   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I1017 17:16:33.683871   28215 logs.go:124] Gathering logs for describe nodes ...
I1017 17:16:33.683880   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.26.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I1017 17:16:33.729735   28215 logs.go:124] Gathering logs for kube-apiserver [d8959036328f] ...
I1017 17:16:33.729744   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d8959036328f"
I1017 17:16:36.251268   28215 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I1017 17:16:41.256372   28215 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I1017 17:16:41.435876   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I1017 17:16:41.444621   28215 logs.go:279] 1 containers: [d8959036328f]
I1017 17:16:41.444708   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I1017 17:16:41.454284   28215 logs.go:279] 1 containers: [2730cc2aef95]
I1017 17:16:41.454374   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I1017 17:16:41.463078   28215 logs.go:279] 2 containers: [926759e7f212 ba6cf9e5453e]
I1017 17:16:41.463164   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I1017 17:16:41.478532   28215 logs.go:279] 1 containers: [31cc51d3bc7c]
I1017 17:16:41.478620   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I1017 17:16:41.487528   28215 logs.go:279] 1 containers: [468210b9872f]
I1017 17:16:41.487629   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I1017 17:16:41.498019   28215 logs.go:279] 0 containers: []
W1017 17:16:41.498028   28215 logs.go:281] No container was found matching "kubernetes-dashboard"
I1017 17:16:41.498118   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I1017 17:16:41.507359   28215 logs.go:279] 1 containers: [6106b035dda1]
I1017 17:16:41.507442   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I1017 17:16:41.516479   28215 logs.go:279] 1 containers: [001ef48cc07d]
I1017 17:16:41.516491   28215 logs.go:124] Gathering logs for dmesg ...
I1017 17:16:41.516497   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I1017 17:16:41.521591   28215 logs.go:124] Gathering logs for describe nodes ...
I1017 17:16:41.521600   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.26.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I1017 17:16:41.570245   28215 logs.go:124] Gathering logs for kube-apiserver [d8959036328f] ...
I1017 17:16:41.570253   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d8959036328f"
I1017 17:16:41.583715   28215 logs.go:124] Gathering logs for coredns [926759e7f212] ...
I1017 17:16:41.583724   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 926759e7f212"
I1017 17:16:41.593602   28215 logs.go:124] Gathering logs for coredns [ba6cf9e5453e] ...
I1017 17:16:41.593611   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 ba6cf9e5453e"
I1017 17:16:41.603122   28215 logs.go:124] Gathering logs for kube-scheduler [31cc51d3bc7c] ...
I1017 17:16:41.603130   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 31cc51d3bc7c"
I1017 17:16:41.616346   28215 logs.go:124] Gathering logs for kube-proxy [468210b9872f] ...
I1017 17:16:41.616354   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 468210b9872f"
I1017 17:16:41.631922   28215 logs.go:124] Gathering logs for kubelet ...
I1017 17:16:41.631931   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I1017 17:16:41.673090   28215 logs.go:124] Gathering logs for Docker ...
I1017 17:16:41.673099   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I1017 17:16:41.697237   28215 logs.go:124] Gathering logs for storage-provisioner [6106b035dda1] ...
I1017 17:16:41.697250   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 6106b035dda1"
I1017 17:16:41.707880   28215 logs.go:124] Gathering logs for kube-controller-manager [001ef48cc07d] ...
I1017 17:16:41.707889   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 001ef48cc07d"
I1017 17:16:41.725417   28215 logs.go:124] Gathering logs for container status ...
I1017 17:16:41.725426   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I1017 17:16:41.739899   28215 logs.go:124] Gathering logs for etcd [2730cc2aef95] ...
I1017 17:16:41.739907   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2730cc2aef95"
I1017 17:16:44.259609   28215 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I1017 17:16:49.264750   28215 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": dial tcp 10.0.2.15:8443: i/o timeout (Client.Timeout exceeded while awaiting headers)
I1017 17:16:49.433765   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I1017 17:16:49.447305   28215 logs.go:279] 1 containers: [d8959036328f]
I1017 17:16:49.447387   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I1017 17:16:49.456500   28215 logs.go:279] 1 containers: [2730cc2aef95]
I1017 17:16:49.456588   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I1017 17:16:49.464987   28215 logs.go:279] 2 containers: [926759e7f212 ba6cf9e5453e]
I1017 17:16:49.465083   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I1017 17:16:49.475394   28215 logs.go:279] 1 containers: [31cc51d3bc7c]
I1017 17:16:49.475486   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I1017 17:16:49.485370   28215 logs.go:279] 1 containers: [468210b9872f]
I1017 17:16:49.485458   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I1017 17:16:49.493844   28215 logs.go:279] 0 containers: []
W1017 17:16:49.493852   28215 logs.go:281] No container was found matching "kubernetes-dashboard"
I1017 17:16:49.493952   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I1017 17:16:49.502376   28215 logs.go:279] 1 containers: [6106b035dda1]
I1017 17:16:49.502464   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I1017 17:16:49.511418   28215 logs.go:279] 1 containers: [001ef48cc07d]
I1017 17:16:49.511430   28215 logs.go:124] Gathering logs for etcd [2730cc2aef95] ...
I1017 17:16:49.511435   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2730cc2aef95"
I1017 17:16:49.524534   28215 logs.go:124] Gathering logs for kube-proxy [468210b9872f] ...
I1017 17:16:49.524542   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 468210b9872f"
I1017 17:16:49.534951   28215 logs.go:124] Gathering logs for kube-controller-manager [001ef48cc07d] ...
I1017 17:16:49.534959   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 001ef48cc07d"
I1017 17:16:49.559112   28215 logs.go:124] Gathering logs for kube-apiserver [d8959036328f] ...
I1017 17:16:49.559121   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d8959036328f"
I1017 17:16:49.571774   28215 logs.go:124] Gathering logs for coredns [926759e7f212] ...
I1017 17:16:49.571783   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 926759e7f212"
I1017 17:16:49.581044   28215 logs.go:124] Gathering logs for coredns [ba6cf9e5453e] ...
I1017 17:16:49.581052   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 ba6cf9e5453e"
I1017 17:16:49.591009   28215 logs.go:124] Gathering logs for kube-scheduler [31cc51d3bc7c] ...
I1017 17:16:49.591019   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 31cc51d3bc7c"
I1017 17:16:49.604821   28215 logs.go:124] Gathering logs for storage-provisioner [6106b035dda1] ...
I1017 17:16:49.604829   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 6106b035dda1"
I1017 17:16:49.614736   28215 logs.go:124] Gathering logs for kubelet ...
I1017 17:16:49.614745   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I1017 17:16:49.658420   28215 logs.go:124] Gathering logs for dmesg ...
I1017 17:16:49.658432   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I1017 17:16:49.663608   28215 logs.go:124] Gathering logs for describe nodes ...
I1017 17:16:49.663616   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.26.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I1017 17:16:49.710635   28215 logs.go:124] Gathering logs for Docker ...
I1017 17:16:49.710645   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I1017 17:16:49.734649   28215 logs.go:124] Gathering logs for container status ...
I1017 17:16:49.734679   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I1017 17:16:52.253012   28215 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I1017 17:16:57.255593   28215 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I1017 17:16:57.436142   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I1017 17:16:57.445515   28215 logs.go:279] 1 containers: [d8959036328f]
I1017 17:16:57.445598   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I1017 17:16:57.454086   28215 logs.go:279] 1 containers: [2730cc2aef95]
I1017 17:16:57.454175   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I1017 17:16:57.462600   28215 logs.go:279] 2 containers: [926759e7f212 ba6cf9e5453e]
I1017 17:16:57.462686   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I1017 17:16:57.471263   28215 logs.go:279] 1 containers: [31cc51d3bc7c]
I1017 17:16:57.471355   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I1017 17:16:57.480933   28215 logs.go:279] 1 containers: [468210b9872f]
I1017 17:16:57.507458   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I1017 17:16:57.517611   28215 logs.go:279] 0 containers: []
W1017 17:16:57.517620   28215 logs.go:281] No container was found matching "kubernetes-dashboard"
I1017 17:16:57.517703   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I1017 17:16:57.525892   28215 logs.go:279] 1 containers: [6106b035dda1]
I1017 17:16:57.525984   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I1017 17:16:57.534572   28215 logs.go:279] 1 containers: [001ef48cc07d]
I1017 17:16:57.534584   28215 logs.go:124] Gathering logs for kube-controller-manager [001ef48cc07d] ...
I1017 17:16:57.534589   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 001ef48cc07d"
I1017 17:16:57.550448   28215 logs.go:124] Gathering logs for kubelet ...
I1017 17:16:57.550458   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I1017 17:16:57.592270   28215 logs.go:124] Gathering logs for dmesg ...
I1017 17:16:57.592281   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I1017 17:16:57.597368   28215 logs.go:124] Gathering logs for describe nodes ...
I1017 17:16:57.597377   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.26.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I1017 17:16:57.649837   28215 logs.go:124] Gathering logs for etcd [2730cc2aef95] ...
I1017 17:16:57.649845   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2730cc2aef95"
I1017 17:16:57.662785   28215 logs.go:124] Gathering logs for kube-scheduler [31cc51d3bc7c] ...
I1017 17:16:57.662794   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 31cc51d3bc7c"
I1017 17:16:57.676782   28215 logs.go:124] Gathering logs for storage-provisioner [6106b035dda1] ...
I1017 17:16:57.676791   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 6106b035dda1"
I1017 17:16:57.687056   28215 logs.go:124] Gathering logs for kube-apiserver [d8959036328f] ...
I1017 17:16:57.687064   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d8959036328f"
I1017 17:16:57.700187   28215 logs.go:124] Gathering logs for coredns [926759e7f212] ...
I1017 17:16:57.700195   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 926759e7f212"
I1017 17:16:57.710312   28215 logs.go:124] Gathering logs for coredns [ba6cf9e5453e] ...
I1017 17:16:57.710321   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 ba6cf9e5453e"
I1017 17:16:57.719777   28215 logs.go:124] Gathering logs for kube-proxy [468210b9872f] ...
I1017 17:16:57.719785   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 468210b9872f"
I1017 17:16:57.729653   28215 logs.go:124] Gathering logs for Docker ...
I1017 17:16:57.729662   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I1017 17:16:57.754831   28215 logs.go:124] Gathering logs for container status ...
I1017 17:16:57.754842   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I1017 17:17:00.273540   28215 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I1017 17:17:05.278680   28215 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I1017 17:17:05.438390   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I1017 17:17:05.451592   28215 logs.go:279] 1 containers: [d8959036328f]
I1017 17:17:05.451682   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I1017 17:17:05.461444   28215 logs.go:279] 1 containers: [2730cc2aef95]
I1017 17:17:05.461533   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I1017 17:17:05.472182   28215 logs.go:279] 2 containers: [926759e7f212 ba6cf9e5453e]
I1017 17:17:05.472288   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I1017 17:17:05.480426   28215 logs.go:279] 1 containers: [31cc51d3bc7c]
I1017 17:17:05.480514   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I1017 17:17:05.489741   28215 logs.go:279] 1 containers: [468210b9872f]
I1017 17:17:05.489831   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I1017 17:17:05.499089   28215 logs.go:279] 0 containers: []
W1017 17:17:05.499097   28215 logs.go:281] No container was found matching "kubernetes-dashboard"
I1017 17:17:05.499172   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I1017 17:17:05.507959   28215 logs.go:279] 1 containers: [6106b035dda1]
I1017 17:17:05.508051   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I1017 17:17:05.517111   28215 logs.go:279] 1 containers: [001ef48cc07d]
I1017 17:17:05.517124   28215 logs.go:124] Gathering logs for kube-apiserver [d8959036328f] ...
I1017 17:17:05.517130   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d8959036328f"
I1017 17:17:05.529301   28215 logs.go:124] Gathering logs for coredns [ba6cf9e5453e] ...
I1017 17:17:05.529308   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 ba6cf9e5453e"
I1017 17:17:05.538874   28215 logs.go:124] Gathering logs for kube-proxy [468210b9872f] ...
I1017 17:17:05.538883   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 468210b9872f"
I1017 17:17:05.549120   28215 logs.go:124] Gathering logs for kube-controller-manager [001ef48cc07d] ...
I1017 17:17:05.549129   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 001ef48cc07d"
I1017 17:17:05.565374   28215 logs.go:124] Gathering logs for container status ...
I1017 17:17:05.565383   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I1017 17:17:05.580124   28215 logs.go:124] Gathering logs for dmesg ...
I1017 17:17:05.580132   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I1017 17:17:05.586068   28215 logs.go:124] Gathering logs for describe nodes ...
I1017 17:17:05.586077   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.26.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I1017 17:17:05.633895   28215 logs.go:124] Gathering logs for coredns [926759e7f212] ...
I1017 17:17:05.633905   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 926759e7f212"
I1017 17:17:05.643221   28215 logs.go:124] Gathering logs for kube-scheduler [31cc51d3bc7c] ...
I1017 17:17:05.643230   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 31cc51d3bc7c"
I1017 17:17:05.656687   28215 logs.go:124] Gathering logs for storage-provisioner [6106b035dda1] ...
I1017 17:17:05.656696   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 6106b035dda1"
I1017 17:17:05.666318   28215 logs.go:124] Gathering logs for Docker ...
I1017 17:17:05.666328   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I1017 17:17:05.691111   28215 logs.go:124] Gathering logs for kubelet ...
I1017 17:17:05.691122   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I1017 17:17:05.731258   28215 logs.go:124] Gathering logs for etcd [2730cc2aef95] ...
I1017 17:17:05.731267   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2730cc2aef95"
I1017 17:17:08.250380   28215 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I1017 17:17:13.255684   28215 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I1017 17:17:13.436894   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I1017 17:17:13.447908   28215 logs.go:279] 1 containers: [d8959036328f]
I1017 17:17:13.447995   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I1017 17:17:13.458125   28215 logs.go:279] 1 containers: [2730cc2aef95]
I1017 17:17:13.458207   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I1017 17:17:13.470230   28215 logs.go:279] 2 containers: [926759e7f212 ba6cf9e5453e]
I1017 17:17:13.470315   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I1017 17:17:13.480733   28215 logs.go:279] 1 containers: [31cc51d3bc7c]
I1017 17:17:13.480821   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I1017 17:17:13.491626   28215 logs.go:279] 1 containers: [468210b9872f]
I1017 17:17:13.491714   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I1017 17:17:13.502868   28215 logs.go:279] 0 containers: []
W1017 17:17:13.502876   28215 logs.go:281] No container was found matching "kubernetes-dashboard"
I1017 17:17:13.502957   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I1017 17:17:13.513143   28215 logs.go:279] 1 containers: [6106b035dda1]
I1017 17:17:13.513231   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I1017 17:17:13.525350   28215 logs.go:279] 1 containers: [001ef48cc07d]
I1017 17:17:13.525362   28215 logs.go:124] Gathering logs for kubelet ...
I1017 17:17:13.525366   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I1017 17:17:13.570365   28215 logs.go:124] Gathering logs for describe nodes ...
I1017 17:17:13.570375   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.26.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I1017 17:17:13.631750   28215 logs.go:124] Gathering logs for coredns [926759e7f212] ...
I1017 17:17:13.631760   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 926759e7f212"
I1017 17:17:13.643683   28215 logs.go:124] Gathering logs for storage-provisioner [6106b035dda1] ...
I1017 17:17:13.643691   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 6106b035dda1"
I1017 17:17:13.655731   28215 logs.go:124] Gathering logs for kube-controller-manager [001ef48cc07d] ...
I1017 17:17:13.655739   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 001ef48cc07d"
I1017 17:17:13.673119   28215 logs.go:124] Gathering logs for container status ...
I1017 17:17:13.673127   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I1017 17:17:13.692124   28215 logs.go:124] Gathering logs for dmesg ...
I1017 17:17:13.692133   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I1017 17:17:13.697904   28215 logs.go:124] Gathering logs for kube-apiserver [d8959036328f] ...
I1017 17:17:13.697913   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d8959036328f"
I1017 17:17:13.715474   28215 logs.go:124] Gathering logs for etcd [2730cc2aef95] ...
I1017 17:17:13.715484   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2730cc2aef95"
I1017 17:17:13.733713   28215 logs.go:124] Gathering logs for coredns [ba6cf9e5453e] ...
I1017 17:17:13.733724   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 ba6cf9e5453e"
I1017 17:17:13.748662   28215 logs.go:124] Gathering logs for kube-scheduler [31cc51d3bc7c] ...
I1017 17:17:13.748671   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 31cc51d3bc7c"
I1017 17:17:13.765226   28215 logs.go:124] Gathering logs for kube-proxy [468210b9872f] ...
I1017 17:17:13.765235   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 468210b9872f"
I1017 17:17:13.776800   28215 logs.go:124] Gathering logs for Docker ...
I1017 17:17:13.776809   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I1017 17:17:16.308366   28215 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I1017 17:17:21.315036   28215 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I1017 17:17:21.437453   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I1017 17:17:21.448139   28215 logs.go:279] 1 containers: [d8959036328f]
I1017 17:17:21.448324   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I1017 17:17:21.459024   28215 logs.go:279] 1 containers: [2730cc2aef95]
I1017 17:17:21.459113   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I1017 17:17:21.468221   28215 logs.go:279] 2 containers: [926759e7f212 ba6cf9e5453e]
I1017 17:17:21.468316   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I1017 17:17:21.480301   28215 logs.go:279] 1 containers: [31cc51d3bc7c]
I1017 17:17:21.480456   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I1017 17:17:21.491093   28215 logs.go:279] 1 containers: [468210b9872f]
I1017 17:17:21.491185   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I1017 17:17:21.501732   28215 logs.go:279] 0 containers: []
W1017 17:17:21.501740   28215 logs.go:281] No container was found matching "kubernetes-dashboard"
I1017 17:17:21.501827   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I1017 17:17:21.512714   28215 logs.go:279] 1 containers: [6106b035dda1]
I1017 17:17:21.512793   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I1017 17:17:21.524370   28215 logs.go:279] 1 containers: [001ef48cc07d]
I1017 17:17:21.524382   28215 logs.go:124] Gathering logs for kube-controller-manager [001ef48cc07d] ...
I1017 17:17:21.524386   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 001ef48cc07d"
I1017 17:17:21.542412   28215 logs.go:124] Gathering logs for Docker ...
I1017 17:17:21.542421   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I1017 17:17:21.571672   28215 logs.go:124] Gathering logs for container status ...
I1017 17:17:21.571682   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I1017 17:17:21.587843   28215 logs.go:124] Gathering logs for dmesg ...
I1017 17:17:21.587853   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I1017 17:17:21.593141   28215 logs.go:124] Gathering logs for describe nodes ...
I1017 17:17:21.593150   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.26.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I1017 17:17:21.647808   28215 logs.go:124] Gathering logs for kube-apiserver [d8959036328f] ...
I1017 17:17:21.647816   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d8959036328f"
I1017 17:17:21.662939   28215 logs.go:124] Gathering logs for coredns [926759e7f212] ...
I1017 17:17:21.662948   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 926759e7f212"
I1017 17:17:21.674548   28215 logs.go:124] Gathering logs for kube-proxy [468210b9872f] ...
I1017 17:17:21.674557   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 468210b9872f"
I1017 17:17:21.688391   28215 logs.go:124] Gathering logs for storage-provisioner [6106b035dda1] ...
I1017 17:17:21.688399   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 6106b035dda1"
I1017 17:17:21.700024   28215 logs.go:124] Gathering logs for kubelet ...
I1017 17:17:21.700033   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I1017 17:17:21.751522   28215 logs.go:124] Gathering logs for etcd [2730cc2aef95] ...
I1017 17:17:21.751550   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2730cc2aef95"
I1017 17:17:21.767689   28215 logs.go:124] Gathering logs for coredns [ba6cf9e5453e] ...
I1017 17:17:21.767698   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 ba6cf9e5453e"
I1017 17:17:21.781459   28215 logs.go:124] Gathering logs for kube-scheduler [31cc51d3bc7c] ...
I1017 17:17:21.781469   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 31cc51d3bc7c"
I1017 17:17:24.307132   28215 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I1017 17:17:29.316807   28215 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I1017 17:17:29.446265   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I1017 17:17:29.455455   28215 logs.go:279] 1 containers: [d8959036328f]
I1017 17:17:29.455545   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I1017 17:17:29.464624   28215 logs.go:279] 1 containers: [2730cc2aef95]
I1017 17:17:29.464706   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I1017 17:17:29.473480   28215 logs.go:279] 2 containers: [926759e7f212 ba6cf9e5453e]
I1017 17:17:29.473572   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I1017 17:17:29.482265   28215 logs.go:279] 1 containers: [31cc51d3bc7c]
I1017 17:17:29.482364   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I1017 17:17:29.491731   28215 logs.go:279] 1 containers: [468210b9872f]
I1017 17:17:29.491825   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I1017 17:17:29.500350   28215 logs.go:279] 0 containers: []
W1017 17:17:29.500356   28215 logs.go:281] No container was found matching "kubernetes-dashboard"
I1017 17:17:29.500442   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I1017 17:17:29.509229   28215 logs.go:279] 1 containers: [6106b035dda1]
I1017 17:17:29.509328   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I1017 17:17:29.518040   28215 logs.go:279] 1 containers: [001ef48cc07d]
I1017 17:17:29.518053   28215 logs.go:124] Gathering logs for coredns [ba6cf9e5453e] ...
I1017 17:17:29.518057   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 ba6cf9e5453e"
I1017 17:17:29.527874   28215 logs.go:124] Gathering logs for kube-scheduler [31cc51d3bc7c] ...
I1017 17:17:29.527883   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 31cc51d3bc7c"
I1017 17:17:29.542648   28215 logs.go:124] Gathering logs for container status ...
I1017 17:17:29.542657   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I1017 17:17:29.556695   28215 logs.go:124] Gathering logs for kubelet ...
I1017 17:17:29.556704   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I1017 17:17:29.597307   28215 logs.go:124] Gathering logs for describe nodes ...
I1017 17:17:29.597317   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.26.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I1017 17:17:29.648085   28215 logs.go:124] Gathering logs for kube-apiserver [d8959036328f] ...
I1017 17:17:29.648095   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d8959036328f"
I1017 17:17:29.660644   28215 logs.go:124] Gathering logs for etcd [2730cc2aef95] ...
I1017 17:17:29.660653   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2730cc2aef95"
I1017 17:17:29.673860   28215 logs.go:124] Gathering logs for coredns [926759e7f212] ...
I1017 17:17:29.673869   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 926759e7f212"
I1017 17:17:29.683154   28215 logs.go:124] Gathering logs for dmesg ...
I1017 17:17:29.683162   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I1017 17:17:29.688750   28215 logs.go:124] Gathering logs for kube-proxy [468210b9872f] ...
I1017 17:17:29.688760   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 468210b9872f"
I1017 17:17:29.699288   28215 logs.go:124] Gathering logs for storage-provisioner [6106b035dda1] ...
I1017 17:17:29.699296   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 6106b035dda1"
I1017 17:17:29.710630   28215 logs.go:124] Gathering logs for kube-controller-manager [001ef48cc07d] ...
I1017 17:17:29.710639   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 001ef48cc07d"
I1017 17:17:29.727409   28215 logs.go:124] Gathering logs for Docker ...
I1017 17:17:29.727418   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I1017 17:17:32.263310   28215 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I1017 17:17:37.267901   28215 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I1017 17:17:37.454429   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I1017 17:17:37.466199   28215 logs.go:279] 1 containers: [d8959036328f]
I1017 17:17:37.466300   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I1017 17:17:37.474644   28215 logs.go:279] 1 containers: [2730cc2aef95]
I1017 17:17:37.474751   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I1017 17:17:37.483727   28215 logs.go:279] 2 containers: [926759e7f212 ba6cf9e5453e]
I1017 17:17:37.483827   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I1017 17:17:37.492088   28215 logs.go:279] 1 containers: [31cc51d3bc7c]
I1017 17:17:37.508273   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I1017 17:17:37.516803   28215 logs.go:279] 1 containers: [468210b9872f]
I1017 17:17:37.516912   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I1017 17:17:37.525641   28215 logs.go:279] 0 containers: []
W1017 17:17:37.525649   28215 logs.go:281] No container was found matching "kubernetes-dashboard"
I1017 17:17:37.525729   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I1017 17:17:37.535543   28215 logs.go:279] 1 containers: [6106b035dda1]
I1017 17:17:37.535630   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I1017 17:17:37.544630   28215 logs.go:279] 1 containers: [001ef48cc07d]
I1017 17:17:37.544641   28215 logs.go:124] Gathering logs for kube-controller-manager [001ef48cc07d] ...
I1017 17:17:37.544646   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 001ef48cc07d"
I1017 17:17:37.560650   28215 logs.go:124] Gathering logs for Docker ...
I1017 17:17:37.560659   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I1017 17:17:37.585279   28215 logs.go:124] Gathering logs for describe nodes ...
I1017 17:17:37.585289   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.26.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I1017 17:17:37.630077   28215 logs.go:124] Gathering logs for kube-apiserver [d8959036328f] ...
I1017 17:17:37.630085   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d8959036328f"
I1017 17:17:37.643368   28215 logs.go:124] Gathering logs for etcd [2730cc2aef95] ...
I1017 17:17:37.643376   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2730cc2aef95"
I1017 17:17:37.656171   28215 logs.go:124] Gathering logs for coredns [926759e7f212] ...
I1017 17:17:37.656180   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 926759e7f212"
I1017 17:17:37.666514   28215 logs.go:124] Gathering logs for coredns [ba6cf9e5453e] ...
I1017 17:17:37.666522   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 ba6cf9e5453e"
I1017 17:17:37.676013   28215 logs.go:124] Gathering logs for storage-provisioner [6106b035dda1] ...
I1017 17:17:37.676022   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 6106b035dda1"
I1017 17:17:37.685429   28215 logs.go:124] Gathering logs for container status ...
I1017 17:17:37.685438   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I1017 17:17:37.700013   28215 logs.go:124] Gathering logs for kubelet ...
I1017 17:17:37.700023   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I1017 17:17:37.739483   28215 logs.go:124] Gathering logs for dmesg ...
I1017 17:17:37.739493   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I1017 17:17:37.744811   28215 logs.go:124] Gathering logs for kube-scheduler [31cc51d3bc7c] ...
I1017 17:17:37.744818   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 31cc51d3bc7c"
I1017 17:17:37.763373   28215 logs.go:124] Gathering logs for kube-proxy [468210b9872f] ...
I1017 17:17:37.763383   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 468210b9872f"
I1017 17:17:40.278778   28215 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I1017 17:17:45.290650   28215 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I1017 17:17:45.461168   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I1017 17:17:45.478401   28215 logs.go:279] 1 containers: [d8959036328f]
I1017 17:17:45.478496   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I1017 17:17:45.487486   28215 logs.go:279] 1 containers: [2730cc2aef95]
I1017 17:17:45.487590   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I1017 17:17:45.495896   28215 logs.go:279] 2 containers: [926759e7f212 ba6cf9e5453e]
I1017 17:17:45.495983   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I1017 17:17:45.504713   28215 logs.go:279] 1 containers: [31cc51d3bc7c]
I1017 17:17:45.504796   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I1017 17:17:45.514686   28215 logs.go:279] 1 containers: [468210b9872f]
I1017 17:17:45.514779   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I1017 17:17:45.524534   28215 logs.go:279] 0 containers: []
W1017 17:17:45.524542   28215 logs.go:281] No container was found matching "kubernetes-dashboard"
I1017 17:17:45.524627   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I1017 17:17:45.533303   28215 logs.go:279] 1 containers: [6106b035dda1]
I1017 17:17:45.533409   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I1017 17:17:45.543186   28215 logs.go:279] 1 containers: [001ef48cc07d]
I1017 17:17:45.543197   28215 logs.go:124] Gathering logs for kubelet ...
I1017 17:17:45.543201   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I1017 17:17:45.588419   28215 logs.go:124] Gathering logs for describe nodes ...
I1017 17:17:45.588431   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.26.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I1017 17:17:45.643534   28215 logs.go:124] Gathering logs for coredns [926759e7f212] ...
I1017 17:17:45.643545   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 926759e7f212"
I1017 17:17:45.653182   28215 logs.go:124] Gathering logs for coredns [ba6cf9e5453e] ...
I1017 17:17:45.653190   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 ba6cf9e5453e"
I1017 17:17:45.662692   28215 logs.go:124] Gathering logs for kube-proxy [468210b9872f] ...
I1017 17:17:45.662702   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 468210b9872f"
I1017 17:17:45.673244   28215 logs.go:124] Gathering logs for kube-controller-manager [001ef48cc07d] ...
I1017 17:17:45.673254   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 001ef48cc07d"
I1017 17:17:45.691942   28215 logs.go:124] Gathering logs for dmesg ...
I1017 17:17:45.691951   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I1017 17:17:45.697249   28215 logs.go:124] Gathering logs for kube-apiserver [d8959036328f] ...
I1017 17:17:45.697257   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d8959036328f"
I1017 17:17:45.711008   28215 logs.go:124] Gathering logs for etcd [2730cc2aef95] ...
I1017 17:17:45.711016   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2730cc2aef95"
I1017 17:17:45.724266   28215 logs.go:124] Gathering logs for kube-scheduler [31cc51d3bc7c] ...
I1017 17:17:45.724276   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 31cc51d3bc7c"
I1017 17:17:45.739688   28215 logs.go:124] Gathering logs for storage-provisioner [6106b035dda1] ...
I1017 17:17:45.739697   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 6106b035dda1"
I1017 17:17:45.749645   28215 logs.go:124] Gathering logs for Docker ...
I1017 17:17:45.749655   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I1017 17:17:45.773575   28215 logs.go:124] Gathering logs for container status ...
I1017 17:17:45.773584   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I1017 17:17:48.293668   28215 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I1017 17:17:53.298831   28215 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I1017 17:17:53.457810   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I1017 17:17:53.473110   28215 logs.go:279] 1 containers: [d8959036328f]
I1017 17:17:53.473194   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I1017 17:17:53.482096   28215 logs.go:279] 1 containers: [2730cc2aef95]
I1017 17:17:53.482220   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I1017 17:17:53.491278   28215 logs.go:279] 2 containers: [926759e7f212 ba6cf9e5453e]
I1017 17:17:53.491369   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I1017 17:17:53.500562   28215 logs.go:279] 1 containers: [31cc51d3bc7c]
I1017 17:17:53.500653   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I1017 17:17:53.509750   28215 logs.go:279] 1 containers: [468210b9872f]
I1017 17:17:53.509848   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I1017 17:17:53.518091   28215 logs.go:279] 0 containers: []
W1017 17:17:53.518099   28215 logs.go:281] No container was found matching "kubernetes-dashboard"
I1017 17:17:53.519052   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I1017 17:17:53.528269   28215 logs.go:279] 1 containers: [6106b035dda1]
I1017 17:17:53.528366   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I1017 17:17:53.538202   28215 logs.go:279] 1 containers: [001ef48cc07d]
I1017 17:17:53.538216   28215 logs.go:124] Gathering logs for coredns [926759e7f212] ...
I1017 17:17:53.538221   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 926759e7f212"
I1017 17:17:53.549030   28215 logs.go:124] Gathering logs for coredns [ba6cf9e5453e] ...
I1017 17:17:53.549040   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 ba6cf9e5453e"
I1017 17:17:53.559055   28215 logs.go:124] Gathering logs for kube-scheduler [31cc51d3bc7c] ...
I1017 17:17:53.559063   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 31cc51d3bc7c"
I1017 17:17:53.572488   28215 logs.go:124] Gathering logs for kubelet ...
I1017 17:17:53.572497   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I1017 17:17:53.613990   28215 logs.go:124] Gathering logs for dmesg ...
I1017 17:17:53.614000   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I1017 17:17:53.619648   28215 logs.go:124] Gathering logs for describe nodes ...
I1017 17:17:53.619655   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.26.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I1017 17:17:53.673049   28215 logs.go:124] Gathering logs for kube-apiserver [d8959036328f] ...
I1017 17:17:53.673058   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d8959036328f"
I1017 17:17:53.687091   28215 logs.go:124] Gathering logs for etcd [2730cc2aef95] ...
I1017 17:17:53.687100   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2730cc2aef95"
I1017 17:17:53.700153   28215 logs.go:124] Gathering logs for kube-proxy [468210b9872f] ...
I1017 17:17:53.700162   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 468210b9872f"
I1017 17:17:53.710711   28215 logs.go:124] Gathering logs for Docker ...
I1017 17:17:53.710720   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I1017 17:17:53.734742   28215 logs.go:124] Gathering logs for container status ...
I1017 17:17:53.734759   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I1017 17:17:53.748757   28215 logs.go:124] Gathering logs for storage-provisioner [6106b035dda1] ...
I1017 17:17:53.748765   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 6106b035dda1"
I1017 17:17:53.761948   28215 logs.go:124] Gathering logs for kube-controller-manager [001ef48cc07d] ...
I1017 17:17:53.761956   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 001ef48cc07d"
I1017 17:17:56.283931   28215 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I1017 17:18:01.286878   28215 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I1017 17:18:01.286975   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I1017 17:18:01.296158   28215 logs.go:279] 1 containers: [d8959036328f]
I1017 17:18:01.296245   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I1017 17:18:01.305094   28215 logs.go:279] 1 containers: [2730cc2aef95]
I1017 17:18:01.305175   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I1017 17:18:01.314211   28215 logs.go:279] 2 containers: [926759e7f212 ba6cf9e5453e]
I1017 17:18:01.314301   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I1017 17:18:01.329284   28215 logs.go:279] 1 containers: [31cc51d3bc7c]
I1017 17:18:01.329370   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I1017 17:18:01.343897   28215 logs.go:279] 1 containers: [468210b9872f]
I1017 17:18:01.343997   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I1017 17:18:01.352583   28215 logs.go:279] 0 containers: []
W1017 17:18:01.352590   28215 logs.go:281] No container was found matching "kubernetes-dashboard"
I1017 17:18:01.352669   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I1017 17:18:01.361632   28215 logs.go:279] 1 containers: [6106b035dda1]
I1017 17:18:01.361733   28215 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I1017 17:18:01.370466   28215 logs.go:279] 1 containers: [001ef48cc07d]
I1017 17:18:01.370480   28215 logs.go:124] Gathering logs for etcd [2730cc2aef95] ...
I1017 17:18:01.370484   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2730cc2aef95"
I1017 17:18:01.383988   28215 logs.go:124] Gathering logs for Docker ...
I1017 17:18:01.383995   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I1017 17:18:01.408809   28215 logs.go:124] Gathering logs for kube-proxy [468210b9872f] ...
I1017 17:18:01.408819   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 468210b9872f"
I1017 17:18:01.419043   28215 logs.go:124] Gathering logs for kubelet ...
I1017 17:18:01.419050   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I1017 17:18:01.459404   28215 logs.go:124] Gathering logs for dmesg ...
I1017 17:18:01.459415   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I1017 17:18:01.464627   28215 logs.go:124] Gathering logs for describe nodes ...
I1017 17:18:01.464635   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.26.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I1017 17:18:01.510069   28215 logs.go:124] Gathering logs for kube-apiserver [d8959036328f] ...
I1017 17:18:01.510078   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d8959036328f"
I1017 17:18:01.522978   28215 logs.go:124] Gathering logs for coredns [926759e7f212] ...
I1017 17:18:01.522987   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 926759e7f212"
I1017 17:18:01.539995   28215 logs.go:124] Gathering logs for coredns [ba6cf9e5453e] ...
I1017 17:18:01.540004   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 ba6cf9e5453e"
I1017 17:18:01.550419   28215 logs.go:124] Gathering logs for kube-scheduler [31cc51d3bc7c] ...
I1017 17:18:01.550427   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 31cc51d3bc7c"
I1017 17:18:01.565545   28215 logs.go:124] Gathering logs for storage-provisioner [6106b035dda1] ...
I1017 17:18:01.565554   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 6106b035dda1"
I1017 17:18:01.578409   28215 logs.go:124] Gathering logs for kube-controller-manager [001ef48cc07d] ...
I1017 17:18:01.578417   28215 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 001ef48cc07d"
I1017 17:18:01.595136   28215 logs.go:124] Gathering logs for container status ...
I1017 17:18:01.595146   28215 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I1017 17:18:04.114324   28215 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I1017 17:18:09.116792   28215 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I1017 17:18:09.136056   28215 out.go:177] 
W1017 17:18:09.155208   28215 out.go:239] ❌  Exiting due to GUEST_START: wait 6m0s for node: wait for healthy API server: apiserver healthz never reported healthy: timed out waiting for the condition
W1017 17:18:09.155237   28215 out.go:239] 
W1017 17:18:09.157715   28215 out.go:239] [31m╭───────────────────────────────────────────────────────────────────────────────────────────╮[0m
[31m│[0m                                                                                           [31m│[0m
[31m│[0m    😿  If the above advice does not help, please let us know:                             [31m│[0m
[31m│[0m    👉  https://github.com/kubernetes/minikube/issues/new/choose                           [31m│[0m
[31m│[0m                                                                                           [31m│[0m
[31m│[0m    Please run `minikube logs --file=logs.txt` and attach logs.txt to the GitHub issue.    [31m│[0m
[31m│[0m                                                                                           [31m│[0m
[31m╰───────────────────────────────────────────────────────────────────────────────────────────╯[0m
I1017 17:18:09.247489   28215 out.go:177] 

* 
* ==> Docker <==
* -- Journal begins at Tue 2023-10-17 11:38:40 UTC, ends at Tue 2023-10-17 11:53:16 UTC. --
Oct 17 11:43:12 minikube dockerd[848]: time="2023-10-17T11:43:12.464029849Z" level=info msg="loading plugin \"io.containerd.event.v1.publisher\"..." runtime=io.containerd.runc.v2 type=io.containerd.event.v1
Oct 17 11:43:12 minikube dockerd[848]: time="2023-10-17T11:43:12.464080061Z" level=info msg="loading plugin \"io.containerd.internal.v1.shutdown\"..." runtime=io.containerd.runc.v2 type=io.containerd.internal.v1
Oct 17 11:43:12 minikube dockerd[848]: time="2023-10-17T11:43:12.464086603Z" level=info msg="loading plugin \"io.containerd.ttrpc.v1.task\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1
Oct 17 11:43:12 minikube dockerd[848]: time="2023-10-17T11:43:12.464161274Z" level=info msg="starting signal loop" namespace=moby path=/run/docker/containerd/daemon/io.containerd.runtime.v2.task/moby/92dc3dbb942b016c4f8a864710bb3b7deb6b6e67cc9adb07c558f068c7fb964e pid=10494 runtime=io.containerd.runc.v2
Oct 17 11:43:12 minikube dockerd[848]: time="2023-10-17T11:43:12.468437994Z" level=info msg="loading plugin \"io.containerd.event.v1.publisher\"..." runtime=io.containerd.runc.v2 type=io.containerd.event.v1
Oct 17 11:43:12 minikube dockerd[848]: time="2023-10-17T11:43:12.468471829Z" level=info msg="loading plugin \"io.containerd.internal.v1.shutdown\"..." runtime=io.containerd.runc.v2 type=io.containerd.internal.v1
Oct 17 11:43:12 minikube dockerd[848]: time="2023-10-17T11:43:12.468478038Z" level=info msg="loading plugin \"io.containerd.ttrpc.v1.task\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1
Oct 17 11:43:12 minikube dockerd[848]: time="2023-10-17T11:43:12.468624005Z" level=info msg="starting signal loop" namespace=moby path=/run/docker/containerd/daemon/io.containerd.runtime.v2.task/moby/e292bd5fc64b3b7dfdec5965291961189f397acc94c6d7cc2ae38e01d3a18276 pid=10511 runtime=io.containerd.runc.v2
Oct 17 11:43:12 minikube dockerd[848]: time="2023-10-17T11:43:12.524227571Z" level=info msg="loading plugin \"io.containerd.event.v1.publisher\"..." runtime=io.containerd.runc.v2 type=io.containerd.event.v1
Oct 17 11:43:12 minikube dockerd[848]: time="2023-10-17T11:43:12.524412040Z" level=info msg="loading plugin \"io.containerd.internal.v1.shutdown\"..." runtime=io.containerd.runc.v2 type=io.containerd.internal.v1
Oct 17 11:43:12 minikube dockerd[848]: time="2023-10-17T11:43:12.524445543Z" level=info msg="loading plugin \"io.containerd.ttrpc.v1.task\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1
Oct 17 11:43:12 minikube dockerd[848]: time="2023-10-17T11:43:12.524648763Z" level=info msg="starting signal loop" namespace=moby path=/run/docker/containerd/daemon/io.containerd.runtime.v2.task/moby/9e546242a974792f3382a03c824e70a3dfb80e2716dc9da9b60c37bc0ff58e02 pid=10540 runtime=io.containerd.runc.v2
Oct 17 11:43:12 minikube dockerd[848]: time="2023-10-17T11:43:12.658008749Z" level=info msg="loading plugin \"io.containerd.event.v1.publisher\"..." runtime=io.containerd.runc.v2 type=io.containerd.event.v1
Oct 17 11:43:12 minikube dockerd[848]: time="2023-10-17T11:43:12.658444359Z" level=info msg="loading plugin \"io.containerd.internal.v1.shutdown\"..." runtime=io.containerd.runc.v2 type=io.containerd.internal.v1
Oct 17 11:43:12 minikube dockerd[848]: time="2023-10-17T11:43:12.658465860Z" level=info msg="loading plugin \"io.containerd.ttrpc.v1.task\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1
Oct 17 11:43:12 minikube dockerd[848]: time="2023-10-17T11:43:12.658981516Z" level=info msg="starting signal loop" namespace=moby path=/run/docker/containerd/daemon/io.containerd.runtime.v2.task/moby/2730cc2aef95f95917a5e9da78129fd4607ac2b916f27bdc3acfe24159eb2d15 pid=10612 runtime=io.containerd.runc.v2
Oct 17 11:43:12 minikube dockerd[848]: time="2023-10-17T11:43:12.738859191Z" level=info msg="loading plugin \"io.containerd.event.v1.publisher\"..." runtime=io.containerd.runc.v2 type=io.containerd.event.v1
Oct 17 11:43:12 minikube dockerd[848]: time="2023-10-17T11:43:12.739618612Z" level=info msg="loading plugin \"io.containerd.internal.v1.shutdown\"..." runtime=io.containerd.runc.v2 type=io.containerd.internal.v1
Oct 17 11:43:12 minikube dockerd[848]: time="2023-10-17T11:43:12.740205523Z" level=info msg="loading plugin \"io.containerd.ttrpc.v1.task\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1
Oct 17 11:43:12 minikube dockerd[848]: time="2023-10-17T11:43:12.740345698Z" level=info msg="starting signal loop" namespace=moby path=/run/docker/containerd/daemon/io.containerd.runtime.v2.task/moby/001ef48cc07d011f7a3771f3c1b6f814e401bc6132bfc095a3e7c9cec33df319 pid=10654 runtime=io.containerd.runc.v2
Oct 17 11:43:12 minikube dockerd[848]: time="2023-10-17T11:43:12.932853966Z" level=info msg="loading plugin \"io.containerd.event.v1.publisher\"..." runtime=io.containerd.runc.v2 type=io.containerd.event.v1
Oct 17 11:43:12 minikube dockerd[848]: time="2023-10-17T11:43:12.934008495Z" level=info msg="loading plugin \"io.containerd.internal.v1.shutdown\"..." runtime=io.containerd.runc.v2 type=io.containerd.internal.v1
Oct 17 11:43:12 minikube dockerd[848]: time="2023-10-17T11:43:12.934044789Z" level=info msg="loading plugin \"io.containerd.ttrpc.v1.task\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1
Oct 17 11:43:12 minikube dockerd[848]: time="2023-10-17T11:43:12.934753082Z" level=info msg="loading plugin \"io.containerd.event.v1.publisher\"..." runtime=io.containerd.runc.v2 type=io.containerd.event.v1
Oct 17 11:43:12 minikube dockerd[848]: time="2023-10-17T11:43:12.934940594Z" level=info msg="starting signal loop" namespace=moby path=/run/docker/containerd/daemon/io.containerd.runtime.v2.task/moby/31cc51d3bc7c28363001cfa888ef71884ec609137daa22f6dd0d4727a3451c45 pid=10707 runtime=io.containerd.runc.v2
Oct 17 11:43:12 minikube dockerd[848]: time="2023-10-17T11:43:12.934957511Z" level=info msg="loading plugin \"io.containerd.internal.v1.shutdown\"..." runtime=io.containerd.runc.v2 type=io.containerd.internal.v1
Oct 17 11:43:12 minikube dockerd[848]: time="2023-10-17T11:43:12.935083102Z" level=info msg="loading plugin \"io.containerd.ttrpc.v1.task\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1
Oct 17 11:43:12 minikube dockerd[848]: time="2023-10-17T11:43:12.935235653Z" level=info msg="starting signal loop" namespace=moby path=/run/docker/containerd/daemon/io.containerd.runtime.v2.task/moby/d8959036328f31eb8cca0a6de6d9320c6588ea1de04edd7294b7c33678635d21 pid=10718 runtime=io.containerd.runc.v2
Oct 17 11:43:31 minikube dockerd[848]: time="2023-10-17T11:43:31.456231677Z" level=info msg="loading plugin \"io.containerd.event.v1.publisher\"..." runtime=io.containerd.runc.v2 type=io.containerd.event.v1
Oct 17 11:43:31 minikube dockerd[848]: time="2023-10-17T11:43:31.456270263Z" level=info msg="loading plugin \"io.containerd.internal.v1.shutdown\"..." runtime=io.containerd.runc.v2 type=io.containerd.internal.v1
Oct 17 11:43:31 minikube dockerd[848]: time="2023-10-17T11:43:31.456277471Z" level=info msg="loading plugin \"io.containerd.ttrpc.v1.task\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1
Oct 17 11:43:31 minikube dockerd[848]: time="2023-10-17T11:43:31.456357767Z" level=info msg="starting signal loop" namespace=moby path=/run/docker/containerd/daemon/io.containerd.runtime.v2.task/moby/28b7a080d1e820ab11b0c7ff7b8c855f592d3b95bc2d23e508bdfc51261c5ea0 pid=11794 runtime=io.containerd.runc.v2
Oct 17 11:43:31 minikube dockerd[848]: time="2023-10-17T11:43:31.665583773Z" level=info msg="loading plugin \"io.containerd.event.v1.publisher\"..." runtime=io.containerd.runc.v2 type=io.containerd.event.v1
Oct 17 11:43:31 minikube dockerd[848]: time="2023-10-17T11:43:31.665677986Z" level=info msg="loading plugin \"io.containerd.internal.v1.shutdown\"..." runtime=io.containerd.runc.v2 type=io.containerd.internal.v1
Oct 17 11:43:31 minikube dockerd[848]: time="2023-10-17T11:43:31.665688945Z" level=info msg="loading plugin \"io.containerd.ttrpc.v1.task\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1
Oct 17 11:43:31 minikube dockerd[848]: time="2023-10-17T11:43:31.665856953Z" level=info msg="starting signal loop" namespace=moby path=/run/docker/containerd/daemon/io.containerd.runtime.v2.task/moby/95289819af7493e2fa64d4e2dc91965cdb9cd4092d5cbc8abb03ce812305c621 pid=11844 runtime=io.containerd.runc.v2
Oct 17 11:43:31 minikube dockerd[848]: time="2023-10-17T11:43:31.670072038Z" level=info msg="loading plugin \"io.containerd.event.v1.publisher\"..." runtime=io.containerd.runc.v2 type=io.containerd.event.v1
Oct 17 11:43:31 minikube dockerd[848]: time="2023-10-17T11:43:31.670116791Z" level=info msg="loading plugin \"io.containerd.internal.v1.shutdown\"..." runtime=io.containerd.runc.v2 type=io.containerd.internal.v1
Oct 17 11:43:31 minikube dockerd[848]: time="2023-10-17T11:43:31.670124708Z" level=info msg="loading plugin \"io.containerd.ttrpc.v1.task\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1
Oct 17 11:43:31 minikube dockerd[848]: time="2023-10-17T11:43:31.670520061Z" level=info msg="starting signal loop" namespace=moby path=/run/docker/containerd/daemon/io.containerd.runtime.v2.task/moby/1f1aeb850b5b078a0c24dc6e7e611c08dc68982603bc06363e24fc3d72f753da pid=11863 runtime=io.containerd.runc.v2
Oct 17 11:43:31 minikube dockerd[848]: time="2023-10-17T11:43:31.670572605Z" level=info msg="loading plugin \"io.containerd.event.v1.publisher\"..." runtime=io.containerd.runc.v2 type=io.containerd.event.v1
Oct 17 11:43:31 minikube dockerd[848]: time="2023-10-17T11:43:31.670603773Z" level=info msg="loading plugin \"io.containerd.internal.v1.shutdown\"..." runtime=io.containerd.runc.v2 type=io.containerd.internal.v1
Oct 17 11:43:31 minikube dockerd[848]: time="2023-10-17T11:43:31.670611774Z" level=info msg="loading plugin \"io.containerd.ttrpc.v1.task\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1
Oct 17 11:43:31 minikube dockerd[848]: time="2023-10-17T11:43:31.670942582Z" level=info msg="starting signal loop" namespace=moby path=/run/docker/containerd/daemon/io.containerd.runtime.v2.task/moby/6106b035dda1464d405e13482289e44c8e99f9e82966047d586a33edf85f74b3 pid=11862 runtime=io.containerd.runc.v2
Oct 17 11:43:32 minikube dockerd[848]: time="2023-10-17T11:43:32.145574153Z" level=info msg="loading plugin \"io.containerd.event.v1.publisher\"..." runtime=io.containerd.runc.v2 type=io.containerd.event.v1
Oct 17 11:43:32 minikube dockerd[848]: time="2023-10-17T11:43:32.145610530Z" level=info msg="loading plugin \"io.containerd.internal.v1.shutdown\"..." runtime=io.containerd.runc.v2 type=io.containerd.internal.v1
Oct 17 11:43:32 minikube dockerd[848]: time="2023-10-17T11:43:32.145618072Z" level=info msg="loading plugin \"io.containerd.ttrpc.v1.task\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1
Oct 17 11:43:32 minikube dockerd[848]: time="2023-10-17T11:43:32.145799956Z" level=info msg="starting signal loop" namespace=moby path=/run/docker/containerd/daemon/io.containerd.runtime.v2.task/moby/ba6cf9e5453e0bce9d1c9343a89119b5e8346089e7aed8ea101168622696d1cd pid=12071 runtime=io.containerd.runc.v2
Oct 17 11:43:32 minikube dockerd[848]: time="2023-10-17T11:43:32.203012194Z" level=info msg="loading plugin \"io.containerd.event.v1.publisher\"..." runtime=io.containerd.runc.v2 type=io.containerd.event.v1
Oct 17 11:43:32 minikube dockerd[848]: time="2023-10-17T11:43:32.203099157Z" level=info msg="loading plugin \"io.containerd.internal.v1.shutdown\"..." runtime=io.containerd.runc.v2 type=io.containerd.internal.v1
Oct 17 11:43:32 minikube dockerd[848]: time="2023-10-17T11:43:32.203107032Z" level=info msg="loading plugin \"io.containerd.ttrpc.v1.task\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1
Oct 17 11:43:32 minikube dockerd[848]: time="2023-10-17T11:43:32.203352544Z" level=info msg="starting signal loop" namespace=moby path=/run/docker/containerd/daemon/io.containerd.runtime.v2.task/moby/926759e7f212abcf2d9a6f00d656aa646268e743babebc428127e69314b59106 pid=12115 runtime=io.containerd.runc.v2
Oct 17 11:43:32 minikube dockerd[848]: time="2023-10-17T11:43:32.325786456Z" level=info msg="loading plugin \"io.containerd.event.v1.publisher\"..." runtime=io.containerd.runc.v2 type=io.containerd.event.v1
Oct 17 11:43:32 minikube dockerd[848]: time="2023-10-17T11:43:32.325871752Z" level=info msg="loading plugin \"io.containerd.internal.v1.shutdown\"..." runtime=io.containerd.runc.v2 type=io.containerd.internal.v1
Oct 17 11:43:32 minikube dockerd[848]: time="2023-10-17T11:43:32.325929588Z" level=info msg="loading plugin \"io.containerd.ttrpc.v1.task\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1
Oct 17 11:43:32 minikube dockerd[848]: time="2023-10-17T11:43:32.326065720Z" level=info msg="starting signal loop" namespace=moby path=/run/docker/containerd/daemon/io.containerd.runtime.v2.task/moby/a8ef94978d9a3521dd30037547552d68a7bfd78430ce44076ac11ba52b1975e4 pid=12168 runtime=io.containerd.runc.v2
Oct 17 11:43:32 minikube dockerd[848]: time="2023-10-17T11:43:32.423902003Z" level=info msg="loading plugin \"io.containerd.event.v1.publisher\"..." runtime=io.containerd.runc.v2 type=io.containerd.event.v1
Oct 17 11:43:32 minikube dockerd[848]: time="2023-10-17T11:43:32.423977715Z" level=info msg="loading plugin \"io.containerd.internal.v1.shutdown\"..." runtime=io.containerd.runc.v2 type=io.containerd.internal.v1
Oct 17 11:43:32 minikube dockerd[848]: time="2023-10-17T11:43:32.423986090Z" level=info msg="loading plugin \"io.containerd.ttrpc.v1.task\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1
Oct 17 11:43:32 minikube dockerd[848]: time="2023-10-17T11:43:32.424317065Z" level=info msg="starting signal loop" namespace=moby path=/run/docker/containerd/daemon/io.containerd.runtime.v2.task/moby/468210b9872f3bc7b08466c466eb02ab104e322f4be1c386f3b2b492f2678474 pid=12216 runtime=io.containerd.runc.v2

* 
* ==> container status <==
* CONTAINER           IMAGE               CREATED             STATE               NAME                      ATTEMPT             POD ID
468210b9872f3       fe58ad8bdce21       9 minutes ago       Running             kube-proxy                0                   a8ef94978d9a3
926759e7f212a       b19406328e70d       9 minutes ago       Running             coredns                   0                   95289819af749
ba6cf9e5453e0       b19406328e70d       9 minutes ago       Running             coredns                   0                   1f1aeb850b5b0
6106b035dda14       ba04bb24b9575       9 minutes ago       Running             storage-provisioner       0                   28b7a080d1e82
d8959036328f3       c85f05247d533       10 minutes ago      Running             kube-apiserver            0                   e292bd5fc64b3
31cc51d3bc7c2       88fe003542051       10 minutes ago      Running             kube-scheduler            0                   92dc3dbb942b0
001ef48cc07d0       66c85aa670f4c       10 minutes ago      Running             kube-controller-manager   0                   9e546242a9747
2730cc2aef95f       ef24580282403       10 minutes ago      Running             etcd                      0                   f269f989107f6

* 
* ==> coredns [926759e7f212] <==
* .:53
[INFO] plugin/reload: Running configuration SHA512 = 4369d49e705690634e66dc4876ba448687add67b4e702a1c8bd9cbe26bf81de42209d08c6b52f2167c69004abbe79b233480d7bb5830c218d455f30e7efd3686
CoreDNS-1.9.3
linux/arm64, go1.18.2, 45b0a11
[INFO] 127.0.0.1:52286 - 64130 "HINFO IN 8604248792205451320.7233752918108141019. udp 57 false 512" NXDOMAIN qr,rd,ra 132 0.291930103s

* 
* ==> coredns [ba6cf9e5453e] <==
* .:53
[INFO] plugin/reload: Running configuration SHA512 = 4369d49e705690634e66dc4876ba448687add67b4e702a1c8bd9cbe26bf81de42209d08c6b52f2167c69004abbe79b233480d7bb5830c218d455f30e7efd3686
CoreDNS-1.9.3
linux/arm64, go1.18.2, 45b0a11
[INFO] 127.0.0.1:41892 - 39417 "HINFO IN 2939430448730109165.9119780960542412854. udp 57 false 512" NXDOMAIN qr,rd,ra 132 0.381233674s

* 
* ==> describe nodes <==
* Name:               minikube
Roles:              control-plane
Labels:             beta.kubernetes.io/arch=arm64
                    beta.kubernetes.io/os=linux
                    kubernetes.io/arch=arm64
                    kubernetes.io/hostname=minikube
                    kubernetes.io/os=linux
                    minikube.k8s.io/commit=ddac20b4b34a9c8c857fc602203b6ba2679794d3
                    minikube.k8s.io/name=minikube
                    minikube.k8s.io/primary=true
                    minikube.k8s.io/updated_at=2023_10_17T17_13_19_0700
                    minikube.k8s.io/version=v1.29.0
                    node-role.kubernetes.io/control-plane=
                    node.kubernetes.io/exclude-from-external-load-balancers=
Annotations:        kubeadm.alpha.kubernetes.io/cri-socket: unix:///var/run/cri-dockerd.sock
                    node.alpha.kubernetes.io/ttl: 0
                    volumes.kubernetes.io/controller-managed-attach-detach: true
CreationTimestamp:  Tue, 17 Oct 2023 11:43:15 +0000
Taints:             <none>
Unschedulable:      false
Lease:
  HolderIdentity:  minikube
  AcquireTime:     <unset>
  RenewTime:       Tue, 17 Oct 2023 11:53:11 +0000
Conditions:
  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message
  ----             ------  -----------------                 ------------------                ------                       -------
  MemoryPressure   False   Tue, 17 Oct 2023 11:48:45 +0000   Tue, 17 Oct 2023 11:43:13 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available
  DiskPressure     False   Tue, 17 Oct 2023 11:48:45 +0000   Tue, 17 Oct 2023 11:43:13 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure
  PIDPressure      False   Tue, 17 Oct 2023 11:48:45 +0000   Tue, 17 Oct 2023 11:43:13 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available
  Ready            True    Tue, 17 Oct 2023 11:48:45 +0000   Tue, 17 Oct 2023 11:43:21 +0000   KubeletReady                 kubelet is posting ready status
Addresses:
  InternalIP:  10.0.2.15
  Hostname:    minikube
Capacity:
  cpu:                2
  ephemeral-storage:  17784760Ki
  hugepages-1Gi:      0
  hugepages-2Mi:      0
  hugepages-32Mi:     0
  hugepages-64Ki:     0
  memory:             3905976Ki
  pods:               110
Allocatable:
  cpu:                2
  ephemeral-storage:  17784760Ki
  hugepages-1Gi:      0
  hugepages-2Mi:      0
  hugepages-32Mi:     0
  hugepages-64Ki:     0
  memory:             3905976Ki
  pods:               110
System Info:
  Machine ID:                 ab80052878f849fab0bf121ae3d018d0
  System UUID:                ab80052878f849fab0bf121ae3d018d0
  Boot ID:                    32c8909b-5339-4412-a460-aa2670801065
  Kernel Version:             5.10.57
  OS Image:                   Buildroot 2021.02.12
  Operating System:           linux
  Architecture:               arm64
  Container Runtime Version:  docker://20.10.23
  Kubelet Version:            v1.26.1
  Kube-Proxy Version:         v1.26.1
PodCIDR:                      10.244.0.0/24
PodCIDRs:                     10.244.0.0/24
Non-terminated Pods:          (8 in total)
  Namespace                   Name                                CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age
  ---------                   ----                                ------------  ----------  ---------------  -------------  ---
  kube-system                 coredns-787d4945fb-8bltg            100m (5%!)(MISSING)     0 (0%!)(MISSING)      70Mi (1%!)(MISSING)        170Mi (4%!)(MISSING)     9m46s
  kube-system                 coredns-787d4945fb-svfmw            100m (5%!)(MISSING)     0 (0%!)(MISSING)      70Mi (1%!)(MISSING)        170Mi (4%!)(MISSING)     9m46s
  kube-system                 etcd-minikube                       100m (5%!)(MISSING)     0 (0%!)(MISSING)      100Mi (2%!)(MISSING)       0 (0%!)(MISSING)         9m58s
  kube-system                 kube-apiserver-minikube             250m (12%!)(MISSING)    0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         9m58s
  kube-system                 kube-controller-manager-minikube    200m (10%!)(MISSING)    0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         9m58s
  kube-system                 kube-proxy-dm7mp                    0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         9m46s
  kube-system                 kube-scheduler-minikube             100m (5%!)(MISSING)     0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         10m
  kube-system                 storage-provisioner                 0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         9m57s
Allocated resources:
  (Total limits may be over 100 percent, i.e., overcommitted.)
  Resource           Requests    Limits
  --------           --------    ------
  cpu                850m (42%!)(MISSING)  0 (0%!)(MISSING)
  memory             240Mi (6%!)(MISSING)  340Mi (8%!)(MISSING)
  ephemeral-storage  0 (0%!)(MISSING)      0 (0%!)(MISSING)
  hugepages-1Gi      0 (0%!)(MISSING)      0 (0%!)(MISSING)
  hugepages-2Mi      0 (0%!)(MISSING)      0 (0%!)(MISSING)
  hugepages-32Mi     0 (0%!)(MISSING)      0 (0%!)(MISSING)
  hugepages-64Ki     0 (0%!)(MISSING)      0 (0%!)(MISSING)
Events:
  Type    Reason                   Age                From             Message
  ----    ------                   ----               ----             -------
  Normal  Starting                 9m44s              kube-proxy       
  Normal  Starting                 10m                kubelet          Starting kubelet.
  Normal  NodeAllocatableEnforced  10m                kubelet          Updated Node Allocatable limit across pods
  Normal  NodeHasSufficientMemory  10m (x5 over 10m)  kubelet          Node minikube status is now: NodeHasSufficientMemory
  Normal  NodeHasNoDiskPressure    10m (x5 over 10m)  kubelet          Node minikube status is now: NodeHasNoDiskPressure
  Normal  NodeHasSufficientPID     10m (x5 over 10m)  kubelet          Node minikube status is now: NodeHasSufficientPID
  Normal  Starting                 9m59s              kubelet          Starting kubelet.
  Normal  NodeAllocatableEnforced  9m58s              kubelet          Updated Node Allocatable limit across pods
  Normal  NodeHasSufficientMemory  9m58s              kubelet          Node minikube status is now: NodeHasSufficientMemory
  Normal  NodeHasNoDiskPressure    9m58s              kubelet          Node minikube status is now: NodeHasNoDiskPressure
  Normal  NodeHasSufficientPID     9m58s              kubelet          Node minikube status is now: NodeHasSufficientPID
  Normal  NodeReady                9m56s              kubelet          Node minikube status is now: NodeReady
  Normal  RegisteredNode           9m46s              node-controller  Node minikube event: Registered Node minikube in Controller

* 
* ==> dmesg <==
* [Oct17 11:38] ACPI: SRAT not present
[  +0.000000] KASLR disabled due to lack of seed
[  +0.859412] EINJ: EINJ table not found.
[  +0.808107] systemd-fstab-generator[114]: Ignoring "noauto" for root device
[  +0.056172] systemd[1]: systemd-journald.service: unit configures an IP firewall, but the local system does not support BPF/cgroup firewalling.
[  +0.001007] systemd[1]: (This warning is only shown for the first unit using IP firewalling.)
[  +7.012407] systemd-fstab-generator[452]: Ignoring "noauto" for root device
[  +0.072818] systemd-fstab-generator[463]: Ignoring "noauto" for root device
[  +0.980181] systemd-fstab-generator[778]: Ignoring "noauto" for root device
[  +0.176450] systemd-fstab-generator[811]: Ignoring "noauto" for root device
[  +0.076370] systemd-fstab-generator[822]: Ignoring "noauto" for root device
[  +0.082343] systemd-fstab-generator[835]: Ignoring "noauto" for root device
[  +1.340671] systemd-fstab-generator[1029]: Ignoring "noauto" for root device
[  +0.075367] systemd-fstab-generator[1040]: Ignoring "noauto" for root device
[  +0.076139] systemd-fstab-generator[1051]: Ignoring "noauto" for root device
[  +0.079612] systemd-fstab-generator[1062]: Ignoring "noauto" for root device
[Oct17 11:39] systemd-fstab-generator[1287]: Ignoring "noauto" for root device
[  +0.312154] kauditd_printk_skb: 67 callbacks suppressed
[  +7.760967] kauditd_printk_skb: 10 callbacks suppressed
[  +8.720477] kauditd_printk_skb: 12 callbacks suppressed
[Oct17 11:43] systemd-fstab-generator[10304]: Ignoring "noauto" for root device
[  +7.236855] systemd-fstab-generator[11240]: Ignoring "noauto" for root device
[Oct17 11:44] kauditd_printk_skb: 8 callbacks suppressed
[Oct17 11:52] hrtimer: interrupt took 15631207 ns

* 
* ==> etcd [2730cc2aef95] <==
* {"level":"warn","ts":"2023-10-17T11:43:12.920Z","caller":"flags/flag.go:93","msg":"unrecognized environment variable","environment-variable":"ETCD_UNSUPPORTED_ARCH=arm64"}
{"level":"info","ts":"2023-10-17T11:43:12.920Z","caller":"etcdmain/etcd.go:73","msg":"Running: ","args":["etcd","--advertise-client-urls=https://10.0.2.15:2379","--cert-file=/var/lib/minikube/certs/etcd/server.crt","--client-cert-auth=true","--data-dir=/var/lib/minikube/etcd","--experimental-initial-corrupt-check=true","--experimental-watch-progress-notify-interval=5s","--initial-advertise-peer-urls=https://10.0.2.15:2380","--initial-cluster=minikube=https://10.0.2.15:2380","--key-file=/var/lib/minikube/certs/etcd/server.key","--listen-client-urls=https://127.0.0.1:2379,https://10.0.2.15:2379","--listen-metrics-urls=http://127.0.0.1:2381","--listen-peer-urls=https://10.0.2.15:2380","--name=minikube","--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt","--peer-client-cert-auth=true","--peer-key-file=/var/lib/minikube/certs/etcd/peer.key","--peer-trusted-ca-file=/var/lib/minikube/certs/etcd/ca.crt","--proxy-refresh-interval=70000","--snapshot-count=10000","--trusted-ca-file=/var/lib/minikube/certs/etcd/ca.crt"]}
{"level":"info","ts":"2023-10-17T11:43:12.920Z","caller":"embed/etcd.go:124","msg":"configuring peer listeners","listen-peer-urls":["https://10.0.2.15:2380"]}
{"level":"info","ts":"2023-10-17T11:43:12.920Z","caller":"embed/etcd.go:484","msg":"starting with peer TLS","tls-info":"cert = /var/lib/minikube/certs/etcd/peer.crt, key = /var/lib/minikube/certs/etcd/peer.key, client-cert=, client-key=, trusted-ca = /var/lib/minikube/certs/etcd/ca.crt, client-cert-auth = true, crl-file = ","cipher-suites":[]}
{"level":"info","ts":"2023-10-17T11:43:12.921Z","caller":"embed/etcd.go:132","msg":"configuring client listeners","listen-client-urls":["https://10.0.2.15:2379","https://127.0.0.1:2379"]}
{"level":"info","ts":"2023-10-17T11:43:12.921Z","caller":"embed/etcd.go:306","msg":"starting an etcd server","etcd-version":"3.5.6","git-sha":"cecbe35ce","go-version":"go1.17.13","go-os":"linux","go-arch":"arm64","max-cpu-set":2,"max-cpu-available":2,"member-initialized":false,"name":"minikube","data-dir":"/var/lib/minikube/etcd","wal-dir":"","wal-dir-dedicated":"","member-dir":"/var/lib/minikube/etcd/member","force-new-cluster":false,"heartbeat-interval":"100ms","election-timeout":"1s","initial-election-tick-advance":true,"snapshot-count":10000,"max-wals":5,"max-snapshots":5,"snapshot-catchup-entries":5000,"initial-advertise-peer-urls":["https://10.0.2.15:2380"],"listen-peer-urls":["https://10.0.2.15:2380"],"advertise-client-urls":["https://10.0.2.15:2379"],"listen-client-urls":["https://10.0.2.15:2379","https://127.0.0.1:2379"],"listen-metrics-urls":["http://127.0.0.1:2381"],"cors":["*"],"host-whitelist":["*"],"initial-cluster":"minikube=https://10.0.2.15:2380","initial-cluster-state":"new","initial-cluster-token":"etcd-cluster","quota-backend-bytes":2147483648,"max-request-bytes":1572864,"max-concurrent-streams":4294967295,"pre-vote":true,"initial-corrupt-check":true,"corrupt-check-time-interval":"0s","compact-check-time-enabled":false,"compact-check-time-interval":"1m0s","auto-compaction-mode":"periodic","auto-compaction-retention":"0s","auto-compaction-interval":"0s","discovery-url":"","discovery-proxy":"","downgrade-check-interval":"5s"}
{"level":"info","ts":"2023-10-17T11:43:12.923Z","caller":"etcdserver/backend.go:81","msg":"opened backend db","path":"/var/lib/minikube/etcd/member/snap/db","took":"2.240179ms"}
{"level":"info","ts":"2023-10-17T11:43:12.937Z","caller":"etcdserver/raft.go:494","msg":"starting local member","local-member-id":"f074a195de705325","cluster-id":"ef296cf39f5d9d66"}
{"level":"info","ts":"2023-10-17T11:43:12.937Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"f074a195de705325 switched to configuration voters=()"}
{"level":"info","ts":"2023-10-17T11:43:12.937Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"f074a195de705325 became follower at term 0"}
{"level":"info","ts":"2023-10-17T11:43:12.937Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"newRaft f074a195de705325 [peers: [], term: 0, commit: 0, applied: 0, lastindex: 0, lastterm: 0]"}
{"level":"info","ts":"2023-10-17T11:43:12.937Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"f074a195de705325 became follower at term 1"}
{"level":"info","ts":"2023-10-17T11:43:12.937Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"f074a195de705325 switched to configuration voters=(17326651331455243045)"}
{"level":"warn","ts":"2023-10-17T11:43:12.939Z","caller":"auth/store.go:1234","msg":"simple token is not cryptographically signed"}
{"level":"info","ts":"2023-10-17T11:43:12.940Z","caller":"mvcc/kvstore.go:393","msg":"kvstore restored","current-rev":1}
{"level":"info","ts":"2023-10-17T11:43:12.941Z","caller":"etcdserver/quota.go:94","msg":"enabled backend quota with default value","quota-name":"v3-applier","quota-size-bytes":2147483648,"quota-size":"2.1 GB"}
{"level":"info","ts":"2023-10-17T11:43:12.942Z","caller":"etcdserver/server.go:854","msg":"starting etcd server","local-member-id":"f074a195de705325","local-server-version":"3.5.6","cluster-version":"to_be_decided"}
{"level":"info","ts":"2023-10-17T11:43:12.944Z","caller":"fileutil/purge.go:44","msg":"started to purge file","dir":"/var/lib/minikube/etcd/member/snap","suffix":"snap.db","max":5,"interval":"30s"}
{"level":"info","ts":"2023-10-17T11:43:12.944Z","caller":"fileutil/purge.go:44","msg":"started to purge file","dir":"/var/lib/minikube/etcd/member/snap","suffix":"snap","max":5,"interval":"30s"}
{"level":"info","ts":"2023-10-17T11:43:12.944Z","caller":"fileutil/purge.go:44","msg":"started to purge file","dir":"/var/lib/minikube/etcd/member/wal","suffix":"wal","max":5,"interval":"30s"}
{"level":"info","ts":"2023-10-17T11:43:12.944Z","caller":"etcdserver/server.go:738","msg":"started as single-node; fast-forwarding election ticks","local-member-id":"f074a195de705325","forward-ticks":9,"forward-duration":"900ms","election-ticks":10,"election-timeout":"1s"}
{"level":"info","ts":"2023-10-17T11:43:12.947Z","caller":"embed/etcd.go:687","msg":"starting with client TLS","tls-info":"cert = /var/lib/minikube/certs/etcd/server.crt, key = /var/lib/minikube/certs/etcd/server.key, client-cert=, client-key=, trusted-ca = /var/lib/minikube/certs/etcd/ca.crt, client-cert-auth = true, crl-file = ","cipher-suites":[]}
{"level":"info","ts":"2023-10-17T11:43:12.947Z","caller":"embed/etcd.go:275","msg":"now serving peer/client/metrics","local-member-id":"f074a195de705325","initial-advertise-peer-urls":["https://10.0.2.15:2380"],"listen-peer-urls":["https://10.0.2.15:2380"],"advertise-client-urls":["https://10.0.2.15:2379"],"listen-client-urls":["https://10.0.2.15:2379","https://127.0.0.1:2379"],"listen-metrics-urls":["http://127.0.0.1:2381"]}
{"level":"info","ts":"2023-10-17T11:43:12.947Z","caller":"embed/etcd.go:762","msg":"serving metrics","address":"http://127.0.0.1:2381"}
{"level":"info","ts":"2023-10-17T11:43:12.947Z","caller":"embed/etcd.go:586","msg":"serving peer traffic","address":"10.0.2.15:2380"}
{"level":"info","ts":"2023-10-17T11:43:12.947Z","caller":"embed/etcd.go:558","msg":"cmux::serve","address":"10.0.2.15:2380"}
{"level":"info","ts":"2023-10-17T11:43:12.947Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"f074a195de705325 switched to configuration voters=(17326651331455243045)"}
{"level":"info","ts":"2023-10-17T11:43:12.947Z","caller":"membership/cluster.go:421","msg":"added member","cluster-id":"ef296cf39f5d9d66","local-member-id":"f074a195de705325","added-peer-id":"f074a195de705325","added-peer-peer-urls":["https://10.0.2.15:2380"]}
{"level":"info","ts":"2023-10-17T11:43:13.938Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"f074a195de705325 is starting a new election at term 1"}
{"level":"info","ts":"2023-10-17T11:43:13.938Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"f074a195de705325 became pre-candidate at term 1"}
{"level":"info","ts":"2023-10-17T11:43:13.938Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"f074a195de705325 received MsgPreVoteResp from f074a195de705325 at term 1"}
{"level":"info","ts":"2023-10-17T11:43:13.938Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"f074a195de705325 became candidate at term 2"}
{"level":"info","ts":"2023-10-17T11:43:13.938Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"f074a195de705325 received MsgVoteResp from f074a195de705325 at term 2"}
{"level":"info","ts":"2023-10-17T11:43:13.938Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"f074a195de705325 became leader at term 2"}
{"level":"info","ts":"2023-10-17T11:43:13.938Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"raft.node: f074a195de705325 elected leader f074a195de705325 at term 2"}
{"level":"info","ts":"2023-10-17T11:43:13.946Z","caller":"embed/serve.go:100","msg":"ready to serve client requests"}
{"level":"info","ts":"2023-10-17T11:43:13.947Z","caller":"embed/serve.go:198","msg":"serving client traffic securely","address":"127.0.0.1:2379"}
{"level":"info","ts":"2023-10-17T11:43:13.949Z","caller":"etcdserver/server.go:2563","msg":"setting up initial cluster version using v2 API","cluster-version":"3.5"}
{"level":"info","ts":"2023-10-17T11:43:13.946Z","caller":"etcdserver/server.go:2054","msg":"published local member to cluster through raft","local-member-id":"f074a195de705325","local-member-attributes":"{Name:minikube ClientURLs:[https://10.0.2.15:2379]}","request-path":"/0/members/f074a195de705325/attributes","cluster-id":"ef296cf39f5d9d66","publish-timeout":"7s"}
{"level":"info","ts":"2023-10-17T11:43:13.954Z","caller":"embed/serve.go:100","msg":"ready to serve client requests"}
{"level":"info","ts":"2023-10-17T11:43:13.955Z","caller":"membership/cluster.go:584","msg":"set initial cluster version","cluster-id":"ef296cf39f5d9d66","local-member-id":"f074a195de705325","cluster-version":"3.5"}
{"level":"info","ts":"2023-10-17T11:43:13.958Z","caller":"api/capability.go:75","msg":"enabled capabilities for version","cluster-version":"3.5"}
{"level":"info","ts":"2023-10-17T11:43:13.958Z","caller":"etcdserver/server.go:2587","msg":"cluster version is updated","cluster-version":"3.5"}
{"level":"info","ts":"2023-10-17T11:43:13.959Z","caller":"embed/serve.go:198","msg":"serving client traffic securely","address":"10.0.2.15:2379"}
{"level":"info","ts":"2023-10-17T11:43:14.006Z","caller":"etcdmain/main.go:44","msg":"notifying init daemon"}
{"level":"info","ts":"2023-10-17T11:43:14.006Z","caller":"etcdmain/main.go:50","msg":"successfully notified init daemon"}
{"level":"info","ts":"2023-10-17T11:43:19.173Z","caller":"traceutil/trace.go:171","msg":"trace[815102863] transaction","detail":"{read_only:false; response_revision:264; number_of_response:1; }","duration":"100.681237ms","start":"2023-10-17T11:43:19.072Z","end":"2023-10-17T11:43:19.173Z","steps":["trace[815102863] 'process raft request'  (duration: 30.388886ms)","trace[815102863] 'compare'  (duration: 70.102923ms)"],"step_count":2}
{"level":"info","ts":"2023-10-17T11:53:14.301Z","caller":"mvcc/index.go:214","msg":"compact tree index","revision":632}
{"level":"info","ts":"2023-10-17T11:53:14.303Z","caller":"mvcc/kvstore_compaction.go:66","msg":"finished scheduled compaction","compact-revision":632,"took":"832.008µs","hash":2544973432}
{"level":"info","ts":"2023-10-17T11:53:14.303Z","caller":"mvcc/hash.go:137","msg":"storing new hash","hash":2544973432,"revision":632,"compact-revision":-1}

* 
* ==> kernel <==
*  11:53:17 up 14 min,  0 users,  load average: 0.48, 0.45, 0.28
Linux minikube 5.10.57 #1 SMP PREEMPT Fri Jan 27 16:27:33 UTC 2023 aarch64 GNU/Linux
PRETTY_NAME="Buildroot 2021.02.12"

* 
* ==> kube-apiserver [d8959036328f] <==
* W1017 11:43:15.171784       1 genericapiserver.go:660] Skipping API apiregistration.k8s.io/v1beta1 because it has no resources.
I1017 11:43:15.805886       1 secure_serving.go:210] Serving securely on [::]:8443
I1017 11:43:15.805940       1 dynamic_serving_content.go:132] "Starting controller" name="serving-cert::/var/lib/minikube/certs/apiserver.crt::/var/lib/minikube/certs/apiserver.key"
I1017 11:43:15.806021       1 tlsconfig.go:240] "Starting DynamicServingCertificateController"
I1017 11:43:15.806153       1 dynamic_cafile_content.go:157] "Starting controller" name="request-header::/var/lib/minikube/certs/front-proxy-ca.crt"
I1017 11:43:15.806267       1 dynamic_cafile_content.go:157] "Starting controller" name="client-ca-bundle::/var/lib/minikube/certs/ca.crt"
I1017 11:43:15.806590       1 gc_controller.go:78] Starting apiserver lease garbage collector
I1017 11:43:15.806651       1 apf_controller.go:361] Starting API Priority and Fairness config controller
I1017 11:43:15.807145       1 controller.go:80] Starting OpenAPI V3 AggregationController
I1017 11:43:15.807370       1 cluster_authentication_trust_controller.go:440] Starting cluster_authentication_trust_controller controller
I1017 11:43:15.807401       1 shared_informer.go:273] Waiting for caches to sync for cluster_authentication_trust_controller
I1017 11:43:15.807529       1 controller.go:121] Starting legacy_token_tracking_controller
I1017 11:43:15.807557       1 shared_informer.go:273] Waiting for caches to sync for configmaps
I1017 11:43:15.807603       1 dynamic_serving_content.go:132] "Starting controller" name="aggregator-proxy-cert::/var/lib/minikube/certs/front-proxy-client.crt::/var/lib/minikube/certs/front-proxy-client.key"
I1017 11:43:15.807938       1 customresource_discovery_controller.go:288] Starting DiscoveryController
I1017 11:43:15.808169       1 apiservice_controller.go:97] Starting APIServiceRegistrationController
I1017 11:43:15.808205       1 cache.go:32] Waiting for caches to sync for APIServiceRegistrationController controller
I1017 11:43:15.808239       1 available_controller.go:494] Starting AvailableConditionController
I1017 11:43:15.808288       1 cache.go:32] Waiting for caches to sync for AvailableConditionController controller
I1017 11:43:15.808323       1 controller.go:83] Starting OpenAPI AggregationController
I1017 11:43:15.816655       1 dynamic_cafile_content.go:157] "Starting controller" name="client-ca-bundle::/var/lib/minikube/certs/ca.crt"
I1017 11:43:15.816724       1 dynamic_cafile_content.go:157] "Starting controller" name="request-header::/var/lib/minikube/certs/front-proxy-ca.crt"
I1017 11:43:15.819804       1 controller.go:85] Starting OpenAPI controller
I1017 11:43:15.819831       1 controller.go:85] Starting OpenAPI V3 controller
I1017 11:43:15.819848       1 naming_controller.go:291] Starting NamingConditionController
I1017 11:43:15.819862       1 establishing_controller.go:76] Starting EstablishingController
I1017 11:43:15.819875       1 nonstructuralschema_controller.go:192] Starting NonStructuralSchemaConditionController
I1017 11:43:15.819883       1 apiapproval_controller.go:186] Starting KubernetesAPIApprovalPolicyConformantConditionController
I1017 11:43:15.819890       1 crd_finalizer.go:266] Starting CRDFinalizer
I1017 11:43:15.808630       1 autoregister_controller.go:141] Starting autoregister controller
I1017 11:43:15.819904       1 cache.go:32] Waiting for caches to sync for autoregister controller
I1017 11:43:15.821436       1 crdregistration_controller.go:111] Starting crd-autoregister controller
I1017 11:43:15.821443       1 shared_informer.go:273] Waiting for caches to sync for crd-autoregister
I1017 11:43:15.906820       1 apf_controller.go:366] Running API Priority and Fairness config worker
I1017 11:43:15.906837       1 apf_controller.go:369] Running API Priority and Fairness periodic rebalancing process
I1017 11:43:15.908850       1 cache.go:39] Caches are synced for AvailableConditionController controller
I1017 11:43:15.913406       1 controller.go:615] quota admission added evaluator for: namespaces
I1017 11:43:15.915315       1 shared_informer.go:280] Caches are synced for cluster_authentication_trust_controller
I1017 11:43:15.915344       1 shared_informer.go:280] Caches are synced for configmaps
I1017 11:43:15.915431       1 cache.go:39] Caches are synced for APIServiceRegistrationController controller
I1017 11:43:15.920390       1 cache.go:39] Caches are synced for autoregister controller
I1017 11:43:15.921599       1 shared_informer.go:280] Caches are synced for crd-autoregister
I1017 11:43:15.964643       1 controller.go:615] quota admission added evaluator for: leases.coordination.k8s.io
I1017 11:43:15.984593       1 shared_informer.go:280] Caches are synced for node_authorizer
I1017 11:43:16.594511       1 controller.go:132] OpenAPI AggregationController: action for item k8s_internal_local_delegation_chain_0000000000: Nothing (removed from the queue).
I1017 11:43:16.811579       1 storage_scheduling.go:95] created PriorityClass system-node-critical with value 2000001000
I1017 11:43:16.815040       1 storage_scheduling.go:95] created PriorityClass system-cluster-critical with value 2000000000
I1017 11:43:16.815053       1 storage_scheduling.go:111] all system priority classes are created successfully or already exist.
I1017 11:43:17.050515       1 controller.go:615] quota admission added evaluator for: roles.rbac.authorization.k8s.io
I1017 11:43:17.082254       1 controller.go:615] quota admission added evaluator for: rolebindings.rbac.authorization.k8s.io
I1017 11:43:17.116288       1 alloc.go:327] "allocated clusterIPs" service="default/kubernetes" clusterIPs=map[IPv4:10.96.0.1]
W1017 11:43:17.121085       1 lease.go:251] Resetting endpoints for master service "kubernetes" to [10.0.2.15]
I1017 11:43:17.121757       1 controller.go:615] quota admission added evaluator for: endpoints
I1017 11:43:17.124692       1 controller.go:615] quota admission added evaluator for: endpointslices.discovery.k8s.io
I1017 11:43:17.881058       1 controller.go:615] quota admission added evaluator for: serviceaccounts
I1017 11:43:18.926544       1 controller.go:615] quota admission added evaluator for: deployments.apps
I1017 11:43:18.934717       1 alloc.go:327] "allocated clusterIPs" service="kube-system/kube-dns" clusterIPs=map[IPv4:10.96.0.10]
I1017 11:43:18.940697       1 controller.go:615] quota admission added evaluator for: daemonsets.apps
I1017 11:43:31.040518       1 controller.go:615] quota admission added evaluator for: replicasets.apps
I1017 11:43:31.633592       1 controller.go:615] quota admission added evaluator for: controllerrevisions.apps

* 
* ==> kube-controller-manager [001ef48cc07d] <==
* I1017 11:43:31.008706       1 controllermanager.go:622] Started "endpointslice"
I1017 11:43:31.008870       1 endpointslice_controller.go:257] Starting endpoint slice controller
I1017 11:43:31.008906       1 shared_informer.go:273] Waiting for caches to sync for endpoint_slice
I1017 11:43:31.012647       1 shared_informer.go:273] Waiting for caches to sync for resource quota
I1017 11:43:31.024766       1 shared_informer.go:273] Waiting for caches to sync for garbage collector
I1017 11:43:31.027699       1 shared_informer.go:280] Caches are synced for HPA
I1017 11:43:31.029147       1 shared_informer.go:280] Caches are synced for ClusterRoleAggregator
I1017 11:43:31.029186       1 shared_informer.go:280] Caches are synced for deployment
I1017 11:43:31.035555       1 shared_informer.go:280] Caches are synced for namespace
I1017 11:43:31.044626       1 shared_informer.go:280] Caches are synced for ReplicationController
I1017 11:43:31.050456       1 event.go:294] "Event occurred" object="kube-system/coredns" fieldPath="" kind="Deployment" apiVersion="apps/v1" type="Normal" reason="ScalingReplicaSet" message="Scaled up replica set coredns-787d4945fb to 2"
W1017 11:43:31.063348       1 actual_state_of_world.go:541] Failed to update statusUpdateNeeded field in actual state of world: Failed to set statusUpdateNeeded to needed true, because nodeName="minikube" does not exist
I1017 11:43:31.079769       1 shared_informer.go:280] Caches are synced for certificate-csrsigning-kube-apiserver-client
I1017 11:43:31.079769       1 shared_informer.go:280] Caches are synced for service account
I1017 11:43:31.079779       1 shared_informer.go:280] Caches are synced for crt configmap
I1017 11:43:31.079786       1 shared_informer.go:280] Caches are synced for ephemeral
I1017 11:43:31.079794       1 shared_informer.go:280] Caches are synced for certificate-csrsigning-kubelet-serving
I1017 11:43:31.079813       1 shared_informer.go:280] Caches are synced for certificate-csrsigning-legacy-unknown
I1017 11:43:31.079818       1 shared_informer.go:280] Caches are synced for certificate-csrsigning-kubelet-client
I1017 11:43:31.081355       1 shared_informer.go:280] Caches are synced for taint
I1017 11:43:31.081914       1 taint_manager.go:206] "Starting NoExecuteTaintManager"
I1017 11:43:31.082064       1 taint_manager.go:211] "Sending events to api server"
I1017 11:43:31.081957       1 node_lifecycle_controller.go:1438] Initializing eviction metric for zone: 
W1017 11:43:31.082293       1 node_lifecycle_controller.go:1053] Missing timestamp for Node minikube. Assuming now as a timestamp.
I1017 11:43:31.082433       1 node_lifecycle_controller.go:1254] Controller detected that zone  is now in state Normal.
I1017 11:43:31.082529       1 shared_informer.go:280] Caches are synced for bootstrap_signer
I1017 11:43:31.082592       1 event.go:294] "Event occurred" object="minikube" fieldPath="" kind="Node" apiVersion="v1" type="Normal" reason="RegisteredNode" message="Node minikube event: Registered Node minikube in Controller"
I1017 11:43:31.082599       1 shared_informer.go:280] Caches are synced for ReplicaSet
I1017 11:43:31.082637       1 shared_informer.go:280] Caches are synced for PVC protection
I1017 11:43:31.086067       1 shared_informer.go:280] Caches are synced for node
I1017 11:43:31.086184       1 range_allocator.go:167] Sending events to api server.
I1017 11:43:31.086227       1 range_allocator.go:171] Starting range CIDR allocator
I1017 11:43:31.086250       1 shared_informer.go:273] Waiting for caches to sync for cidrallocator
I1017 11:43:31.086274       1 shared_informer.go:280] Caches are synced for cidrallocator
I1017 11:43:31.086534       1 shared_informer.go:280] Caches are synced for certificate-csrapproving
I1017 11:43:31.089668       1 shared_informer.go:280] Caches are synced for attach detach
I1017 11:43:31.090241       1 shared_informer.go:280] Caches are synced for PV protection
I1017 11:43:31.092559       1 shared_informer.go:280] Caches are synced for GC
I1017 11:43:31.094133       1 shared_informer.go:280] Caches are synced for TTL after finished
I1017 11:43:31.096618       1 range_allocator.go:372] Set node minikube PodCIDR to [10.244.0.0/24]
I1017 11:43:31.097644       1 shared_informer.go:280] Caches are synced for job
I1017 11:43:31.099755       1 shared_informer.go:280] Caches are synced for cronjob
I1017 11:43:31.102738       1 shared_informer.go:280] Caches are synced for disruption
I1017 11:43:31.104325       1 shared_informer.go:280] Caches are synced for stateful set
I1017 11:43:31.106524       1 shared_informer.go:280] Caches are synced for expand
I1017 11:43:31.129463       1 shared_informer.go:280] Caches are synced for daemon sets
I1017 11:43:31.129544       1 shared_informer.go:280] Caches are synced for TTL
I1017 11:43:31.180261       1 shared_informer.go:280] Caches are synced for persistent volume
I1017 11:43:31.213385       1 shared_informer.go:280] Caches are synced for resource quota
I1017 11:43:31.231467       1 shared_informer.go:280] Caches are synced for endpoint
I1017 11:43:31.236694       1 shared_informer.go:280] Caches are synced for resource quota
I1017 11:43:31.237909       1 event.go:294] "Event occurred" object="kube-system/coredns-787d4945fb" fieldPath="" kind="ReplicaSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: coredns-787d4945fb-8bltg"
I1017 11:43:31.241791       1 event.go:294] "Event occurred" object="kube-system/coredns-787d4945fb" fieldPath="" kind="ReplicaSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: coredns-787d4945fb-svfmw"
I1017 11:43:31.296400       1 shared_informer.go:280] Caches are synced for endpoint_slice_mirroring
I1017 11:43:31.309019       1 shared_informer.go:280] Caches are synced for endpoint_slice
I1017 11:43:31.626583       1 shared_informer.go:280] Caches are synced for garbage collector
I1017 11:43:31.640069       1 event.go:294] "Event occurred" object="kube-system/kube-proxy" fieldPath="" kind="DaemonSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: kube-proxy-dm7mp"
I1017 11:43:31.704992       1 event.go:294] "Event occurred" object="kube-dns" fieldPath="" kind="Endpoints" apiVersion="v1" type="Warning" reason="FailedToCreateEndpoint" message="Failed to create endpoint for service kube-system/kube-dns: endpoints \"kube-dns\" already exists"
I1017 11:43:31.709556       1 shared_informer.go:280] Caches are synced for garbage collector
I1017 11:43:31.709571       1 garbagecollector.go:163] Garbage collector: all resource monitors have synced. Proceeding to collect garbage

* 
* ==> kube-proxy [468210b9872f] <==
* I1017 11:43:32.530978       1 node.go:163] Successfully retrieved node IP: 10.0.2.15
I1017 11:43:32.531035       1 server_others.go:109] "Detected node IP" address="10.0.2.15"
I1017 11:43:32.531061       1 server_others.go:535] "Using iptables proxy"
I1017 11:43:32.544925       1 server_others.go:170] "kube-proxy running in single-stack mode, this ipFamily is not supported" ipFamily=IPv6
I1017 11:43:32.544945       1 server_others.go:176] "Using iptables Proxier"
I1017 11:43:32.544987       1 proxier.go:242] "Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"
I1017 11:43:32.545392       1 server.go:655] "Version info" version="v1.26.1"
I1017 11:43:32.545460       1 server.go:657] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
I1017 11:43:32.546052       1 config.go:317] "Starting service config controller"
I1017 11:43:32.546144       1 shared_informer.go:273] Waiting for caches to sync for service config
I1017 11:43:32.546165       1 config.go:226] "Starting endpoint slice config controller"
I1017 11:43:32.546231       1 shared_informer.go:273] Waiting for caches to sync for endpoint slice config
I1017 11:43:32.547682       1 config.go:444] "Starting node config controller"
I1017 11:43:32.547751       1 shared_informer.go:273] Waiting for caches to sync for node config
I1017 11:43:32.646646       1 shared_informer.go:280] Caches are synced for endpoint slice config
I1017 11:43:32.646661       1 shared_informer.go:280] Caches are synced for service config
I1017 11:43:32.648155       1 shared_informer.go:280] Caches are synced for node config

* 
* ==> kube-scheduler [31cc51d3bc7c] <==
* I1017 11:43:13.768357       1 serving.go:348] Generated self-signed cert in-memory
W1017 11:43:15.839525       1 requestheader_controller.go:193] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W1017 11:43:15.839550       1 authentication.go:349] Error looking up in-cluster authentication configuration: configmaps "extension-apiserver-authentication" is forbidden: User "system:kube-scheduler" cannot get resource "configmaps" in API group "" in the namespace "kube-system"
W1017 11:43:15.839557       1 authentication.go:350] Continuing without authentication configuration. This may treat all requests as anonymous.
W1017 11:43:15.839562       1 authentication.go:351] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I1017 11:43:15.918722       1 server.go:152] "Starting Kubernetes Scheduler" version="v1.26.1"
I1017 11:43:15.918744       1 server.go:154] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
I1017 11:43:15.919745       1 configmap_cafile_content.go:202] "Starting controller" name="client-ca::kube-system::extension-apiserver-authentication::client-ca-file"
I1017 11:43:15.919785       1 shared_informer.go:273] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
W1017 11:43:15.921921       1 reflector.go:424] pkg/server/dynamiccertificates/configmap_cafile_content.go:206: failed to list *v1.ConfigMap: configmaps "extension-apiserver-authentication" is forbidden: User "system:kube-scheduler" cannot list resource "configmaps" in API group "" in the namespace "kube-system"
E1017 11:43:15.922217       1 reflector.go:140] pkg/server/dynamiccertificates/configmap_cafile_content.go:206: Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: configmaps "extension-apiserver-authentication" is forbidden: User "system:kube-scheduler" cannot list resource "configmaps" in API group "" in the namespace "kube-system"
I1017 11:43:15.926210       1 secure_serving.go:210] Serving securely on 127.0.0.1:10259
I1017 11:43:15.926667       1 tlsconfig.go:240] "Starting DynamicServingCertificateController"
W1017 11:43:15.933593       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.Pod: pods is forbidden: User "system:kube-scheduler" cannot list resource "pods" in API group "" at the cluster scope
E1017 11:43:15.933638       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Pod: failed to list *v1.Pod: pods is forbidden: User "system:kube-scheduler" cannot list resource "pods" in API group "" at the cluster scope
W1017 11:43:15.933566       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.Node: nodes is forbidden: User "system:kube-scheduler" cannot list resource "nodes" in API group "" at the cluster scope
E1017 11:43:15.933667       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Node: failed to list *v1.Node: nodes is forbidden: User "system:kube-scheduler" cannot list resource "nodes" in API group "" at the cluster scope
W1017 11:43:15.933799       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.CSIStorageCapacity: csistoragecapacities.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csistoragecapacities" in API group "storage.k8s.io" at the cluster scope
E1017 11:43:15.933826       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.CSIStorageCapacity: failed to list *v1.CSIStorageCapacity: csistoragecapacities.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csistoragecapacities" in API group "storage.k8s.io" at the cluster scope
W1017 11:43:15.933851       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.CSIDriver: csidrivers.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csidrivers" in API group "storage.k8s.io" at the cluster scope
E1017 11:43:15.933866       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.CSIDriver: failed to list *v1.CSIDriver: csidrivers.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csidrivers" in API group "storage.k8s.io" at the cluster scope
W1017 11:43:15.933912       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.StatefulSet: statefulsets.apps is forbidden: User "system:kube-scheduler" cannot list resource "statefulsets" in API group "apps" at the cluster scope
E1017 11:43:15.933923       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.StatefulSet: failed to list *v1.StatefulSet: statefulsets.apps is forbidden: User "system:kube-scheduler" cannot list resource "statefulsets" in API group "apps" at the cluster scope
W1017 11:43:15.933950       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.Namespace: namespaces is forbidden: User "system:kube-scheduler" cannot list resource "namespaces" in API group "" at the cluster scope
E1017 11:43:15.933957       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Namespace: failed to list *v1.Namespace: namespaces is forbidden: User "system:kube-scheduler" cannot list resource "namespaces" in API group "" at the cluster scope
W1017 11:43:15.934004       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.ReplicaSet: replicasets.apps is forbidden: User "system:kube-scheduler" cannot list resource "replicasets" in API group "apps" at the cluster scope
E1017 11:43:15.934012       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.ReplicaSet: failed to list *v1.ReplicaSet: replicasets.apps is forbidden: User "system:kube-scheduler" cannot list resource "replicasets" in API group "apps" at the cluster scope
W1017 11:43:15.934049       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.CSINode: csinodes.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csinodes" in API group "storage.k8s.io" at the cluster scope
E1017 11:43:15.934056       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.CSINode: failed to list *v1.CSINode: csinodes.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csinodes" in API group "storage.k8s.io" at the cluster scope
W1017 11:43:15.934082       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.PersistentVolumeClaim: persistentvolumeclaims is forbidden: User "system:kube-scheduler" cannot list resource "persistentvolumeclaims" in API group "" at the cluster scope
E1017 11:43:15.934088       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.PersistentVolumeClaim: failed to list *v1.PersistentVolumeClaim: persistentvolumeclaims is forbidden: User "system:kube-scheduler" cannot list resource "persistentvolumeclaims" in API group "" at the cluster scope
W1017 11:43:15.934113       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.PersistentVolume: persistentvolumes is forbidden: User "system:kube-scheduler" cannot list resource "persistentvolumes" in API group "" at the cluster scope
E1017 11:43:15.934140       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.PersistentVolume: failed to list *v1.PersistentVolume: persistentvolumes is forbidden: User "system:kube-scheduler" cannot list resource "persistentvolumes" in API group "" at the cluster scope
W1017 11:43:15.934209       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.Service: services is forbidden: User "system:kube-scheduler" cannot list resource "services" in API group "" at the cluster scope
E1017 11:43:15.934225       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Service: failed to list *v1.Service: services is forbidden: User "system:kube-scheduler" cannot list resource "services" in API group "" at the cluster scope
W1017 11:43:15.934282       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.StorageClass: storageclasses.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "storageclasses" in API group "storage.k8s.io" at the cluster scope
E1017 11:43:15.934295       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.StorageClass: failed to list *v1.StorageClass: storageclasses.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "storageclasses" in API group "storage.k8s.io" at the cluster scope
W1017 11:43:15.934320       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.ReplicationController: replicationcontrollers is forbidden: User "system:kube-scheduler" cannot list resource "replicationcontrollers" in API group "" at the cluster scope
E1017 11:43:15.934369       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.ReplicationController: failed to list *v1.ReplicationController: replicationcontrollers is forbidden: User "system:kube-scheduler" cannot list resource "replicationcontrollers" in API group "" at the cluster scope
W1017 11:43:15.934462       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.PodDisruptionBudget: poddisruptionbudgets.policy is forbidden: User "system:kube-scheduler" cannot list resource "poddisruptionbudgets" in API group "policy" at the cluster scope
E1017 11:43:15.934480       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.PodDisruptionBudget: failed to list *v1.PodDisruptionBudget: poddisruptionbudgets.policy is forbidden: User "system:kube-scheduler" cannot list resource "poddisruptionbudgets" in API group "policy" at the cluster scope
W1017 11:43:16.773545       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.PodDisruptionBudget: poddisruptionbudgets.policy is forbidden: User "system:kube-scheduler" cannot list resource "poddisruptionbudgets" in API group "policy" at the cluster scope
E1017 11:43:16.773571       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.PodDisruptionBudget: failed to list *v1.PodDisruptionBudget: poddisruptionbudgets.policy is forbidden: User "system:kube-scheduler" cannot list resource "poddisruptionbudgets" in API group "policy" at the cluster scope
W1017 11:43:16.774963       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.StorageClass: storageclasses.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "storageclasses" in API group "storage.k8s.io" at the cluster scope
E1017 11:43:16.774974       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.StorageClass: failed to list *v1.StorageClass: storageclasses.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "storageclasses" in API group "storage.k8s.io" at the cluster scope
W1017 11:43:16.777562       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.ReplicationController: replicationcontrollers is forbidden: User "system:kube-scheduler" cannot list resource "replicationcontrollers" in API group "" at the cluster scope
E1017 11:43:16.777597       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.ReplicationController: failed to list *v1.ReplicationController: replicationcontrollers is forbidden: User "system:kube-scheduler" cannot list resource "replicationcontrollers" in API group "" at the cluster scope
W1017 11:43:16.796587       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.CSINode: csinodes.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csinodes" in API group "storage.k8s.io" at the cluster scope
E1017 11:43:16.796602       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.CSINode: failed to list *v1.CSINode: csinodes.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csinodes" in API group "storage.k8s.io" at the cluster scope
W1017 11:43:16.805411       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.StatefulSet: statefulsets.apps is forbidden: User "system:kube-scheduler" cannot list resource "statefulsets" in API group "apps" at the cluster scope
E1017 11:43:16.805429       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.StatefulSet: failed to list *v1.StatefulSet: statefulsets.apps is forbidden: User "system:kube-scheduler" cannot list resource "statefulsets" in API group "apps" at the cluster scope
W1017 11:43:16.944183       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.ReplicaSet: replicasets.apps is forbidden: User "system:kube-scheduler" cannot list resource "replicasets" in API group "apps" at the cluster scope
E1017 11:43:16.944317       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.ReplicaSet: failed to list *v1.ReplicaSet: replicasets.apps is forbidden: User "system:kube-scheduler" cannot list resource "replicasets" in API group "apps" at the cluster scope
I1017 11:43:17.320053       1 shared_informer.go:280] Caches are synced for client-ca::kube-system::extension-apiserver-authentication::client-ca-file

* 
* ==> kubelet <==
* -- Journal begins at Tue 2023-10-17 11:38:40 UTC, ends at Tue 2023-10-17 11:53:18 UTC. --
Oct 17 11:43:19 minikube kubelet[11258]: I1017 11:43:19.775703   11258 kubelet_node_status.go:108] "Node was previously registered" node="minikube"
Oct 17 11:43:19 minikube kubelet[11258]: I1017 11:43:19.775801   11258 kubelet_node_status.go:73] "Successfully registered node" node="minikube"
Oct 17 11:43:19 minikube kubelet[11258]: I1017 11:43:19.977596   11258 apiserver.go:52] "Watching apiserver"
Oct 17 11:43:20 minikube kubelet[11258]: I1017 11:43:20.397033   11258 desired_state_of_world_populator.go:159] "Finished populating initial desired state of world"
Oct 17 11:43:20 minikube kubelet[11258]: I1017 11:43:20.413021   11258 reconciler.go:41] "Reconciler: start to sync state"
Oct 17 11:43:20 minikube kubelet[11258]: E1017 11:43:20.578190   11258 kubelet.go:1802] "Failed creating a mirror pod for" err="pods \"kube-scheduler-minikube\" already exists" pod="kube-system/kube-scheduler-minikube"
Oct 17 11:43:20 minikube kubelet[11258]: E1017 11:43:20.778175   11258 kubelet.go:1802] "Failed creating a mirror pod for" err="pods \"kube-controller-manager-minikube\" already exists" pod="kube-system/kube-controller-manager-minikube"
Oct 17 11:43:20 minikube kubelet[11258]: E1017 11:43:20.978050   11258 kubelet.go:1802] "Failed creating a mirror pod for" err="pods \"etcd-minikube\" already exists" pod="kube-system/etcd-minikube"
Oct 17 11:43:21 minikube kubelet[11258]: I1017 11:43:21.175456   11258 request.go:690] Waited for 1.001429885s due to client-side throttling, not priority and fairness, request: POST:https://control-plane.minikube.internal:8443/api/v1/namespaces/kube-system/pods
Oct 17 11:43:21 minikube kubelet[11258]: E1017 11:43:21.180653   11258 kubelet.go:1802] "Failed creating a mirror pod for" err="pods \"kube-apiserver-minikube\" already exists" pod="kube-system/kube-apiserver-minikube"
Oct 17 11:43:21 minikube kubelet[11258]: I1017 11:43:21.186488   11258 kubelet_node_status.go:493] "Fast updating node status as it just became ready"
Oct 17 11:43:21 minikube kubelet[11258]: I1017 11:43:21.979394   11258 pod_startup_latency_tracker.go:102] "Observed pod startup duration" pod="kube-system/kube-apiserver-minikube" podStartSLOduration=2.979335271 pod.CreationTimestamp="2023-10-17 11:43:19 +0000 UTC" firstStartedPulling="0001-01-01 00:00:00 +0000 UTC" lastFinishedPulling="0001-01-01 00:00:00 +0000 UTC" observedRunningTime="2023-10-17 11:43:21.581484668 +0000 UTC m=+2.679524606" watchObservedRunningTime="2023-10-17 11:43:21.979335271 +0000 UTC m=+3.077375209"
Oct 17 11:43:22 minikube kubelet[11258]: I1017 11:43:22.777883   11258 pod_startup_latency_tracker.go:102] "Observed pod startup duration" pod="kube-system/kube-scheduler-minikube" podStartSLOduration=5.777855552 pod.CreationTimestamp="2023-10-17 11:43:17 +0000 UTC" firstStartedPulling="0001-01-01 00:00:00 +0000 UTC" lastFinishedPulling="0001-01-01 00:00:00 +0000 UTC" observedRunningTime="2023-10-17 11:43:22.385957594 +0000 UTC m=+3.483997532" watchObservedRunningTime="2023-10-17 11:43:22.777855552 +0000 UTC m=+3.875895490"
Oct 17 11:43:23 minikube kubelet[11258]: I1017 11:43:23.186634   11258 pod_startup_latency_tracker.go:102] "Observed pod startup duration" pod="kube-system/kube-controller-manager-minikube" podStartSLOduration=4.186594659 pod.CreationTimestamp="2023-10-17 11:43:19 +0000 UTC" firstStartedPulling="0001-01-01 00:00:00 +0000 UTC" lastFinishedPulling="0001-01-01 00:00:00 +0000 UTC" observedRunningTime="2023-10-17 11:43:22.778126609 +0000 UTC m=+3.876166546" watchObservedRunningTime="2023-10-17 11:43:23.186594659 +0000 UTC m=+4.284634555"
Oct 17 11:43:23 minikube kubelet[11258]: I1017 11:43:23.583092   11258 pod_startup_latency_tracker.go:102] "Observed pod startup duration" pod="kube-system/etcd-minikube" podStartSLOduration=4.583068595 pod.CreationTimestamp="2023-10-17 11:43:19 +0000 UTC" firstStartedPulling="0001-01-01 00:00:00 +0000 UTC" lastFinishedPulling="0001-01-01 00:00:00 +0000 UTC" observedRunningTime="2023-10-17 11:43:23.186889133 +0000 UTC m=+4.284929071" watchObservedRunningTime="2023-10-17 11:43:23.583068595 +0000 UTC m=+4.681108532"
Oct 17 11:43:31 minikube kubelet[11258]: I1017 11:43:31.101086   11258 topology_manager.go:210] "Topology Admit Handler"
Oct 17 11:43:31 minikube kubelet[11258]: E1017 11:43:31.101362   11258 cpu_manager.go:395] "RemoveStaleState: removing container" podUID="3a79c397-283e-47f3-a783-4f9b4d3f170e" containerName="nging"
Oct 17 11:43:31 minikube kubelet[11258]: E1017 11:43:31.101403   11258 cpu_manager.go:395] "RemoveStaleState: removing container" podUID="c86f0118-7464-46d3-875c-f29720ade964" containerName="coredns"
Oct 17 11:43:31 minikube kubelet[11258]: E1017 11:43:31.101423   11258 cpu_manager.go:395] "RemoveStaleState: removing container" podUID="bd1f33f1-f9df-4649-a1db-2f4ab4f928bd" containerName="postgres"
Oct 17 11:43:31 minikube kubelet[11258]: E1017 11:43:31.101442   11258 cpu_manager.go:395] "RemoveStaleState: removing container" podUID="ecb238a7-7cbc-4beb-a76f-95fcd5765791" containerName="nginx"
Oct 17 11:43:31 minikube kubelet[11258]: E1017 11:43:31.101462   11258 cpu_manager.go:395] "RemoveStaleState: removing container" podUID="4ad9e476-eb6c-43e6-98a5-3baee38e2737" containerName="nginx"
Oct 17 11:43:31 minikube kubelet[11258]: E1017 11:43:31.101480   11258 cpu_manager.go:395] "RemoveStaleState: removing container" podUID="95b553dd-7086-4843-8736-65765565349e" containerName="nginx"
Oct 17 11:43:31 minikube kubelet[11258]: E1017 11:43:31.101490   11258 cpu_manager.go:395] "RemoveStaleState: removing container" podUID="542167ff-b943-4d92-a3a1-16d60672fc72" containerName="nginx"
Oct 17 11:43:31 minikube kubelet[11258]: E1017 11:43:31.101493   11258 cpu_manager.go:395] "RemoveStaleState: removing container" podUID="7c6b106c-c280-4cbc-922c-466175aa3c5e" containerName="nginx"
Oct 17 11:43:31 minikube kubelet[11258]: I1017 11:43:31.101506   11258 memory_manager.go:346] "RemoveStaleState removing state" podUID="3a79c397-283e-47f3-a783-4f9b4d3f170e" containerName="nging"
Oct 17 11:43:31 minikube kubelet[11258]: I1017 11:43:31.101509   11258 memory_manager.go:346] "RemoveStaleState removing state" podUID="4ad9e476-eb6c-43e6-98a5-3baee38e2737" containerName="nginx"
Oct 17 11:43:31 minikube kubelet[11258]: I1017 11:43:31.101513   11258 memory_manager.go:346] "RemoveStaleState removing state" podUID="542167ff-b943-4d92-a3a1-16d60672fc72" containerName="nginx"
Oct 17 11:43:31 minikube kubelet[11258]: I1017 11:43:31.101516   11258 memory_manager.go:346] "RemoveStaleState removing state" podUID="c86f0118-7464-46d3-875c-f29720ade964" containerName="coredns"
Oct 17 11:43:31 minikube kubelet[11258]: I1017 11:43:31.101519   11258 memory_manager.go:346] "RemoveStaleState removing state" podUID="bd1f33f1-f9df-4649-a1db-2f4ab4f928bd" containerName="postgres"
Oct 17 11:43:31 minikube kubelet[11258]: I1017 11:43:31.101522   11258 memory_manager.go:346] "RemoveStaleState removing state" podUID="ecb238a7-7cbc-4beb-a76f-95fcd5765791" containerName="nginx"
Oct 17 11:43:31 minikube kubelet[11258]: I1017 11:43:31.101525   11258 memory_manager.go:346] "RemoveStaleState removing state" podUID="95b553dd-7086-4843-8736-65765565349e" containerName="nginx"
Oct 17 11:43:31 minikube kubelet[11258]: I1017 11:43:31.101528   11258 memory_manager.go:346] "RemoveStaleState removing state" podUID="7c6b106c-c280-4cbc-922c-466175aa3c5e" containerName="nginx"
Oct 17 11:43:31 minikube kubelet[11258]: I1017 11:43:31.191731   11258 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"tmp\" (UniqueName: \"kubernetes.io/host-path/1593085a-ea40-447c-bd12-1b9e37373be0-tmp\") pod \"storage-provisioner\" (UID: \"1593085a-ea40-447c-bd12-1b9e37373be0\") " pod="kube-system/storage-provisioner"
Oct 17 11:43:31 minikube kubelet[11258]: I1017 11:43:31.191790   11258 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-h2mdw\" (UniqueName: \"kubernetes.io/projected/1593085a-ea40-447c-bd12-1b9e37373be0-kube-api-access-h2mdw\") pod \"storage-provisioner\" (UID: \"1593085a-ea40-447c-bd12-1b9e37373be0\") " pod="kube-system/storage-provisioner"
Oct 17 11:43:31 minikube kubelet[11258]: I1017 11:43:31.241871   11258 topology_manager.go:210] "Topology Admit Handler"
Oct 17 11:43:31 minikube kubelet[11258]: I1017 11:43:31.252130   11258 topology_manager.go:210] "Topology Admit Handler"
Oct 17 11:43:31 minikube kubelet[11258]: I1017 11:43:31.292671   11258 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-m2g76\" (UniqueName: \"kubernetes.io/projected/8f7133b8-fc25-4e86-8d2a-b8786540640f-kube-api-access-m2g76\") pod \"coredns-787d4945fb-svfmw\" (UID: \"8f7133b8-fc25-4e86-8d2a-b8786540640f\") " pod="kube-system/coredns-787d4945fb-svfmw"
Oct 17 11:43:31 minikube kubelet[11258]: I1017 11:43:31.292725   11258 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"config-volume\" (UniqueName: \"kubernetes.io/configmap/702ae144-433c-4b34-9651-48d58a7dc33d-config-volume\") pod \"coredns-787d4945fb-8bltg\" (UID: \"702ae144-433c-4b34-9651-48d58a7dc33d\") " pod="kube-system/coredns-787d4945fb-8bltg"
Oct 17 11:43:31 minikube kubelet[11258]: I1017 11:43:31.292742   11258 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-zpzsq\" (UniqueName: \"kubernetes.io/projected/702ae144-433c-4b34-9651-48d58a7dc33d-kube-api-access-zpzsq\") pod \"coredns-787d4945fb-8bltg\" (UID: \"702ae144-433c-4b34-9651-48d58a7dc33d\") " pod="kube-system/coredns-787d4945fb-8bltg"
Oct 17 11:43:31 minikube kubelet[11258]: I1017 11:43:31.292756   11258 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"config-volume\" (UniqueName: \"kubernetes.io/configmap/8f7133b8-fc25-4e86-8d2a-b8786540640f-config-volume\") pod \"coredns-787d4945fb-svfmw\" (UID: \"8f7133b8-fc25-4e86-8d2a-b8786540640f\") " pod="kube-system/coredns-787d4945fb-svfmw"
Oct 17 11:43:31 minikube kubelet[11258]: I1017 11:43:31.648121   11258 topology_manager.go:210] "Topology Admit Handler"
Oct 17 11:43:31 minikube kubelet[11258]: I1017 11:43:31.693940   11258 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-proxy\" (UniqueName: \"kubernetes.io/configmap/105c138b-f2bf-4bbf-b666-b4b08f4f256f-kube-proxy\") pod \"kube-proxy-dm7mp\" (UID: \"105c138b-f2bf-4bbf-b666-b4b08f4f256f\") " pod="kube-system/kube-proxy-dm7mp"
Oct 17 11:43:31 minikube kubelet[11258]: I1017 11:43:31.694055   11258 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"xtables-lock\" (UniqueName: \"kubernetes.io/host-path/105c138b-f2bf-4bbf-b666-b4b08f4f256f-xtables-lock\") pod \"kube-proxy-dm7mp\" (UID: \"105c138b-f2bf-4bbf-b666-b4b08f4f256f\") " pod="kube-system/kube-proxy-dm7mp"
Oct 17 11:43:31 minikube kubelet[11258]: I1017 11:43:31.694080   11258 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-pr8dp\" (UniqueName: \"kubernetes.io/projected/105c138b-f2bf-4bbf-b666-b4b08f4f256f-kube-api-access-pr8dp\") pod \"kube-proxy-dm7mp\" (UID: \"105c138b-f2bf-4bbf-b666-b4b08f4f256f\") " pod="kube-system/kube-proxy-dm7mp"
Oct 17 11:43:31 minikube kubelet[11258]: I1017 11:43:31.694111   11258 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"lib-modules\" (UniqueName: \"kubernetes.io/host-path/105c138b-f2bf-4bbf-b666-b4b08f4f256f-lib-modules\") pod \"kube-proxy-dm7mp\" (UID: \"105c138b-f2bf-4bbf-b666-b4b08f4f256f\") " pod="kube-system/kube-proxy-dm7mp"
Oct 17 11:43:32 minikube kubelet[11258]: I1017 11:43:32.510694   11258 pod_startup_latency_tracker.go:102] "Observed pod startup duration" pod="kube-system/coredns-787d4945fb-8bltg" podStartSLOduration=1.510565026 pod.CreationTimestamp="2023-10-17 11:43:31 +0000 UTC" firstStartedPulling="0001-01-01 00:00:00 +0000 UTC" lastFinishedPulling="0001-01-01 00:00:00 +0000 UTC" observedRunningTime="2023-10-17 11:43:32.509804988 +0000 UTC m=+13.607845009" watchObservedRunningTime="2023-10-17 11:43:32.510565026 +0000 UTC m=+13.608604963"
Oct 17 11:43:32 minikube kubelet[11258]: I1017 11:43:32.906532   11258 pod_startup_latency_tracker.go:102] "Observed pod startup duration" pod="kube-system/storage-provisioner" podStartSLOduration=12.906499924 pod.CreationTimestamp="2023-10-17 11:43:20 +0000 UTC" firstStartedPulling="0001-01-01 00:00:00 +0000 UTC" lastFinishedPulling="0001-01-01 00:00:00 +0000 UTC" observedRunningTime="2023-10-17 11:43:32.906366334 +0000 UTC m=+14.004406272" watchObservedRunningTime="2023-10-17 11:43:32.906499924 +0000 UTC m=+14.004539862"
Oct 17 11:43:33 minikube kubelet[11258]: I1017 11:43:33.715280   11258 pod_startup_latency_tracker.go:102] "Observed pod startup duration" pod="kube-system/coredns-787d4945fb-svfmw" podStartSLOduration=2.7152540309999997 pod.CreationTimestamp="2023-10-17 11:43:31 +0000 UTC" firstStartedPulling="0001-01-01 00:00:00 +0000 UTC" lastFinishedPulling="0001-01-01 00:00:00 +0000 UTC" observedRunningTime="2023-10-17 11:43:33.308507427 +0000 UTC m=+14.406547365" watchObservedRunningTime="2023-10-17 11:43:33.715254031 +0000 UTC m=+14.813293969"
Oct 17 11:43:34 minikube kubelet[11258]: I1017 11:43:34.107700   11258 pod_startup_latency_tracker.go:102] "Observed pod startup duration" pod="kube-system/kube-proxy-dm7mp" podStartSLOduration=3.107668883 pod.CreationTimestamp="2023-10-17 11:43:31 +0000 UTC" firstStartedPulling="0001-01-01 00:00:00 +0000 UTC" lastFinishedPulling="0001-01-01 00:00:00 +0000 UTC" observedRunningTime="2023-10-17 11:43:33.715595214 +0000 UTC m=+14.813635152" watchObservedRunningTime="2023-10-17 11:43:34.107668883 +0000 UTC m=+15.205708779"
Oct 17 11:43:40 minikube kubelet[11258]: I1017 11:43:40.221861   11258 kuberuntime_manager.go:1114] "Updating runtime config through cri with podcidr" CIDR="10.244.0.0/24"
Oct 17 11:43:40 minikube kubelet[11258]: I1017 11:43:40.223870   11258 kubelet_network.go:61] "Updating Pod CIDR" originalPodCIDR="" newPodCIDR="10.244.0.0/24"
Oct 17 11:44:19 minikube kubelet[11258]: I1017 11:44:19.077111   11258 scope.go:115] "RemoveContainer" containerID="cd7ae03b0e4271d797c6046460370ab92738c1be9fa829b3ce28ca84e7b775c1"
Oct 17 11:44:19 minikube kubelet[11258]: I1017 11:44:19.086726   11258 scope.go:115] "RemoveContainer" containerID="0b0f981e9bc6c4953214f4e2c533a066467739045ba6071b0e8264652317ea54"
Oct 17 11:44:19 minikube kubelet[11258]: I1017 11:44:19.094766   11258 scope.go:115] "RemoveContainer" containerID="ff122cd1d4f673098c738983bd5f2dd8300520ffb9171dcbe089bd0787b6afd7"
Oct 17 11:44:19 minikube kubelet[11258]: I1017 11:44:19.102862   11258 scope.go:115] "RemoveContainer" containerID="9d8ce9c34f4f9ee251347d569fd08a1498fa58f817352fbc4f9252c27193c2d6"
Oct 17 11:44:19 minikube kubelet[11258]: I1017 11:44:19.113516   11258 scope.go:115] "RemoveContainer" containerID="0daad7692d14b312b29200681ee986ac7666bb6d33a9cfb9c7c1be0460a52eab"
Oct 17 11:44:19 minikube kubelet[11258]: I1017 11:44:19.124020   11258 scope.go:115] "RemoveContainer" containerID="07a118ea48956c0b1cc6b43f8ac32ae5564e8f4fcb9ffdabd4344b48e644b94e"
Oct 17 11:44:19 minikube kubelet[11258]: I1017 11:44:19.131995   11258 scope.go:115] "RemoveContainer" containerID="201aeb579d23724a294b31634ff148d96f96b25bb3fd70d05ffa65611cf40a6f"
Oct 17 11:44:19 minikube kubelet[11258]: I1017 11:44:19.140543   11258 scope.go:115] "RemoveContainer" containerID="98e6de8cc2f305140940f27df6b295e1a7a168c936c54c14172d8a8848c3e3de"
Oct 17 11:48:19 minikube kubelet[11258]: W1017 11:48:19.042391   11258 machine.go:65] Cannot read vendor id correctly, set empty.

* 
* ==> storage-provisioner [6106b035dda1] <==
* I1017 11:43:31.777687       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I1017 11:43:31.786237       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I1017 11:43:31.786899       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I1017 11:43:31.794146       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I1017 11:43:31.794588       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_c1eb1914-657a-4aff-9228-199ace768dc1!
I1017 11:43:31.794689       1 event.go:282] Event(v1.ObjectReference{Kind:"Endpoints", Namespace:"kube-system", Name:"k8s.io-minikube-hostpath", UID:"4637e8f0-6863-4656-b552-0a85e56d85ea", APIVersion:"v1", ResourceVersion:"374", FieldPath:""}): type: 'Normal' reason: 'LeaderElection' minikube_c1eb1914-657a-4aff-9228-199ace768dc1 became leader
I1017 11:43:31.898456       1 controller.go:884] Started provisioner controller k8s.io/minikube-hostpath_minikube_c1eb1914-657a-4aff-9228-199ace768dc1!

